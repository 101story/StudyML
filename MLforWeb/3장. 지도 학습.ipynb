{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 분석 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주택 데이터 <br>\n",
    "평균 제곱 오차와 결정 계수를 계산<br>\n",
    "결정계수R^2 =1 인 경우 모델이 데이터에 완전히 적합<br>\n",
    "결정계수R^2 =0 인 경우 모델이 데이터를 설명하지 못함<br>\n",
    "음수인 경우 점점 부적합되는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv',sep=',',header=None)\n",
    "#shuffle the data\n",
    "# 교차 검증 폴드 데이터를 임의로 추출 \n",
    "# 데이터를 재편함\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "X= df[df.columns[:-1]].values\n",
    "Y = df[df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression\n",
      "mean R2: 0.71 (+/- 0.19)\n",
      "MSE: 23.6892459329\n"
     ]
    }
   ],
   "source": [
    "cv = 10\n",
    "print('linear regression')\n",
    "lin = LinearRegression()\n",
    "scores = model_selection.cross_val_score(lin, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(lin, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge r2egression\n",
      "mean R2: 0.71 (+/- 0.18)\n",
      "MSE: 23.8534712192\n"
     ]
    }
   ],
   "source": [
    "print('ridge r2egression')\n",
    "ridge = Ridge(alpha=1.0)\n",
    "scores = model_selection.cross_val_score(ridge, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(ridge, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso regression\n",
      "mean R2: 0.70 (+/- 0.17)\n",
      "MSE: 24.8529216472\n"
     ]
    }
   ],
   "source": [
    "print('lasso regression')\n",
    "lasso = Lasso(alpha=0.1)\n",
    "scores = model_selection.cross_val_score(lasso, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(lasso, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree regression\n",
      "mean R2: 0.78 (+/- 0.16)\n",
      "MSE: 18.5230237154\n"
     ]
    }
   ],
   "source": [
    "print('decision tree regression')\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "scores = model_selection.cross_val_score(tree, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(tree, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest regression\n",
      "mean R2: 0.87 (+/- 0.09)\n",
      "MSE: 10.3944529644\n"
     ]
    }
   ],
   "source": [
    "print('random forest regression')\n",
    "forest = RandomForestRegressor(n_estimators=50, max_depth=None, min_samples_split=2,\n",
    "                               random_state=0)\n",
    "scores = model_selection.cross_val_score(forest, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(forest, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear support vector machine\n",
      "mean R2: 0.69 (+/- 0.24)\n",
      "MSE: 25.9612224042\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "print('linear support vector machine')\n",
    "svm_lin = svm.SVR(epsilon=0.2,kernel='linear',C=1)\n",
    "scores = model_selection.cross_val_score(svm_lin, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(svm_lin, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support vector machine rbf\n",
      "mean R2: -0.01 (+/- 0.12)\n",
      "MSE: 83.8253978427\n"
     ]
    }
   ],
   "source": [
    "print('support vector machine rbf')\n",
    "clf = svm.SVR(epsilon=0.2,kernel='rbf',C=1.)\n",
    "scores = model_selection.cross_val_score(clf, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "mean R2: 0.55 (+/- 0.18)\n",
      "MSE: 37.5442608696\n"
     ]
    }
   ],
   "source": [
    "print('knn')\n",
    "knn = KNeighborsRegressor()\n",
    "scores = model_selection.cross_val_score(knn, X, Y, cv=cv)\n",
    "print(\"mean R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(knn, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "램덤 포레스트 결정 계수 평균이 0.87로 가장 적합함<br>\n",
    "특징선택 <br> 모델을 훈련 할 때 전체 특징 중 일부만 적절하고 나머지는 모델의 결정계수에 공헌하지 못함 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 재귀적 특징 축소 방법 RFE\n",
    "가장 큰 절대 가중치를 갖는 속성을 고려 <br>\n",
    "원하는 개수의 특징을 선택할 수 있을 때까지 반복<br>\n",
    "SVM 알고리즘의 경우 가중치는 w 값 뿐이지만, 회귀 분석의 경우 모델의 파라미터가 0(세타) 가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "best_features=4 \n",
    "# 최적의 속성을 4개로 줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature selection on linear regression\n",
      "R2: 0.60 (+/- 0.30)\n",
      "MSE: 33.2738633043\n",
      "feature selection ridge regression\n",
      "R2: 0.60 (+/- 0.29)\n",
      "MSE: 33.3838301611\n",
      "feature selection on lasso regression\n",
      "R2: 0.67 (+/- 0.21)\n",
      "MSE: 27.5283180344\n",
      "feature selection on decision tree\n",
      "R2: 0.76 (+/- 0.18)\n",
      "MSE: 20.0476284585\n",
      "feature selection on random forest\n",
      "R2: 0.84 (+/- 0.13)\n",
      "MSE: 13.132366332\n",
      "feature selection on linear support vector machine\n",
      "R2: 0.59 (+/- 0.29)\n",
      "MSE: 25.9612224042\n"
     ]
    }
   ],
   "source": [
    "print('feature selection on linear regression')\n",
    "rfe_lin = RFE(lin,best_features).fit(X,Y)\n",
    "# support_ 속성으로 특징 선택 여부를 타나내는 불리언 리스트를 반환\n",
    "# 선택된 특징을 모델 평가에 적용\n",
    "mask = np.array(rfe_lin.support_)\n",
    "scores = model_selection.cross_val_score(lin, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(lin, X[:,mask],Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))\n",
    "\n",
    "print('feature selection ridge regression')\n",
    "rfe_ridge = RFE(ridge,best_features).fit(X,Y)\n",
    "mask = np.array(rfe_ridge.support_)\n",
    "scores = model_selection.cross_val_score(ridge, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(ridge, X[:,mask],Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))\n",
    "\n",
    "print('feature selection on lasso regression')\n",
    "rfe_lasso = RFE(lasso,best_features).fit(X,Y)\n",
    "mask = np.array(rfe_lasso.support_)\n",
    "scores = model_selection.cross_val_score(lasso, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(lasso, X[:,mask],Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))\n",
    "\n",
    "print('feature selection on decision tree') \n",
    "rfe_tree = RFE(tree,best_features).fit(X,Y)\n",
    "mask = np.array(rfe_tree.support_)\n",
    "scores = model_selection.cross_val_score(tree, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(tree, X[:,mask],Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))\n",
    "\n",
    "print('feature selection on random forest')\n",
    "rfe_forest = RFE(forest,best_features).fit(X,Y)\n",
    "mask = np.array(rfe_forest.support_)\n",
    "scores = model_selection.cross_val_score(forest, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(forest, X[:,mask],Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted)) \n",
    "\n",
    "print('feature selection on linear support vector machine')\n",
    "rfe_svm = RFE(svm_lin,best_features).fit(X,Y)\n",
    "mask = np.array(rfe_svm.support_)\n",
    "scores = model_selection.cross_val_score(svm_lin, X[:,mask], Y, cv=cv)\n",
    "print(\"R2: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predicted = model_selection.cross_val_predict(svm_lin, X,Y, cv=cv)\n",
    "print('MSE:',mean_squared_error(Y,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN 알고리즘의 경우 특징에 가중치를 제공하지 않기 때문에 RFE 함수가 적용되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection \n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동차의 주요 특성을 설명하는 6개의 특징에 기반을 둔 데이터 사용 <br>\n",
    "분류의 정확성을 평가하기 위해 <br>\n",
    "정확률, 재현율, f 척도 사용<br>\n",
    "긍정과 부정 두 부류를 갖는 데이터 집합이 있을 때 <br>\n",
    "긍정인데 긍정으로 정확히 레이블된 참긍정과 <br>\n",
    "부정인데 긍정으로 잘못 레이블된 거짓 긍정 개수<br>\n",
    "긍정인데 부정으로 잘못 레이블된 거짓 부정의 개수 정의<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data in\n",
    "df = pd.read_csv('data_cars.csv',header=None)\n",
    "for i in range(len(df.columns)):\n",
    "    df[i] = df[i].astype('category')\n",
    "df.head()\n",
    "# 범주형 특징값\n",
    "# buying0, maint1, doors2, persons3, lug_boot4, safety5, car evaluation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1  2  3  4  5  6\n",
      "1337  1  3  1  1  1  0  0\n",
      "889   2  3  0  2  0  2  0\n",
      "341   3  1  0  1  0  0  0\n",
      "1664  1  1  1  1  0  0  3\n",
      "1605  1  2  3  1  1  1  2\n"
     ]
    }
   ],
   "source": [
    "#map catgories to values 분류를 숫자로 매핑 \n",
    "map0 = dict( zip( df[0].cat.categories, range( len(df[0].cat.categories ))))\n",
    "#print map0\n",
    "map1 = dict( zip( df[1].cat.categories, range( len(df[1].cat.categories ))))\n",
    "map2 = dict( zip( df[2].cat.categories, range( len(df[2].cat.categories ))))\n",
    "map3 = dict( zip( df[3].cat.categories, range( len(df[3].cat.categories ))))\n",
    "map4 = dict( zip( df[4].cat.categories, range( len(df[4].cat.categories ))))\n",
    "map5 = dict( zip( df[5].cat.categories, range( len(df[5].cat.categories ))))\n",
    "map6 = dict( zip( df[6].cat.categories, range( len(df[6].cat.categories ))))\n",
    "\n",
    "cat_cols = df.select_dtypes(['category']).columns\n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.cat.codes)\n",
    "\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CalcMeasures 성능 측정 후 저장을 위한 함수 \n",
    "df_f1 = pd.DataFrame(columns=['method']+sorted(map6, key=map6.get))\n",
    "df_precision = pd.DataFrame(columns=['method']+sorted(map6, key=map6.get))\n",
    "df_recall = pd.DataFrame(columns=['method']+sorted(map6, key=map6.get))\n",
    "def CalcMeasures(method,y_pred,y_true,df_f1=df_f1\n",
    "                 ,df_precision=df_precision,df_recall=df_recall):\n",
    "\n",
    "    df_f1.loc[len(df_f1)] = [method]+list(f1_score(y_pred,y_true,average=None))\n",
    "    df_precision.loc[len(df_precision)] = [method]+list(precision_score(y_pred,y_true,average=None))\n",
    "    df_recall.loc[len(df_recall)] = [method]+list(recall_score(y_pred,y_true,average=None))\n",
    "\n",
    "# x, y 데이터 분리\n",
    "X= df[df.columns[:-1]].values\n",
    "Y = df[df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\jhee\\Documents\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 10 개의 교차 검증 폴드가 사용 \n",
    "\n",
    "cv = 10\n",
    "method = 'linear support vector machine'\n",
    "clf = svm.SVC(kernel='linear',C=50)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'rbf support vector machine'\n",
    "clf = svm.SVC(kernel='rbf',C=50)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'poly support vector machine'\n",
    "clf = svm.SVC(kernel='poly',C=50)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'decision tree'\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'random forest'\n",
    "clf = RandomForestClassifier(n_estimators=50,random_state=0,max_features=None)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'naive bayes'\n",
    "clf = MultinomialNB()\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'logistic regression'\n",
    "clf = LogisticRegression()\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)\n",
    "\n",
    "method = 'k nearest neighbours'\n",
    "clf = KNeighborsClassifier(weights='distance',n_neighbors=5)\n",
    "y_pred = model_selection.cross_val_predict(clf, X,Y, cv=cv)\n",
    "CalcMeasures(method,y_pred,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "측정된 성능 값은 데이터 프레임에 저장됨<br>\n",
    "등급별로 4회 평가<br>\n",
    "acc:0, unacc:2 good:1 vgood:3<br>\n",
    "가장 좋은 모델 RBF 커널 SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>acc</th>\n",
       "      <th>good</th>\n",
       "      <th>unacc</th>\n",
       "      <th>vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear support vector machine</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846866</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf support vector machine</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999587</td>\n",
       "      <td>0.992248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly support vector machine</td>\n",
       "      <td>0.788436</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.938292</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.964613</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.993394</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.966234</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.993367</td>\n",
       "      <td>0.977099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825299</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.275168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823097</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k nearest neighbours</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.951549</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method       acc      good     unacc     vgood\n",
       "0  linear support vector machine  0.264591  0.000000  0.846866  0.000000\n",
       "1     rbf support vector machine  0.997403  1.000000  0.999587  0.992248\n",
       "2    poly support vector machine  0.788436  0.843750  0.938292  0.783333\n",
       "3                  decision tree  0.964613  0.893617  0.993394  0.969231\n",
       "4                  random forest  0.966234  0.937063  0.993367  0.977099\n",
       "5                    naive bayes  0.040404  0.000000  0.825299  0.000000\n",
       "6            logistic regression  0.275168  0.000000  0.823097  0.055556\n",
       "7           k nearest neighbours  0.778689  0.579439  0.951549  0.686869"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>acc</th>\n",
       "      <th>good</th>\n",
       "      <th>unacc</th>\n",
       "      <th>vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear support vector machine</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982645</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf support vector machine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly support vector machine</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.948760</td>\n",
       "      <td>0.723077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.990083</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997521</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.213542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924793</td>\n",
       "      <td>0.030769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k nearest neighbours</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.990083</td>\n",
       "      <td>0.523077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method       acc      good     unacc     vgood\n",
       "0  linear support vector machine  0.177083  0.000000  0.982645  0.000000\n",
       "1     rbf support vector machine  1.000000  1.000000  0.999174  0.984615\n",
       "2    poly support vector machine  0.781250  0.782609  0.948760  0.723077\n",
       "3                  decision tree  0.958333  0.913043  0.994215  0.969231\n",
       "4                  random forest  0.968750  0.971014  0.990083  0.984615\n",
       "5                    naive bayes  0.020833  0.000000  0.997521  0.000000\n",
       "6            logistic regression  0.213542  0.000000  0.924793  0.030769\n",
       "7           k nearest neighbours  0.742188  0.449275  0.990083  0.523077"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>acc</th>\n",
       "      <th>good</th>\n",
       "      <th>unacc</th>\n",
       "      <th>vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear support vector machine</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf support vector machine</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly support vector machine</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.928052</td>\n",
       "      <td>0.854545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.970976</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.992574</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.963731</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.996672</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.386792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741551</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>k nearest neighbours</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.915902</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method       acc      good     unacc     vgood\n",
       "0  linear support vector machine  0.523077  0.000000  0.744055  0.000000\n",
       "1     rbf support vector machine  0.994819  1.000000  1.000000  1.000000\n",
       "2    poly support vector machine  0.795756  0.915254  0.928052  0.854545\n",
       "3                  decision tree  0.970976  0.875000  0.992574  0.969231\n",
       "4                  random forest  0.963731  0.905405  0.996672  0.969697\n",
       "5                    naive bayes  0.666667  0.000000  0.703790  0.000000\n",
       "6            logistic regression  0.386792  0.000000  0.741551  0.285714\n",
       "7           k nearest neighbours  0.818966  0.815789  0.915902  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc       384\n",
       "good       69\n",
       "unacc    1210\n",
       "vgood      65\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_counts=df[6].value_counts()\n",
    "pd.Series(map6).map(labels_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
