{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 오차역전파법 Backpropagation : 오차를 역으로 전파 하는 방법 \n",
    "\n",
    "# 5.1 계산 그래프 \n",
    "\n",
    "계산 과정을 그래프로 나타낸 것 : Node(노드)와 Edge(에지) 로 표현\n",
    "\n",
    "## 5.1.1 계산 그래프로 풀다 \n",
    "\n",
    "[사과 한개] --100원--> [*2 개]  --200원-->  [**1.1 수수료] --220원-->  결제 \n",
    "\n",
    "1. 계산 그래프를 구성한다. \n",
    "2. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다. \n",
    "\n",
    "* forward propagation : 계산을 왼쪽에서 오른쪽으로 진행\n",
    "* backward propagation : 계산을 오른쪽에서 왼쪽으로 진행 \n",
    "\n",
    "## 5.1.2 국소적 계산 \n",
    "국소적 : 자신과 직접 관계된 작은 범위 \n",
    "<img width=50% src ='calculateGraph.png' ></img>\n",
    "\n",
    "\n",
    "## 5.1.3 왜 계산 그래프?\n",
    "사과 값이 조금 올랐다. 지불금액이 얼마나 증가 하는가? <br>\n",
    "--> 역전파를 이용해 구할 수 있다. \n",
    "\n",
    "<img width=50% src ='apple.png' ></img>\n",
    "\n",
    "> 사과 가격에 대한 지불금액의 미분 <br>\n",
    "사과 가격이 1원 오르면 최종 금액은 2.2원 오르게 된다. <br>\n",
    "오른쪽에서 왼쪽으로 1 -> 1.1 > 2.2 순으로 미분 값을 전달\n",
    "\n",
    "# 5.2 Chain rule (연쇄법칙)\n",
    "\n",
    "## 5.2.1 계산 그래프의 역전파 \n",
    "\n",
    "신호 E 에 순전파 때의 계산의 미분을 곱한 후 다음 노드로 전달한다. <br>\n",
    "f(x) 가 $x^2$ 라면 미분한 값은 2x 가 된다. \n",
    "\n",
    "## 5.2.2 연쇄법칙이란?\n",
    "* 합성 함수 : 여러 함수로 구성된 함수 \n",
    "    * 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타냄 <br>\n",
    "\n",
    "$z = (x+y)^2$   <br>\n",
    "        =><br>\n",
    "        $z = t^2$<br>\n",
    "        $t = (x+y)$\n",
    "\n",
    "각각에 대해서 편미분 하면 x 에 대한 z 의 미분 값은 = 2(x+y) 가 된다. \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "# 5.3 역전파\n",
    "\n",
    "## 5.3.1 덧셈 노드의 역전파 \n",
    "\n",
    "$z=x+y$ 를 미분 \n",
    "\n",
    "덧셈 노드의 역전파는 1을 곱하기만 할뿐 입력되는 값을 그대로 다음 노드로 보냄\n",
    "\n",
    "입력신호를 다음 노드로 출력할 뿐 그대로 다음노드로 전달함 \n",
    "\n",
    "## 5.3.2 곱셈 노드의 역전파 \n",
    "\n",
    "$z=xy$ 를 미분\n",
    "\n",
    "곱셈 노드의 역전파는 상류의 값에 순전파 때의 입력 신호들을 '서로 바꾼 값' 을 곱해서 하류에 보냄\n",
    "\n",
    "<img  width=50% src ='calculateGraphBack.png'/>\n",
    "\n",
    "10, 5 x -> 50 이 됐으면 곱셈의 역전파에서는 \n",
    "\n",
    "1.3 이라는 임의의 값이 역으로 흘러오면 <br>\n",
    "1.3 x 5 = 6.5 다른 하나는 1.3 x 10 = 13 이 됨 (각각의 편미분 값)<br>\n",
    "6.5 는 10 이 온 방향으로 <br>\n",
    "13 은 5 가 온 방향으로 보내짐 \n",
    "\n",
    "\n",
    "결과의 오차를 반영하기 위해 각각의 노드에 하이퍼파라메터 값을 역으로 변경시켜 나간다. \n",
    "\n",
    "최종 오차에 weight 가 얼마나 영향을 주는지 계산 (오차에 주는 영향을 반영해서 최종오차가 줄어들도록 함)\n",
    "\n",
    "\n",
    "\n",
    "# 5.4 단순 계층 구현\n",
    "\n",
    "## 5.4.1 곱셈 계층 \n",
    "\n",
    "모든 계층이 forward() 와 backward() 라는 공통의 인터페이스를 갖도록 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    # 순전파에서 유지할 x,y 변수 초기화\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        return out\n",
    "    \n",
    "    # 상류에서 넘어온 미분 (dout) 에 순전파 떄의 값을 서로 바꿔 곱한 후 하류로 흘려 보냄 \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y # x 와 y 를 바꾼다. \n",
    "        dy = dout * self.x\n",
    "        return dx, dy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱셈 계층 순전파 역전파 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 220\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dTax: 200\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "# backward\n",
    "dprice = 1 \n",
    "# 순전파 출력에 대한 미분 값\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4.2 덧셈 계층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "\n",
    "    # 상류에서 내려 오는 미분 값을 그대로 하류로 보냄 \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈 계층과 곱셈 계층으로 순전파 역전파 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# layer\n",
    "mul_apple_layer = MulLayer() # 사과 수량 * 개수 \n",
    "mul_orange_layer = MulLayer()  # 오랜지 수량 * 개수 \n",
    "add_apple_orange_layer = AddLayer() # 사과가격 + 오랜지가격 \n",
    "mul_tax_layer = MulLayer() # 총 가격 * 수수료 \n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
    "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
    "\n",
    "\n",
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 활성화 함수 계층 구현하기 \n",
    "\n",
    "## 5.5.1 ReLU 계층\n",
    "\n",
    "y = x (x>0) <br>\n",
    "y = 0 (x<=0)\n",
    "\n",
    "x 에 대한 미분 \n",
    "\n",
    "$\\frac{dy}{dx}$ = 1 (x>0) <br>\n",
    "$\\frac{dy}{dx}$ = 0 (x<=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        sef.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask : True/False 로 구성된 넘파일 배열로 <br>\n",
    "    순전파의 입력인 x 의 원소값이 0 이하인 인덱스는 True 그외에는 False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)\n",
    "mask = (x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.2 Sigmoid 계층 \n",
    "\n",
    "$\\frac{1}{1+\\exp(-x)}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-1))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        \n",
    "        return dx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파의 출력을 인스턴스 변수 out 에 보관했다, 역전파 때 그 변수를 사용 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 Affine/Softmax 계층 구현\n",
    "\n",
    "## 5.6.1 Affine 계층 \n",
    "\n",
    "== Fully Connected\n",
    "\n",
    "Y = np.dot(X,W) +B 로 계산 \n",
    "\n",
    "X(2,) * W(2,3) = O(3,) 의 차원의 원소 개수를 일치 시켜야 함<br>\n",
    "(신경망의 순전파 때 수행하는 행렬의 내적 = 어파인 변환(Affine transformaton))\n",
    "\n",
    "\n",
    "<img src='Affine.png' width=30%>\n",
    "\n",
    "$X \\cdot W = \\frac{\\partial L}{\\partial Y}$ 이기때문에\n",
    "\n",
    "$\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y}\\cdot {W}^{t}$ <br>\n",
    "$\\frac{\\partial L}{\\partial W} =  {X}^{t}\\cdot\\frac{\\partial L}{\\partial Y}$\n",
    "\n",
    "역전파로 $\\frac{\\partial L}{\\partial X}$ 값과 $\\frac{\\partial L}{\\partial W}$ 값을 구함 \n",
    "\n",
    "편향을 더할때에도 각각의 N 개의 데이터 모두에게 적용\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "x_dot_w = np.array([[0,0,0], [10,10,10]])\n",
    "B = np.array([1,2,3])\n",
    "\n",
    "print(x_dot_w + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향의 역전파는 N 개의 데이터 대한 미분을 데이터 마다 더해서 구함.<br>\n",
    "np.sum() 에서 0 번째 축(데이터를 단위로 한 축)에 대해서 총합을 구함.\n",
    "\n",
    "순방향 편향을 더할때 브로드캐스팅됨 (역으로 sum() 해줘서 역전파로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY = np.array([[1,2,3], [4,5,6]]) # 데이터 2개 \n",
    "dB = np.sum(dY, axis = 0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6.3 Softmax-with-Loss 계층\n",
    "\n",
    "softmax : 입력 값을 정규화하여 출력 \n",
    "\n",
    "신경망이 수행하는 작업 : 학습, 추론<br> \n",
    "    추론에서 주로 max 값을 사용<br>\n",
    "    학습에서 주로 softmax 값을 사용 \n",
    "    \n",
    "손실 함수인 교차 엔트로피 오차도 포함 = softmax-with-loss\n",
    "\n",
    "- 3 클래스 분류를 가정하고 이전 계층의 입력(점수)를 받아 softmax 계층은 (a1, a2, a3) 를 정규화 하여 (y1, y2, y3) 를 출력 \n",
    "- Cross Entropy Error 계층은 softmax 출력과 정답을 받고 손실을 L 을 출력\n",
    "- softmax 계층의 역전파는 (y1-t1, y2-t2, y3-t3) 오차가 앞계층에 전해짐 \n",
    "\n",
    "예) 정답이 (0, 1, 0)  일때 softmax 에서 (0.3, 0.2, 0.5) 를 출력 했을 때 <br>\n",
    "정답인 1번 인덱스 는 확률이 0.2(20%) 라서 softmaxk 의 역전파는 (0.3, -0.8, 0.5) 가 되어 커다란 오차를 전파 하게 됨 \n",
    "\n",
    "\n",
    "\n",
    "** 소프트맥스의 역전파 결과가 깔끔한 것에 유의** \n",
    "    -  소프트맥스의 손실 함수로 교차 엔트로피 오차를 적용함 \n",
    "    -  회귀 문제라면 출력의 활성화 함수로 ‘항등 함수’, 손실 함수로 ‘평균 제곱 오차’를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실\n",
    "        self.y = None #softmax 출력\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(t)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7 오차역전파법 구현하기\n",
    "\n",
    "\n",
    "## 5.7.1 신경망 학습의 전체 그림 \n",
    "\n",
    "* 전체 \n",
    "    - 가중치와 편향을 훈련 데이터에 적응하도록 저정하는 과정 (학습) 을 진행\n",
    "* 1단계 - 미니배치\n",
    "    - 훈련 데이터 중 일부를 가져와 손실 함수 값을 줄이는 것이 목표\n",
    "* 2단계 - 기울기 산출 \n",
    "    - 각 가중치 매개변수의 기울기를 구해 손실 함수의 값을 가장 작게 하는 방향을 제시 \n",
    "* 3단계 - 매개변수 갱신\n",
    "    - 가중치 매개변수를 기울기 방향으로 조금 갱신\n",
    "* 4단계 - 반복\n",
    "\n",
    "기울기 산출 에서 오차역전파법 사용 \n",
    "\n",
    "수치 미분은 구현하기 쉽지만 계산이 올래 걸리나 오차역전파법은 기울기를 효율적이고 빠르게 구할 수 있음 \n",
    "\n",
    "## 5.7.2 오차역전파법을 이용한 신경망 구현\n",
    "\n",
    "lastLayer : 신경망의 마지막 계층 Softmax With Loss 계층 이용\n",
    "\n",
    "OrderedDict : 순서를 지정해둔대로 사용할수 있는 사전 (그냥 사전은 알파뱃순으로 정렬됨)\n",
    "\n",
    "<img src = 'layer.png' width=50%>\n",
    "\n",
    "<center>input data -> [Affine, Relu] : input 계층 -> [Affine, Relu] : hidden 계층 -> [Affine] : output 계층 -> [softmax]</center>\n",
    "\n",
    "\n",
    "-- 아래 예제에서는 input 계층을 따로 두지 않고 바로 hidden layer 로 시작함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict() # 순서가 있는 dictionary\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7.3 오차역전파법으로 구한 기울기 검증\n",
    "\n",
    "오차역전파의 복잡한 구현에 실수를 찾기 위해<br> \n",
    "수치미분을 사용하여 정확히 구현했는지 확인\n",
    "\n",
    "gradient check 기울기 확인 (두 기울기 구하는 방법을 비교) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:3.11714869341e-13\n",
      "b1:1.07402969981e-12\n",
      "W2:1.03968210311e-12\n",
      "b2:1.19904092211e-10\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from tmp.dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 절대 오차의 평균을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오차역전파법을 사용한 학습 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13575 0.1375\n",
      "0.904166666667 0.9051\n",
      "0.9223 0.9228\n",
      "0.93395 0.9343\n",
      "0.945233333333 0.943\n",
      "0.949516666667 0.9473\n",
      "0.95715 0.954\n",
      "0.961316666667 0.9566\n",
      "0.964383333333 0.9625\n",
      "0.96815 0.9653\n",
      "0.970266666667 0.9673\n",
      "0.972216666667 0.9684\n",
      "0.974866666667 0.9693\n",
      "0.975816666667 0.9693\n",
      "0.976883333333 0.9696\n",
      "0.978216666667 0.9708\n",
      "0.97865 0.9705\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from tmp.dataset.mnist import load_mnist\n",
    "#from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(len(train_acc_list))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQUREQgoEEREBFAgiIhL6//PMvzBNCDuFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,train_acc_list)\n",
    "plt.plot(x,test_acc_list)\n",
    "plt.ylim([0.8, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8891390>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncCcisiCGOxGRBTHciYgs6P8ByNuowoYWcn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(train_loss_list))\n",
    "x \n",
    "plt.plot(x, train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
