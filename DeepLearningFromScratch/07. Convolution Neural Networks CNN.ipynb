{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks \n",
    "\n",
    "합성곱 신경망 \n",
    "\n",
    "이미지 인식, 음성 인식 등에 사용됨 \n",
    "\n",
    "\n",
    "# 7.1 전체 구조\n",
    "\n",
    "* Pooling Layer 추가됨 \n",
    "\n",
    "* Fully Connected (전결합) : 인접하는 계층의 모든 뉴런과 결합\n",
    "\n",
    "* Affine 계층 : 완전히 연결된 계층 \n",
    "\n",
    "        Affine -> ReLU -> Affine -> ReLU -> Affine -> Softmax ->\n",
    "\n",
    "* CNN 구조 \n",
    "    \n",
    "        Conv -> ReLU -> Pooling -> Conv -> ReLU -> Pooling\n",
    "        -> Conv -> ReLU -> Affine -> ReLU -> Affine -> Softmax -> \n",
    "    \n",
    "    Conv 합성곱 계층과 Pooling 계층이 추가 됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "\n",
    "# 7.2 Conv 계층\n",
    "\n",
    "## 7.2.1 Fully Connected 계층의 문제점 \n",
    "\n",
    "* Fully Connected : 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있다. \n",
    "\n",
    "    문제점 : 데이터의 형상이 무시 된다. <br>\n",
    "    예) 3차원 이미지 데이터를 평평한 1차원 데이터로 바꿔서 연산을 해야함 MNIST 데이터 셋을 사용한 사례에서 (1,28,28) 이미지를 1줄로 784 개의 데이터를 Affine 계층에 입력으로 사용\n",
    "\n",
    "\n",
    "* Feature map : 합성곱 계층의 입출력 데이터 \n",
    "    input feature map, output feature map\n",
    "    \n",
    "    \n",
    "## 7.2.2 Conv 연산\n",
    "\n",
    "합성곱 연산은 이미지 처리에서 말하는 **필터 연산** 에 해당\n",
    "\n",
    "가로 세로 방향의 차원을 가짐 입력 (4,4) 필터는 (3,3) -> (2,2) 출력 \n",
    "\n",
    "<img src='CNNFilter.png' width=50%>\n",
    "\n",
    "* kernel : 필터 \n",
    "\n",
    "* window : 합성곱의 연산은 필터의 윈도우를 일정간격으로 이동하며 입력데이터 적용 \n",
    "\n",
    "입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구함 (단일곱셈 누산 Fused multiply-add FMA 라함) 그 결과를 출력의 장소에 저장 \n",
    "\n",
    "CNN 에서의 필터 = 가중치 \n",
    "\n",
    "편향은 항상 하나만 존재하여 필터를 적용한 모든 원소에 같은 값을 더하여 사용 \n",
    "\n",
    "\n",
    "## 7.2.3 패딩\n",
    "\n",
    "* padding : 입력 데이터 주변의 특정 값을 채움 \n",
    "\n",
    "-- 패딩은 주로 출력 크기를 조정할 목적으로 사용, 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달 할수 있다. (Conv 연산을 거칠때 마다 점점 크기가 줄어듬을 방지) \n",
    "\n",
    "\n",
    "## 7.2.4 스트라이드 \n",
    "\n",
    "* stride : 필터를 적용하는 위치의 간격, window 가 이동하는 간격 (보폭)\n",
    "\n",
    "입력 (H,W) 필터 (FH, FW) -> 출력 (OH, OW) <br>\n",
    "패딩 P, 스트라이드 S\n",
    "\n",
    "\\begin{equation*}\n",
    "    OH = \\frac{H + 2P + - FH}{S} + 1 \\\\\n",
    "    OW = \\frac{H + 2P + - FW}{S} + 1\n",
    "\\end{equation*}\n",
    "\n",
    "정수로 나눠 떨어져야함. 값이 딱 나눠 떨어지지 않을 때엔 가장 가까운 정수로 반올림 등 (특별히 에러를 내지 않고 진행하도록 구현)\n",
    "\n",
    "## 7.2.5 3차원 데이터의 Conv 연산 \n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "필터도 여러가지 채널(색상) 에 맞춰서 줘야한다. 채널이 3개면 필터도 3개 \n",
    "\n",
    "## 7.2.6 블록으로 생각하기 \n",
    "\n",
    "3차원의 연산은 데이터와 필터를 직육면체 블록으로 생각 \n",
    "\n",
    "채널수 C, 필터 높이 FH, 필터 너비 FW (C, FH, FW)\n",
    "\n",
    "<img src='CNNblock.png' width=50%/>\n",
    "\n",
    "\n",
    "여러개의 필터를 사용하면 4차원이 됨 -> 출력데이터가 필터의 개수만큼 만들어짐 (FN)\n",
    "\n",
    "형상이 다른 블록의 덧셈은 브로드캐스트됨\n",
    "\n",
    "\n",
    "## 7.2.7 배치 처리 \n",
    "\n",
    "<img src ='CNNblock2.png' width=50%/>\n",
    "\n",
    "블럭이 N 개, 필터의 개수는 그대로 (N 데이터수, FN 필터 수 , OH 높이, OW 너비) 4차원의 데이터 \n",
    "\n",
    "N 개의 데이터에 대한 합성곱 연산이 이뤄짐 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7.3 풀링계층 \n",
    "\n",
    "Pooling layer : 가로, 세로 방향의 공간을 줄이는 연산 \n",
    "\n",
    "\n",
    "* 최대 풀링(max pooling)을 스트라이드 2로 처리 영역의 최대값을 취함 \n",
    "* 평균 풀링 : 평균 풀링은 대상 영역의 평균으로 계산 \n",
    "\n",
    "## 7.3.1 풀링계층의 특징\n",
    "\n",
    "* 최댓값 혹은 평균을 취하는 명확한 처리하므로 학습해야 할 매개변수가 없다.\n",
    "* 채널마다 독립적으로 계산하므로 채널 수가 변하지 않는다.\n",
    "* 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다. (영향을 적게 받는다, 떨림 같은..)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 합성곱/풀링 계층 구현하기\n",
    "\n",
    "## 7.4.1 4차원배열\n",
    "\n",
    "* 높이 28, 너비 28, 채널 1 인 이미지 데이터 10개 (10, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.63464697,  0.29145329,  0.70943543,  0.07292147,  0.61769742,\n",
       "         0.0262977 ,  0.63931379,  0.88161805,  0.50876108,  0.96345767,\n",
       "         0.30438957,  0.47415976,  0.89437433,  0.42327603,  0.70335345,\n",
       "         0.53635078,  0.83545286,  0.12923368,  0.90939233,  0.40892987,\n",
       "         0.3615447 ,  0.70294223,  0.58095422,  0.47800973,  0.84101858,\n",
       "         0.92739338,  0.94328139,  0.68488791],\n",
       "       [ 0.09005096,  0.38282588,  0.6024875 ,  0.79704861,  0.71563762,\n",
       "         0.42587486,  0.50756603,  0.49538155,  0.57475933,  0.51511513,\n",
       "         0.58623892,  0.81419385,  0.89426036,  0.5061551 ,  0.18958154,\n",
       "         0.10657779,  0.18733242,  0.10495775,  0.52886277,  0.217858  ,\n",
       "         0.93185952,  0.19957075,  0.07862927,  0.65470483,  0.12457137,\n",
       "         0.59053177,  0.01442056,  0.34501623]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape\n",
    "x[0].shape\n",
    "x[0, 0][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.2 im2col 로 데이터 펼침\n",
    "\n",
    "넘파이에서는 원소에 접근할 때 for 문을 사용하지 않는 것이 좋음\n",
    "\n",
    "<img src = 'CNNim2col.png' width=50%>\n",
    "* im2col 함수를 구현 : 입력데이터를 필터링(가중치 계산) 하기 좋게 전개하는(펼치는)함수, 4차원 데이터가 2차원 행렬로 바뀜 \n",
    "    <br>입력데이터에서 필터를 적용해 3차원 블록을 한줄로 늘어 놓음 \n",
    "    \n",
    "* caffe 와 chainer 에서도 im2col 이용 \n",
    "\n",
    "<img src ='CNNim2col1.png' width=50%>\n",
    "\n",
    "필터를 세로로 1열로 전개 N 개의 필터 만큼 [데이터열 x FN] 이 됨 <br>\n",
    "2차원인 출력 데이터를 4차원의 reshape 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 75)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.rand(1,3,7,7) # 데이터 수, 채널, 높이, 너비 (4차원데이터)\n",
    "col1 = im2col(x1, 5, 5,stride=1, pad=0)\n",
    "col1.shape # 9 출력 이미지의 사이즈 75/3=25 채널 3 개로 되어 있음 1채널에는 25 = 5개 씩 5개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 75)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.random.rand(10,3,7,7) \n",
    "col2 = im2col(x2, 5, 5,stride=1, pad=0)\n",
    "col2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.49151141,  0.12164675,  0.86855103,  0.22889157,  0.14627692],\n",
       "         [ 0.07541529,  0.3949526 ,  0.33361449,  0.86657293,  0.4811581 ],\n",
       "         [ 0.32640807,  0.39474257,  0.82698389,  0.73426756,  0.2800613 ],\n",
       "         [ 0.07286197,  0.3153743 ,  0.3133537 ,  0.87511364,  0.28247084],\n",
       "         [ 0.42991487,  0.09583869,  0.14669056,  0.30303999,  0.64246304]],\n",
       "\n",
       "        [[ 0.05630697,  0.65717021,  0.79114124,  0.45824106,  0.034449  ],\n",
       "         [ 0.61192191,  0.39725512,  0.64123497,  0.75642833,  0.05970315],\n",
       "         [ 0.01500802,  0.33153892,  0.80708351,  0.68613629,  0.50918153],\n",
       "         [ 0.03102622,  0.61155163,  0.56794188,  0.11420271,  0.15683787],\n",
       "         [ 0.12565463,  0.09268063,  0.37644713,  0.55595962,  0.53431739]],\n",
       "\n",
       "        [[ 0.84796216,  0.07615896,  0.20359564,  0.84968551,  0.69550601],\n",
       "         [ 0.49095945,  0.34566338,  0.28857688,  0.38606163,  0.02631764],\n",
       "         [ 0.88426045,  0.25525849,  0.790754  ,  0.69487079,  0.05823669],\n",
       "         [ 0.56016581,  0.67255286,  0.09210888,  0.43415972,  0.63087052],\n",
       "         [ 0.96774258,  0.4621141 ,  0.04172049,  0.64125415,  0.25157897]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:, :,:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49151141,  0.12164675,  0.86855103,  0.22889157,  0.14627692,\n",
       "        0.07541529,  0.3949526 ,  0.33361449,  0.86657293,  0.4811581 ,\n",
       "        0.32640807,  0.39474257,  0.82698389,  0.73426756,  0.2800613 ,\n",
       "        0.07286197,  0.3153743 ,  0.3133537 ,  0.87511364,  0.28247084,\n",
       "        0.42991487,  0.09583869,  0.14669056,  0.30303999,  0.64246304,\n",
       "        0.05630697,  0.65717021,  0.79114124,  0.45824106,  0.034449  ,\n",
       "        0.61192191,  0.39725512,  0.64123497,  0.75642833,  0.05970315,\n",
       "        0.01500802,  0.33153892,  0.80708351,  0.68613629,  0.50918153,\n",
       "        0.03102622,  0.61155163,  0.56794188,  0.11420271,  0.15683787,\n",
       "        0.12565463,  0.09268063,  0.37644713,  0.55595962,  0.53431739,\n",
       "        0.84796216,  0.07615896,  0.20359564,  0.84968551,  0.69550601,\n",
       "        0.49095945,  0.34566338,  0.28857688,  0.38606163,  0.02631764,\n",
       "        0.88426045,  0.25525849,  0.790754  ,  0.69487079,  0.05823669,\n",
       "        0.56016581,  0.67255286,  0.09210888,  0.43415972,  0.63087052,\n",
       "        0.96774258,  0.4621141 ,  0.04172049,  0.64125415,  0.25157897])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1[0, :] #  0.05630697 6번째 -> x1 의 두번쨰 [[ 0.05630697 합쳐짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.3 합성곱 계층 구현\n",
    "\n",
    "- Pooling 클래스\n",
    "    - forward() 메소드\n",
    "        - 입력 데이터 전개\n",
    "        - 행별 최댓값\n",
    "        - 적절한 모향으로 성형\n",
    "    - backward() 메소드\n",
    "        - ReLU 노드 구현 시 사용한 max의 역전파 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import col2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 중간 데이터（backward 시 사용）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape  # 필터개수, 채널, 필터높이, 필터폭\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        ## Conv 구현 \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        # 2차원 배열로 만듬 \n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        # 두 행렬의 내적함 \n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        # (N,H,W,C) -> (N, C, H, W) 로 변경함 \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    # col2im 컬럼을 이미지로 변환하는 함수 사용 \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy reshape\n",
    "x = np.array(np.arange(27)).reshape(1,3,3,3)\n",
    "x\n",
    "x.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0, 1],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[4, 5],\n",
       "         [6, 7]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0, 2],\n",
       "         [4, 6]],\n",
       "\n",
       "        [[1, 3],\n",
       "         [5, 7]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array(np.arange(8)).reshape(4,2)\n",
    "x1\n",
    "x1.reshape(1,2,2,-1)\n",
    "x1.reshape(1,2,2,-1).transpose(0, 3, 1, 2) #0,2,4.. 열을 2x2 행렬 데이터로 바꿈 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.4 풀링 계층 구현\n",
    "\n",
    "im2col 함수를 사용해 입력 데이터 전개\n",
    "\n",
    "채널이 독립인 점이 합성곱 계층과 다른 점 (채널별로 다 구함)\n",
    "\n",
    "* 풀링 계층 구현의 흐름: 최대 풀링(가장 큰 원소는 회색으로 표시)\n",
    "    - 입력 데이터 전개\n",
    "    - 행별 최댓값\n",
    "    - 적절한 모향으로 성형\n",
    "\n",
    "<img src='CNNmaxPooling.png' width=50%>\n",
    "\n",
    "** 풀링 계층 구현하기 **\n",
    "\n",
    "* Pooling 클래스\n",
    "    - forward() 메소드\n",
    "        - 입력 데이터 전개\n",
    "        - 행별 최댓값 (np.max(x, axis=1) x 의 1번째 차원의 축마나 최댓값을 구함 \n",
    "        - 적절한 모향으로 성형\n",
    "    - backward() 메소드\n",
    "        - ReLU 노드 구현 시 사용한 max의 역전파 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        # 전개 \n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        # 최댓값 \n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        # reshape\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 CNN 구현하기\n",
    "\n",
    "layer 마다 활성화 함수를 사용하는 이유 : Affine (FC) 모든 노드가 다음 모든노드에 연결되어 있을때 이전 노드의 출력이 0 이 되는 것을 방지함 \n",
    "\n",
    "<img src='CNNM.png' width=50%>\n",
    "\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "     [W1]  conv - relu - pool - [W2] - affine - relu - [W3] - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_num : 필터수 \n",
    "    filter_size : 필터 크기\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "\n",
    "    # 28x28 정사각형\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        # output 도 정사각형 출력 크기 계산 \n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        # filter -> Conv\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        # poll out -> hiddent input(Affine)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        # hidden out -> output input\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        # W1\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        # W2\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        # W3\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        \n",
    "        # forward : 계층의 앞부터 계산 결과를 다음 계층에 전달 \n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3004933729\n",
      "=== epoch:1, train acc:0.225, test acc:0.283 ===\n",
      "train loss:2.29759204223\n",
      "train loss:2.29630255832\n",
      "train loss:2.28675761048\n",
      "train loss:2.28628841839\n",
      "train loss:2.27836895007\n",
      "train loss:2.26065546549\n",
      "train loss:2.25340627217\n",
      "train loss:2.24488923317\n",
      "train loss:2.20976790229\n",
      "train loss:2.18030040008\n",
      "train loss:2.16575824722\n",
      "train loss:2.15049411198\n",
      "train loss:2.08104603623\n",
      "train loss:2.03276491604\n",
      "train loss:1.98379224527\n",
      "train loss:1.95328003997\n",
      "train loss:1.81915474906\n",
      "train loss:1.81567198019\n",
      "train loss:1.75879464667\n",
      "train loss:1.62372378823\n",
      "train loss:1.57343644673\n",
      "train loss:1.5160620078\n",
      "train loss:1.53236897986\n",
      "train loss:1.29320807595\n",
      "train loss:1.23867080235\n",
      "train loss:1.1878332515\n",
      "train loss:1.06468662389\n",
      "train loss:1.02382487568\n",
      "train loss:0.993899497916\n",
      "train loss:0.895273827021\n",
      "train loss:0.979171921067\n",
      "train loss:0.877360956926\n",
      "train loss:0.89361443878\n",
      "train loss:0.857050385868\n",
      "train loss:0.807713651045\n",
      "train loss:0.820289636544\n",
      "train loss:0.692833462302\n",
      "train loss:0.70107226414\n",
      "train loss:0.671866261924\n",
      "train loss:0.731262313641\n",
      "train loss:0.662179819338\n",
      "train loss:0.580361366294\n",
      "train loss:0.561030372232\n",
      "train loss:0.702246502567\n",
      "train loss:0.631713127672\n",
      "train loss:0.582795566091\n",
      "train loss:0.644789816984\n",
      "train loss:0.675997492403\n",
      "train loss:0.696616265397\n",
      "train loss:0.866695271241\n",
      "train loss:0.490620987024\n",
      "train loss:0.552760742312\n",
      "train loss:0.658055728221\n",
      "train loss:0.609417351403\n",
      "train loss:0.446648877116\n",
      "train loss:0.705890790211\n",
      "train loss:0.629177498001\n",
      "train loss:0.522263023518\n",
      "train loss:0.58994984326\n",
      "train loss:0.507549775103\n",
      "train loss:0.573817126245\n",
      "train loss:0.503088000261\n",
      "train loss:0.405767977541\n",
      "train loss:0.452597350203\n",
      "train loss:0.508235239502\n",
      "train loss:0.368411768407\n",
      "train loss:0.382516828995\n",
      "train loss:0.38908479467\n",
      "train loss:0.554940176699\n",
      "train loss:0.312312013754\n",
      "train loss:0.509539201129\n",
      "train loss:0.455882016322\n",
      "train loss:0.534069381384\n",
      "train loss:0.279183362518\n",
      "train loss:0.398706984827\n",
      "train loss:0.353823135172\n",
      "train loss:0.397972262259\n",
      "train loss:0.430470867353\n",
      "train loss:0.415483509906\n",
      "train loss:0.525266733315\n",
      "train loss:0.403996488624\n",
      "train loss:0.323576256098\n",
      "train loss:0.415973776023\n",
      "train loss:0.26665385196\n",
      "train loss:0.233655898667\n",
      "train loss:0.500009545118\n",
      "train loss:0.362676630635\n",
      "train loss:0.347870354401\n",
      "train loss:0.411197091624\n",
      "train loss:0.368712607654\n",
      "train loss:0.271760720486\n",
      "train loss:0.441801769901\n",
      "train loss:0.441521984409\n",
      "train loss:0.366932394584\n",
      "train loss:0.338719043281\n",
      "train loss:0.45860665518\n",
      "train loss:0.458264228163\n",
      "train loss:0.176159229375\n",
      "train loss:0.368409394915\n",
      "train loss:0.324666040149\n",
      "train loss:0.367612277157\n",
      "train loss:0.500129468396\n",
      "train loss:0.433528064173\n",
      "train loss:0.249829412048\n",
      "train loss:0.492604169068\n",
      "train loss:0.275492756136\n",
      "train loss:0.428211164619\n",
      "train loss:0.290083953535\n",
      "train loss:0.410921959846\n",
      "train loss:0.371626457637\n",
      "train loss:0.25142363814\n",
      "train loss:0.428664209491\n",
      "train loss:0.437972589735\n",
      "train loss:0.265541211418\n",
      "train loss:0.27632491487\n",
      "train loss:0.176247013478\n",
      "train loss:0.462867411117\n",
      "train loss:0.378012209443\n",
      "train loss:0.282954402003\n",
      "train loss:0.261130211527\n",
      "train loss:0.364534214979\n",
      "train loss:0.467147270549\n",
      "train loss:0.665314263662\n",
      "train loss:0.303287352614\n",
      "train loss:0.299267184118\n",
      "train loss:0.280416044315\n",
      "train loss:0.56750923048\n",
      "train loss:0.244695025119\n",
      "train loss:0.217897301962\n",
      "train loss:0.365799428822\n",
      "train loss:0.330738728771\n",
      "train loss:0.314659170445\n",
      "train loss:0.320116157153\n",
      "train loss:0.356727238716\n",
      "train loss:0.282060874789\n",
      "train loss:0.427324411841\n",
      "train loss:0.440446659495\n",
      "train loss:0.44726264001\n",
      "train loss:0.391884195436\n",
      "train loss:0.282661336441\n",
      "train loss:0.326994605153\n",
      "train loss:0.395262770114\n",
      "train loss:0.326539713561\n",
      "train loss:0.210096461519\n",
      "train loss:0.297451991937\n",
      "train loss:0.268937502441\n",
      "train loss:0.267990484921\n",
      "train loss:0.336207180313\n",
      "train loss:0.178233979907\n",
      "train loss:0.235585147069\n",
      "train loss:0.38069063742\n",
      "train loss:0.399280971609\n",
      "train loss:0.161844278474\n",
      "train loss:0.343999975822\n",
      "train loss:0.340842439607\n",
      "train loss:0.309057436144\n",
      "train loss:0.341006427185\n",
      "train loss:0.378208017455\n",
      "train loss:0.32860122766\n",
      "train loss:0.484180163146\n",
      "train loss:0.321089095396\n",
      "train loss:0.284274679634\n",
      "train loss:0.345181931354\n",
      "train loss:0.225402698676\n",
      "train loss:0.338113688211\n",
      "train loss:0.361464317687\n",
      "train loss:0.21953656602\n",
      "train loss:0.346832954453\n",
      "train loss:0.355923235503\n",
      "train loss:0.236858860149\n",
      "train loss:0.452365452631\n",
      "train loss:0.324199294143\n",
      "train loss:0.29857746804\n",
      "train loss:0.250992986757\n",
      "train loss:0.185528842302\n",
      "train loss:0.496471771806\n",
      "train loss:0.294640803259\n",
      "train loss:0.275672291787\n",
      "train loss:0.263642103374\n",
      "train loss:0.379322421099\n",
      "train loss:0.238395769112\n",
      "train loss:0.211196162216\n",
      "train loss:0.209744832109\n",
      "train loss:0.336625665661\n",
      "train loss:0.278548120522\n",
      "train loss:0.216744392888\n",
      "train loss:0.325780134114\n",
      "train loss:0.223585105872\n",
      "train loss:0.264713455613\n",
      "train loss:0.29052692461\n",
      "train loss:0.212676691108\n",
      "train loss:0.190550057262\n",
      "train loss:0.261077147609\n",
      "train loss:0.394612387679\n",
      "train loss:0.198237852873\n",
      "train loss:0.281292578583\n",
      "train loss:0.216919307164\n",
      "train loss:0.197702664101\n",
      "train loss:0.308869488525\n",
      "train loss:0.146896829825\n",
      "train loss:0.189120757948\n",
      "train loss:0.163040609363\n",
      "train loss:0.277868821355\n",
      "train loss:0.268996069643\n",
      "train loss:0.2630534893\n",
      "train loss:0.175993038412\n",
      "train loss:0.308806596652\n",
      "train loss:0.26956073314\n",
      "train loss:0.289537851405\n",
      "train loss:0.255574707377\n",
      "train loss:0.225333438602\n",
      "train loss:0.238623461141\n",
      "train loss:0.130080364717\n",
      "train loss:0.225090446385\n",
      "train loss:0.188835179728\n",
      "train loss:0.252405249415\n",
      "train loss:0.268356162475\n",
      "train loss:0.222412844447\n",
      "train loss:0.134692984705\n",
      "train loss:0.305189969354\n",
      "train loss:0.302467297732\n",
      "train loss:0.237229236494\n",
      "train loss:0.23833538074\n",
      "train loss:0.320673558246\n",
      "train loss:0.199570586901\n",
      "train loss:0.166274128147\n",
      "train loss:0.219628808469\n",
      "train loss:0.168165060461\n",
      "train loss:0.355728511143\n",
      "train loss:0.197944394736\n",
      "train loss:0.387502179159\n",
      "train loss:0.293680632644\n",
      "train loss:0.211524850297\n",
      "train loss:0.463483232532\n",
      "train loss:0.196023734461\n",
      "train loss:0.389758275056\n",
      "train loss:0.255028335241\n",
      "train loss:0.24842422744\n",
      "train loss:0.383030612977\n",
      "train loss:0.238308916317\n",
      "train loss:0.187668308445\n",
      "train loss:0.391788292249\n",
      "train loss:0.20542624745\n",
      "train loss:0.278311152579\n",
      "train loss:0.201434456696\n",
      "train loss:0.235490416689\n",
      "train loss:0.214682223865\n",
      "train loss:0.171102284175\n",
      "train loss:0.373125823186\n",
      "train loss:0.123525523144\n",
      "train loss:0.148105724689\n",
      "train loss:0.229967955621\n",
      "train loss:0.242620701553\n",
      "train loss:0.199136340758\n",
      "train loss:0.183723915006\n",
      "train loss:0.194312641208\n",
      "train loss:0.267596496753\n",
      "train loss:0.167054167139\n",
      "train loss:0.193228382359\n",
      "train loss:0.305728336394\n",
      "train loss:0.200840191686\n",
      "train loss:0.283906189724\n",
      "train loss:0.173851066154\n",
      "train loss:0.382218987916\n",
      "train loss:0.254747680949\n",
      "train loss:0.31002016574\n",
      "train loss:0.144175045234\n",
      "train loss:0.257866875461\n",
      "train loss:0.0802151383653\n",
      "train loss:0.248644589935\n",
      "train loss:0.158906914623\n",
      "train loss:0.180914091571\n",
      "train loss:0.158213169519\n",
      "train loss:0.120823104423\n",
      "train loss:0.203383946821\n",
      "train loss:0.279404672797\n",
      "train loss:0.203770369161\n",
      "train loss:0.196980958254\n",
      "train loss:0.226346892848\n",
      "train loss:0.304322093496\n",
      "train loss:0.192561353562\n",
      "train loss:0.179055704771\n",
      "train loss:0.1390732802\n",
      "train loss:0.115154718275\n",
      "train loss:0.339225414188\n",
      "train loss:0.1597400046\n",
      "train loss:0.219143937461\n",
      "train loss:0.315614570341\n",
      "train loss:0.198435753609\n",
      "train loss:0.210359713459\n",
      "train loss:0.232497134051\n",
      "train loss:0.548158525199\n",
      "train loss:0.210875268865\n",
      "train loss:0.187875093292\n",
      "train loss:0.251254349347\n",
      "train loss:0.188534452684\n",
      "train loss:0.24506212036\n",
      "train loss:0.167289066357\n",
      "train loss:0.181866039422\n",
      "train loss:0.20822812561\n",
      "train loss:0.46274508582\n",
      "train loss:0.18077766674\n",
      "train loss:0.221051407092\n",
      "train loss:0.174159737272\n",
      "train loss:0.117956000777\n",
      "train loss:0.214277925055\n",
      "train loss:0.143138769824\n",
      "train loss:0.285031298027\n",
      "train loss:0.145452515499\n",
      "train loss:0.233658554942\n",
      "train loss:0.170005003247\n",
      "train loss:0.241436831645\n",
      "train loss:0.25254685019\n",
      "train loss:0.265599268338\n",
      "train loss:0.160990905315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.138045493214\n",
      "train loss:0.12691529553\n",
      "train loss:0.258115171816\n",
      "train loss:0.15861901814\n",
      "train loss:0.155343196257\n",
      "train loss:0.294687538856\n",
      "train loss:0.160332996816\n",
      "train loss:0.168511754807\n",
      "train loss:0.211770083785\n",
      "train loss:0.271274921992\n",
      "train loss:0.196312279583\n",
      "train loss:0.126804571389\n",
      "train loss:0.199524577309\n",
      "train loss:0.160117859818\n",
      "train loss:0.144780357701\n",
      "train loss:0.124910259614\n",
      "train loss:0.196337186277\n",
      "train loss:0.353179704404\n",
      "train loss:0.096237289156\n",
      "train loss:0.168967874172\n",
      "train loss:0.0976045323448\n",
      "train loss:0.330319634179\n",
      "train loss:0.269093141621\n",
      "train loss:0.0753767099363\n",
      "train loss:0.144696869609\n",
      "train loss:0.258841901554\n",
      "train loss:0.235106617488\n",
      "train loss:0.117319018108\n",
      "train loss:0.128988061647\n",
      "train loss:0.272467165287\n",
      "train loss:0.1820315636\n",
      "train loss:0.192307905237\n",
      "train loss:0.168116807677\n",
      "train loss:0.174215389251\n",
      "train loss:0.123384829383\n",
      "train loss:0.146144821958\n",
      "train loss:0.173533722348\n",
      "train loss:0.109101595976\n",
      "train loss:0.153975937326\n",
      "train loss:0.0901670380489\n",
      "train loss:0.0636829469951\n",
      "train loss:0.197012670953\n",
      "train loss:0.171381212518\n",
      "train loss:0.187667504554\n",
      "train loss:0.132360079622\n",
      "train loss:0.14632819836\n",
      "train loss:0.160650984908\n",
      "train loss:0.245383775165\n",
      "train loss:0.081922432174\n",
      "train loss:0.211182501716\n",
      "train loss:0.231997365286\n",
      "train loss:0.126320946179\n",
      "train loss:0.441214665547\n",
      "train loss:0.213082911838\n",
      "train loss:0.319685360487\n",
      "train loss:0.211937413322\n",
      "train loss:0.2350425548\n",
      "train loss:0.163248780192\n",
      "train loss:0.117478257144\n",
      "train loss:0.193767127496\n",
      "train loss:0.0964943098674\n",
      "train loss:0.1201731714\n",
      "train loss:0.153723653681\n",
      "train loss:0.308124447214\n",
      "train loss:0.145272051996\n",
      "train loss:0.196623479462\n",
      "train loss:0.195501884356\n",
      "train loss:0.249123179966\n",
      "train loss:0.120942541225\n",
      "train loss:0.107926484159\n",
      "train loss:0.131434232374\n",
      "train loss:0.145668280911\n",
      "train loss:0.214364940635\n",
      "train loss:0.14153284915\n",
      "train loss:0.0574912837483\n",
      "train loss:0.16243159263\n",
      "train loss:0.130374079251\n",
      "train loss:0.331288913646\n",
      "train loss:0.220044182336\n",
      "train loss:0.148203622695\n",
      "train loss:0.201869145339\n",
      "train loss:0.13021514074\n",
      "train loss:0.0775298862161\n",
      "train loss:0.260319842235\n",
      "train loss:0.102694618538\n",
      "train loss:0.139395493261\n",
      "train loss:0.0826385062486\n",
      "train loss:0.0521643072109\n",
      "train loss:0.189374671098\n",
      "train loss:0.147840601943\n",
      "train loss:0.157770090078\n",
      "train loss:0.111497329893\n",
      "train loss:0.14664354906\n",
      "train loss:0.0887645449356\n",
      "train loss:0.177736402705\n",
      "train loss:0.162645501194\n",
      "train loss:0.0809364666765\n",
      "train loss:0.0929339960699\n",
      "train loss:0.104170559487\n",
      "train loss:0.16137755529\n",
      "train loss:0.193646899504\n",
      "train loss:0.117813697936\n",
      "train loss:0.176566152731\n",
      "train loss:0.08052764279\n",
      "train loss:0.175570818824\n",
      "train loss:0.101925287101\n",
      "train loss:0.203007382141\n",
      "train loss:0.124037934063\n",
      "train loss:0.281556057173\n",
      "train loss:0.106932973512\n",
      "train loss:0.234775554375\n",
      "train loss:0.169875538795\n",
      "train loss:0.0774993539377\n",
      "train loss:0.23937729174\n",
      "train loss:0.113182201236\n",
      "train loss:0.184575759188\n",
      "train loss:0.23688928758\n",
      "train loss:0.105792278122\n",
      "train loss:0.187667449847\n",
      "train loss:0.185142769406\n",
      "train loss:0.152397294845\n",
      "train loss:0.050066929411\n",
      "train loss:0.173554555364\n",
      "train loss:0.0935306743898\n",
      "train loss:0.0740710550437\n",
      "train loss:0.116148542771\n",
      "train loss:0.150543008752\n",
      "train loss:0.143200250756\n",
      "train loss:0.20677255366\n",
      "train loss:0.236356174781\n",
      "train loss:0.0829087812911\n",
      "train loss:0.0683378719298\n",
      "train loss:0.111929732059\n",
      "train loss:0.110362409801\n",
      "train loss:0.221725781801\n",
      "train loss:0.0955338689262\n",
      "train loss:0.0512985562551\n",
      "train loss:0.0635119007523\n",
      "train loss:0.0991740780059\n",
      "train loss:0.0989041474533\n",
      "train loss:0.0925324550152\n",
      "train loss:0.197820579671\n",
      "train loss:0.177896045673\n",
      "train loss:0.128342667102\n",
      "train loss:0.207211404309\n",
      "train loss:0.17014737795\n",
      "train loss:0.152049877629\n",
      "train loss:0.121223321392\n",
      "train loss:0.102326167071\n",
      "train loss:0.130183835568\n",
      "train loss:0.203511879033\n",
      "train loss:0.188138890166\n",
      "train loss:0.18203745856\n",
      "train loss:0.151692720597\n",
      "train loss:0.162119232989\n",
      "train loss:0.171952535149\n",
      "train loss:0.155242695646\n",
      "train loss:0.0910592879123\n",
      "train loss:0.0817359073531\n",
      "train loss:0.201981218052\n",
      "train loss:0.110367719442\n",
      "train loss:0.148595706377\n",
      "train loss:0.132999566248\n",
      "train loss:0.101985431714\n",
      "train loss:0.163583984722\n",
      "train loss:0.13050321869\n",
      "train loss:0.134078595975\n",
      "train loss:0.156346612354\n",
      "train loss:0.114727051508\n",
      "train loss:0.129300557579\n",
      "train loss:0.119178979115\n",
      "train loss:0.10985770343\n",
      "train loss:0.176526587923\n",
      "train loss:0.0919153045574\n",
      "train loss:0.126779111113\n",
      "train loss:0.142641148222\n",
      "train loss:0.0918183585788\n",
      "train loss:0.0729206323546\n",
      "train loss:0.148097884545\n",
      "train loss:0.107148707522\n",
      "train loss:0.225444135498\n",
      "train loss:0.149271954118\n",
      "train loss:0.171950405871\n",
      "train loss:0.0986785674688\n",
      "train loss:0.116390949887\n",
      "train loss:0.134535984183\n",
      "train loss:0.0738359185713\n",
      "train loss:0.101131595329\n",
      "train loss:0.242779313098\n",
      "train loss:0.0768961263822\n",
      "train loss:0.240614315043\n",
      "train loss:0.158151795044\n",
      "train loss:0.0947767160414\n",
      "train loss:0.121600476873\n",
      "train loss:0.123516600529\n",
      "train loss:0.139002522949\n",
      "train loss:0.25624085147\n",
      "train loss:0.133165748286\n",
      "train loss:0.119020990147\n",
      "train loss:0.149270462983\n",
      "train loss:0.146238415731\n",
      "train loss:0.0957818540145\n",
      "train loss:0.100554700049\n",
      "train loss:0.140415275642\n",
      "train loss:0.0973030377554\n",
      "train loss:0.0885999081613\n",
      "train loss:0.280867311572\n",
      "train loss:0.298817372122\n",
      "train loss:0.0991882052857\n",
      "train loss:0.0916171360786\n",
      "train loss:0.0775961961036\n",
      "train loss:0.127045196507\n",
      "train loss:0.147917066517\n",
      "train loss:0.145219117079\n",
      "train loss:0.148971257232\n",
      "train loss:0.0617007462204\n",
      "train loss:0.133648217156\n",
      "train loss:0.125801214641\n",
      "train loss:0.122643521522\n",
      "train loss:0.209622549447\n",
      "train loss:0.108339464737\n",
      "train loss:0.0662574423204\n",
      "train loss:0.251793645136\n",
      "train loss:0.113034679227\n",
      "train loss:0.150931563236\n",
      "train loss:0.139180167393\n",
      "train loss:0.202312188516\n",
      "train loss:0.256845118237\n",
      "train loss:0.0933152369492\n",
      "train loss:0.141285238685\n",
      "train loss:0.107185953945\n",
      "train loss:0.15557892532\n",
      "train loss:0.0956010886628\n",
      "train loss:0.162927638186\n",
      "train loss:0.0783594712168\n",
      "train loss:0.0793548024525\n",
      "train loss:0.0411455642512\n",
      "train loss:0.100068781711\n",
      "train loss:0.115603331865\n",
      "train loss:0.0929627000536\n",
      "train loss:0.152598744951\n",
      "train loss:0.0788354460283\n",
      "train loss:0.113831169623\n",
      "train loss:0.0944796792188\n",
      "train loss:0.133933078303\n",
      "train loss:0.0826910869419\n",
      "train loss:0.0461330575102\n",
      "train loss:0.0878927012722\n",
      "train loss:0.122161788686\n",
      "train loss:0.209864214647\n",
      "train loss:0.0848146042886\n",
      "train loss:0.150979987731\n",
      "train loss:0.0835379864245\n",
      "train loss:0.0612374171391\n",
      "train loss:0.0910653494814\n",
      "train loss:0.176853737386\n",
      "train loss:0.121523516323\n",
      "train loss:0.115402799586\n",
      "train loss:0.145392448401\n",
      "train loss:0.227847176515\n",
      "train loss:0.22982089097\n",
      "train loss:0.214404582421\n",
      "train loss:0.160482183886\n",
      "train loss:0.106657994642\n",
      "train loss:0.14740234183\n",
      "train loss:0.140242433328\n",
      "train loss:0.0563269308969\n",
      "train loss:0.123095692696\n",
      "train loss:0.170777178876\n",
      "train loss:0.0555731421426\n",
      "train loss:0.136208623918\n",
      "train loss:0.151516316134\n",
      "train loss:0.0724817166468\n",
      "train loss:0.0763792118075\n",
      "train loss:0.0541887235247\n",
      "train loss:0.0646301820877\n",
      "train loss:0.115681359614\n",
      "train loss:0.0863886689463\n",
      "train loss:0.110886753868\n",
      "train loss:0.0628698580352\n",
      "train loss:0.107599816125\n",
      "train loss:0.118547883697\n",
      "train loss:0.1009788088\n",
      "train loss:0.0583402100761\n",
      "train loss:0.144799248229\n",
      "=== epoch:2, train acc:0.968, test acc:0.971 ===\n",
      "train loss:0.093388394484\n",
      "train loss:0.0687451781557\n",
      "train loss:0.156176633236\n",
      "train loss:0.210567072603\n",
      "train loss:0.135681551362\n",
      "train loss:0.192368508345\n",
      "train loss:0.119399592844\n",
      "train loss:0.0779356153912\n",
      "train loss:0.114822952918\n",
      "train loss:0.0745209005374\n",
      "train loss:0.0843948316976\n",
      "train loss:0.124095896269\n",
      "train loss:0.117175323091\n",
      "train loss:0.0938445787686\n",
      "train loss:0.286702320236\n",
      "train loss:0.114203353378\n",
      "train loss:0.104085175216\n",
      "train loss:0.146606479272\n",
      "train loss:0.133005954223\n",
      "train loss:0.0813014462004\n",
      "train loss:0.189317259526\n",
      "train loss:0.185801154243\n",
      "train loss:0.0580078226259\n",
      "train loss:0.082533297032\n",
      "train loss:0.0813558050316\n",
      "train loss:0.0432041159105\n",
      "train loss:0.0391223946541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0966513169651\n",
      "train loss:0.107132341746\n",
      "train loss:0.101334615624\n",
      "train loss:0.232162452183\n",
      "train loss:0.073205624353\n",
      "train loss:0.0987732374247\n",
      "train loss:0.0696021063618\n",
      "train loss:0.154184723147\n",
      "train loss:0.0429455570664\n",
      "train loss:0.0975227185958\n",
      "train loss:0.0472816530465\n",
      "train loss:0.0523910580187\n",
      "train loss:0.0664572954407\n",
      "train loss:0.150672444096\n",
      "train loss:0.0636971721359\n",
      "train loss:0.101014758119\n",
      "train loss:0.191071997139\n",
      "train loss:0.059638459658\n",
      "train loss:0.161911347342\n",
      "train loss:0.1226293994\n",
      "train loss:0.2216275944\n",
      "train loss:0.132167947643\n",
      "train loss:0.0993279988694\n",
      "train loss:0.0424454051398\n",
      "train loss:0.0987157555444\n",
      "train loss:0.0891415706367\n",
      "train loss:0.100274814935\n",
      "train loss:0.120874238816\n",
      "train loss:0.123216213597\n",
      "train loss:0.128377607318\n",
      "train loss:0.0793404770287\n",
      "train loss:0.0642617436143\n",
      "train loss:0.0704460946985\n",
      "train loss:0.109823997964\n",
      "train loss:0.0526296806596\n",
      "train loss:0.0879606911657\n",
      "train loss:0.116918542715\n",
      "train loss:0.0919871991213\n",
      "train loss:0.0526904509571\n",
      "train loss:0.0637098248454\n",
      "train loss:0.0523444481817\n",
      "train loss:0.090536057818\n",
      "train loss:0.0797793829877\n",
      "train loss:0.134126717198\n",
      "train loss:0.0917688608538\n",
      "train loss:0.0813023772008\n",
      "train loss:0.0890615331314\n",
      "train loss:0.0825335104128\n",
      "train loss:0.120641984655\n",
      "train loss:0.0916406549054\n",
      "train loss:0.101303112751\n",
      "train loss:0.105172203416\n",
      "train loss:0.0640561455087\n",
      "train loss:0.163656978837\n",
      "train loss:0.08187418666\n",
      "train loss:0.148671264311\n",
      "train loss:0.051149612885\n",
      "train loss:0.240859115938\n",
      "train loss:0.10708045848\n",
      "train loss:0.0534419397128\n",
      "train loss:0.0647283007949\n",
      "train loss:0.0561658648607\n",
      "train loss:0.0333368656492\n",
      "train loss:0.0816712595023\n",
      "train loss:0.0695660717021\n",
      "train loss:0.113285879617\n",
      "train loss:0.0909953208859\n",
      "train loss:0.0750196738048\n",
      "train loss:0.266488008956\n",
      "train loss:0.0682921795119\n",
      "train loss:0.133114582133\n",
      "train loss:0.0652320467514\n",
      "train loss:0.170794790047\n",
      "train loss:0.0452034590574\n",
      "train loss:0.187100065588\n",
      "train loss:0.0453738518537\n",
      "train loss:0.0448452379749\n",
      "train loss:0.0489044438642\n",
      "train loss:0.0580667776826\n",
      "train loss:0.139691549902\n",
      "train loss:0.113051345162\n",
      "train loss:0.110778894206\n",
      "train loss:0.141391207206\n",
      "train loss:0.0357500397219\n",
      "train loss:0.142248505147\n",
      "train loss:0.119964557037\n",
      "train loss:0.0676088497832\n",
      "train loss:0.155097238097\n",
      "train loss:0.080490630015\n",
      "train loss:0.0996282961423\n",
      "train loss:0.0368739886309\n",
      "train loss:0.1242369486\n",
      "train loss:0.103120674158\n",
      "train loss:0.0522078299079\n",
      "train loss:0.0343813454926\n",
      "train loss:0.104096262549\n",
      "train loss:0.103790123505\n",
      "train loss:0.035168045878\n",
      "train loss:0.0705667433707\n",
      "train loss:0.142068777695\n",
      "train loss:0.112458901942\n",
      "train loss:0.0349203934001\n",
      "train loss:0.121139666874\n",
      "train loss:0.12862894443\n",
      "train loss:0.101596312023\n",
      "train loss:0.0607716860762\n",
      "train loss:0.0994253732802\n",
      "train loss:0.0798556942554\n",
      "train loss:0.0541457029404\n",
      "train loss:0.0713242696653\n",
      "train loss:0.101656135662\n",
      "train loss:0.0789254754711\n",
      "train loss:0.0340431601859\n",
      "train loss:0.0447565381295\n",
      "train loss:0.0628326928654\n",
      "train loss:0.0830926645401\n",
      "train loss:0.0498243918434\n",
      "train loss:0.0858694985375\n",
      "train loss:0.0788865245428\n",
      "train loss:0.0922079000218\n",
      "train loss:0.158311497744\n",
      "train loss:0.101111922699\n",
      "train loss:0.0330097037668\n",
      "train loss:0.133557479368\n",
      "train loss:0.0748402504119\n",
      "train loss:0.0781298426442\n",
      "train loss:0.0276667452256\n",
      "train loss:0.0655027495408\n",
      "train loss:0.0544862921529\n",
      "train loss:0.0283619024062\n",
      "train loss:0.11578550854\n",
      "train loss:0.0638435474187\n",
      "train loss:0.0700007362899\n",
      "train loss:0.123926776822\n",
      "train loss:0.100069587782\n",
      "train loss:0.0422584250212\n",
      "train loss:0.0538905786838\n",
      "train loss:0.0940955676006\n",
      "train loss:0.135647818185\n",
      "train loss:0.105652010914\n",
      "train loss:0.0463377833494\n",
      "train loss:0.104766289194\n",
      "train loss:0.102335639251\n",
      "train loss:0.0860920699313\n",
      "train loss:0.197833339136\n",
      "train loss:0.0938852179821\n",
      "train loss:0.143721138575\n",
      "train loss:0.0403816222363\n",
      "train loss:0.0531447098657\n",
      "train loss:0.157806864214\n",
      "train loss:0.0286035492189\n",
      "train loss:0.060889450302\n",
      "train loss:0.0405260500383\n",
      "train loss:0.0808138918262\n",
      "train loss:0.0764852309172\n",
      "train loss:0.0965967513752\n",
      "train loss:0.0345556872465\n",
      "train loss:0.13698054864\n",
      "train loss:0.050101849114\n",
      "train loss:0.0603885928169\n",
      "train loss:0.0399252741003\n",
      "train loss:0.0659390583176\n",
      "train loss:0.100192377237\n",
      "train loss:0.0449499858001\n",
      "train loss:0.0736500567916\n",
      "train loss:0.10924278647\n",
      "train loss:0.0342073845053\n",
      "train loss:0.115745902113\n",
      "train loss:0.0247163164891\n",
      "train loss:0.0778628854969\n",
      "train loss:0.089253893938\n",
      "train loss:0.137905340989\n",
      "train loss:0.105729680748\n",
      "train loss:0.0417822689069\n",
      "train loss:0.0796326832043\n",
      "train loss:0.0829057120655\n",
      "train loss:0.0826768149257\n",
      "train loss:0.143146187288\n",
      "train loss:0.0590898837087\n",
      "train loss:0.0921323732243\n",
      "train loss:0.0424368913039\n",
      "train loss:0.143348700416\n",
      "train loss:0.0726241479247\n",
      "train loss:0.0782843125195\n",
      "train loss:0.0851738606975\n",
      "train loss:0.140237138758\n",
      "train loss:0.0263042409234\n",
      "train loss:0.0671327928349\n",
      "train loss:0.0396027805283\n",
      "train loss:0.071963643351\n",
      "train loss:0.106074835171\n",
      "train loss:0.144949452554\n",
      "train loss:0.133162977339\n",
      "train loss:0.198271596612\n",
      "train loss:0.11342827376\n",
      "train loss:0.0638510852842\n",
      "train loss:0.0856341026402\n",
      "train loss:0.0419633296058\n",
      "train loss:0.0997468162911\n",
      "train loss:0.0786618849903\n",
      "train loss:0.0593013677764\n",
      "train loss:0.127470136812\n",
      "train loss:0.0638299864698\n",
      "train loss:0.0981280942257\n",
      "train loss:0.0981030849662\n",
      "train loss:0.0866486654883\n",
      "train loss:0.0901126593823\n",
      "train loss:0.115022226737\n",
      "train loss:0.128523289749\n",
      "train loss:0.0738507855794\n",
      "train loss:0.0812663011789\n",
      "train loss:0.081070293735\n",
      "train loss:0.102500817658\n",
      "train loss:0.0404029972678\n",
      "train loss:0.0279112326304\n",
      "train loss:0.0662969825579\n",
      "train loss:0.035044194629\n",
      "train loss:0.076955535668\n",
      "train loss:0.0304621302507\n",
      "train loss:0.062789487156\n",
      "train loss:0.144477406321\n",
      "train loss:0.0269928713007\n",
      "train loss:0.039787818048\n",
      "train loss:0.0848091312206\n",
      "train loss:0.0686030950829\n",
      "train loss:0.0202143793526\n",
      "train loss:0.138881290941\n",
      "train loss:0.141656119296\n",
      "train loss:0.0973385679539\n",
      "train loss:0.0487224423841\n",
      "train loss:0.064601145961\n",
      "train loss:0.0429166358695\n",
      "train loss:0.0507819729934\n",
      "train loss:0.103664461107\n",
      "train loss:0.0895255914503\n",
      "train loss:0.064986021179\n",
      "train loss:0.0438018988886\n",
      "train loss:0.0303577235498\n",
      "train loss:0.0682400168304\n",
      "train loss:0.0374103394914\n",
      "train loss:0.0798745671042\n",
      "train loss:0.0363983907011\n",
      "train loss:0.108790854313\n",
      "train loss:0.0491837897829\n",
      "train loss:0.0542788107981\n",
      "train loss:0.100188479957\n",
      "train loss:0.0496983753054\n",
      "train loss:0.0417810854643\n",
      "train loss:0.0598086868292\n",
      "train loss:0.0273162719269\n",
      "train loss:0.0151327454335\n",
      "train loss:0.135228609229\n",
      "train loss:0.0569219098457\n",
      "train loss:0.0975695880895\n",
      "train loss:0.034108274\n",
      "train loss:0.121124556666\n",
      "train loss:0.0409839576417\n",
      "train loss:0.121484437923\n",
      "train loss:0.0831035656741\n",
      "train loss:0.0969310203992\n",
      "train loss:0.0464519342834\n",
      "train loss:0.0610881656723\n",
      "train loss:0.0369666557284\n",
      "train loss:0.103630247708\n",
      "train loss:0.0540483432598\n",
      "train loss:0.0945176525075\n",
      "train loss:0.0618901288677\n",
      "train loss:0.0641953366901\n",
      "train loss:0.112130391746\n",
      "train loss:0.0922058875892\n",
      "train loss:0.0400031390605\n",
      "train loss:0.105939947067\n",
      "train loss:0.0641550042497\n",
      "train loss:0.0755865261664\n",
      "train loss:0.092839428371\n",
      "train loss:0.100421497598\n",
      "train loss:0.14230441228\n",
      "train loss:0.0811506949025\n",
      "train loss:0.0727814486586\n",
      "train loss:0.155906542929\n",
      "train loss:0.0352663632833\n",
      "train loss:0.0296524594384\n",
      "train loss:0.0396734322989\n",
      "train loss:0.134165140632\n",
      "train loss:0.154461284821\n",
      "train loss:0.082864661668\n",
      "train loss:0.0880801886106\n",
      "train loss:0.11097329222\n",
      "train loss:0.0381590004296\n",
      "train loss:0.0501382054568\n",
      "train loss:0.0720400349294\n",
      "train loss:0.065982910363\n",
      "train loss:0.0665591544103\n",
      "train loss:0.0587210225872\n",
      "train loss:0.0915250914915\n",
      "train loss:0.0759639917261\n",
      "train loss:0.0843710607944\n",
      "train loss:0.175558333656\n",
      "train loss:0.0332000034296\n",
      "train loss:0.0744256959223\n",
      "train loss:0.0546611308009\n",
      "train loss:0.0819016834966\n",
      "train loss:0.0612929957332\n",
      "train loss:0.041446729392\n",
      "train loss:0.0199863406373\n",
      "train loss:0.0753924697493\n",
      "train loss:0.136870122969\n",
      "train loss:0.0411712507399\n",
      "train loss:0.0992037764369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.086662345017\n",
      "train loss:0.0383415839786\n",
      "train loss:0.130283875151\n",
      "train loss:0.0314460857308\n",
      "train loss:0.0544416475956\n",
      "train loss:0.106301049837\n",
      "train loss:0.0732475329261\n",
      "train loss:0.0534056486528\n",
      "train loss:0.0440004273862\n",
      "train loss:0.0677768463097\n",
      "train loss:0.0478028674061\n",
      "train loss:0.141632558268\n",
      "train loss:0.0350227159192\n",
      "train loss:0.0242941076585\n",
      "train loss:0.0556026693248\n",
      "train loss:0.0133629592659\n",
      "train loss:0.0319497697418\n",
      "train loss:0.0788925465566\n",
      "train loss:0.116892756662\n",
      "train loss:0.135615447853\n",
      "train loss:0.148619549408\n",
      "train loss:0.0668209686477\n",
      "train loss:0.0522488648812\n",
      "train loss:0.0555230662634\n",
      "train loss:0.053710627426\n",
      "train loss:0.0815354983249\n",
      "train loss:0.0142247998696\n",
      "train loss:0.0367602926152\n",
      "train loss:0.0798551914678\n",
      "train loss:0.0876333922547\n",
      "train loss:0.140060359466\n",
      "train loss:0.0511424398368\n",
      "train loss:0.0776431332295\n",
      "train loss:0.0926996693191\n",
      "train loss:0.0845359921443\n",
      "train loss:0.0741222937669\n",
      "train loss:0.0702679192843\n",
      "train loss:0.0387864076859\n",
      "train loss:0.0752017997689\n",
      "train loss:0.0762351943435\n",
      "train loss:0.0236370811465\n",
      "train loss:0.0513389642879\n",
      "train loss:0.171022098588\n",
      "train loss:0.102853192992\n",
      "train loss:0.0617395256072\n",
      "train loss:0.0871830769939\n",
      "train loss:0.0335055045555\n",
      "train loss:0.0365672672178\n",
      "train loss:0.0127130102658\n",
      "train loss:0.0537155057093\n",
      "train loss:0.0928846236669\n",
      "train loss:0.121016984337\n",
      "train loss:0.0610722508776\n",
      "train loss:0.0483936980282\n",
      "train loss:0.118716956097\n",
      "train loss:0.157184617416\n",
      "train loss:0.0408541808779\n",
      "train loss:0.0115626594417\n",
      "train loss:0.071763387302\n",
      "train loss:0.094657436915\n",
      "train loss:0.107025205647\n",
      "train loss:0.0833667866677\n",
      "train loss:0.0552701529805\n",
      "train loss:0.0286273429819\n",
      "train loss:0.0333147143725\n",
      "train loss:0.0513217032727\n",
      "train loss:0.0834733841459\n",
      "train loss:0.126679388659\n",
      "train loss:0.194266287464\n",
      "train loss:0.0784272165852\n",
      "train loss:0.0814551681265\n",
      "train loss:0.0511856170969\n",
      "train loss:0.0610799524082\n",
      "train loss:0.0435395196639\n",
      "train loss:0.0634835423321\n",
      "train loss:0.0875694734509\n",
      "train loss:0.0879640961361\n",
      "train loss:0.0475606241154\n",
      "train loss:0.152444667451\n",
      "train loss:0.15523632103\n",
      "train loss:0.0607180984784\n",
      "train loss:0.0420394010651\n",
      "train loss:0.0891840817463\n",
      "train loss:0.111923655022\n",
      "train loss:0.0671576263832\n",
      "train loss:0.0649220029521\n",
      "train loss:0.0689308990345\n",
      "train loss:0.0545464846261\n",
      "train loss:0.0739879212775\n",
      "train loss:0.0236506599836\n",
      "train loss:0.0239184866626\n",
      "train loss:0.0839474430197\n",
      "train loss:0.0463273856253\n",
      "train loss:0.167476594244\n",
      "train loss:0.0926675986593\n",
      "train loss:0.061609262039\n",
      "train loss:0.0299666328266\n",
      "train loss:0.0938362320819\n",
      "train loss:0.0467548619399\n",
      "train loss:0.0351496341225\n",
      "train loss:0.0288484537628\n",
      "train loss:0.0827957543746\n",
      "train loss:0.0480758373742\n",
      "train loss:0.0637692655961\n",
      "train loss:0.10364874343\n",
      "train loss:0.0950209680702\n",
      "train loss:0.122934613769\n",
      "train loss:0.0270793660654\n",
      "train loss:0.0964680869194\n",
      "train loss:0.0751584149946\n",
      "train loss:0.0618853718172\n",
      "train loss:0.0295911282952\n",
      "train loss:0.0636506801469\n",
      "train loss:0.0550679206172\n",
      "train loss:0.0538387314041\n",
      "train loss:0.146769709557\n",
      "train loss:0.18054588503\n",
      "train loss:0.0605614353324\n",
      "train loss:0.0316803974532\n",
      "train loss:0.0876062588891\n",
      "train loss:0.100508150969\n",
      "train loss:0.0752264033772\n",
      "train loss:0.017770881029\n",
      "train loss:0.110093302204\n",
      "train loss:0.202336889282\n",
      "train loss:0.042494941184\n",
      "train loss:0.0927318498523\n",
      "train loss:0.0377620099962\n",
      "train loss:0.0363012661612\n",
      "train loss:0.0592390933366\n",
      "train loss:0.035826322235\n",
      "train loss:0.0533356340651\n",
      "train loss:0.0796733910622\n",
      "train loss:0.018736007031\n",
      "train loss:0.0692746959581\n",
      "train loss:0.102528861607\n",
      "train loss:0.0751726748015\n",
      "train loss:0.0588118849259\n",
      "train loss:0.0280750452798\n",
      "train loss:0.0195653072122\n",
      "train loss:0.241596148003\n",
      "train loss:0.058027082396\n",
      "train loss:0.121008849441\n",
      "train loss:0.0294117405887\n",
      "train loss:0.0873699088368\n",
      "train loss:0.0371573872117\n",
      "train loss:0.0401159511685\n",
      "train loss:0.0755519108629\n",
      "train loss:0.0199151518547\n",
      "train loss:0.0268383045803\n",
      "train loss:0.114743637318\n",
      "train loss:0.0198611667057\n",
      "train loss:0.0848763539305\n",
      "train loss:0.0484398443475\n",
      "train loss:0.0654459910814\n",
      "train loss:0.0591907569612\n",
      "train loss:0.0552610354325\n",
      "train loss:0.102320073741\n",
      "train loss:0.0371023021492\n",
      "train loss:0.0713926901171\n",
      "train loss:0.0547150281592\n",
      "train loss:0.0260692297371\n",
      "train loss:0.0441214247806\n",
      "train loss:0.126005548784\n",
      "train loss:0.0568801172157\n",
      "train loss:0.0637459496379\n",
      "train loss:0.0243233336944\n",
      "train loss:0.0139247297869\n",
      "train loss:0.0464757673223\n",
      "train loss:0.095440549149\n",
      "train loss:0.0818877566782\n",
      "train loss:0.0528614522866\n",
      "train loss:0.0629523669453\n",
      "train loss:0.0407386215129\n",
      "train loss:0.104872975871\n",
      "train loss:0.0486971103389\n",
      "train loss:0.0350814484718\n",
      "train loss:0.0507837650757\n",
      "train loss:0.0781561723372\n",
      "train loss:0.0724172105682\n",
      "train loss:0.0502446025383\n",
      "train loss:0.0474139832848\n",
      "train loss:0.023668957588\n",
      "train loss:0.045995892005\n",
      "train loss:0.0821103581309\n",
      "train loss:0.0538429041151\n",
      "train loss:0.0418547138835\n",
      "train loss:0.0248150576175\n",
      "train loss:0.02222748429\n",
      "train loss:0.0303075627423\n",
      "train loss:0.0541216669007\n",
      "train loss:0.0648516551855\n",
      "train loss:0.0123613474617\n",
      "train loss:0.0174137255132\n",
      "train loss:0.0678121676845\n",
      "train loss:0.0352666536084\n",
      "train loss:0.130056061502\n",
      "train loss:0.0231840389863\n",
      "train loss:0.0906136251813\n",
      "train loss:0.106506990478\n",
      "train loss:0.122394442007\n",
      "train loss:0.029294055285\n",
      "train loss:0.0340858357441\n",
      "train loss:0.0149027443119\n",
      "train loss:0.0332424066967\n",
      "train loss:0.0962693142807\n",
      "train loss:0.0517579009147\n",
      "train loss:0.0390776837827\n",
      "train loss:0.0387724112249\n",
      "train loss:0.0338029596666\n",
      "train loss:0.0225986735999\n",
      "train loss:0.0302420904302\n",
      "train loss:0.0383631338613\n",
      "train loss:0.0738127506928\n",
      "train loss:0.0438436481478\n",
      "train loss:0.0420798293247\n",
      "train loss:0.0663281112468\n",
      "train loss:0.0774380471744\n",
      "train loss:0.051155975766\n",
      "train loss:0.0245978512102\n",
      "train loss:0.110639944316\n",
      "train loss:0.112572206803\n",
      "train loss:0.0159578969338\n",
      "train loss:0.065434199363\n",
      "train loss:0.0448639256147\n",
      "train loss:0.0235738340082\n",
      "train loss:0.141000614318\n",
      "train loss:0.0297126691479\n",
      "train loss:0.0610588425364\n",
      "train loss:0.0498516506273\n",
      "train loss:0.0207948421971\n",
      "train loss:0.0335086542425\n",
      "train loss:0.112990588598\n",
      "train loss:0.0302135406105\n",
      "train loss:0.0223001348294\n",
      "train loss:0.0529214730622\n",
      "train loss:0.0480216119226\n",
      "train loss:0.0212983831163\n",
      "train loss:0.022847411403\n",
      "train loss:0.0328966897052\n",
      "train loss:0.0360579315856\n",
      "train loss:0.0801368751289\n",
      "train loss:0.0540901735361\n",
      "train loss:0.0329548542309\n",
      "train loss:0.0250186052443\n",
      "train loss:0.0344991908978\n",
      "train loss:0.0685133982443\n",
      "train loss:0.0325809537052\n",
      "train loss:0.0250800231655\n",
      "train loss:0.0771720800488\n",
      "train loss:0.0183267973321\n",
      "train loss:0.0126215841589\n",
      "train loss:0.0387027545148\n",
      "train loss:0.0961265418142\n",
      "train loss:0.0776989423775\n",
      "train loss:0.0134452844021\n",
      "train loss:0.0209751224859\n",
      "train loss:0.029976729653\n",
      "train loss:0.0362902143041\n",
      "train loss:0.0404727659872\n",
      "train loss:0.0588487792423\n",
      "train loss:0.0210242871686\n",
      "train loss:0.0150033087611\n",
      "train loss:0.0443186734674\n",
      "=== epoch:3, train acc:0.976, test acc:0.976 ===\n",
      "train loss:0.0736411584291\n",
      "train loss:0.0399673749922\n",
      "train loss:0.0171584845687\n",
      "train loss:0.0539075044041\n",
      "train loss:0.0450193982175\n",
      "train loss:0.0823430371255\n",
      "train loss:0.104713838987\n",
      "train loss:0.0329936811465\n",
      "train loss:0.100877244875\n",
      "train loss:0.130676598452\n",
      "train loss:0.110200445485\n",
      "train loss:0.0688076397105\n",
      "train loss:0.0769876785517\n",
      "train loss:0.0100389612075\n",
      "train loss:0.0690648657804\n",
      "train loss:0.0503313458538\n",
      "train loss:0.0822178208882\n",
      "train loss:0.0156083939163\n",
      "train loss:0.163019636598\n",
      "train loss:0.0537588671366\n",
      "train loss:0.0521035745496\n",
      "train loss:0.0976388809331\n",
      "train loss:0.0627427280513\n",
      "train loss:0.0778090716516\n",
      "train loss:0.0426438972837\n",
      "train loss:0.0564898764015\n",
      "train loss:0.0443032969993\n",
      "train loss:0.0374636970126\n",
      "train loss:0.0714283199716\n",
      "train loss:0.0171575924611\n",
      "train loss:0.0193179755157\n",
      "train loss:0.0575548607958\n",
      "train loss:0.15705384401\n",
      "train loss:0.0670685651309\n",
      "train loss:0.0202351445043\n",
      "train loss:0.0830656179284\n",
      "train loss:0.08380108975\n",
      "train loss:0.0780225753783\n",
      "train loss:0.0676797486507\n",
      "train loss:0.0486967937372\n",
      "train loss:0.0500230374871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0140677587736\n",
      "train loss:0.0760943040871\n",
      "train loss:0.0487974484743\n",
      "train loss:0.0597810507037\n",
      "train loss:0.09728968058\n",
      "train loss:0.0517319021428\n",
      "train loss:0.0684254577032\n",
      "train loss:0.0545469225661\n",
      "train loss:0.119548434254\n",
      "train loss:0.0202668798776\n",
      "train loss:0.0644620055555\n",
      "train loss:0.0862493028834\n",
      "train loss:0.0684785480934\n",
      "train loss:0.102831802485\n",
      "train loss:0.0117449407398\n",
      "train loss:0.0464538188131\n",
      "train loss:0.0821749560939\n",
      "train loss:0.0372859593596\n",
      "train loss:0.0545827873177\n",
      "train loss:0.058310393084\n",
      "train loss:0.0551884464758\n",
      "train loss:0.0785567200748\n",
      "train loss:0.162321365475\n",
      "train loss:0.0248299076235\n",
      "train loss:0.0389826287061\n",
      "train loss:0.013833249521\n",
      "train loss:0.0304857437051\n",
      "train loss:0.0592724980379\n",
      "train loss:0.106435105177\n",
      "train loss:0.0434927154563\n",
      "train loss:0.0990108182521\n",
      "train loss:0.0192271075766\n",
      "train loss:0.0814568687369\n",
      "train loss:0.0454799366509\n",
      "train loss:0.0561210780638\n",
      "train loss:0.00995306753627\n",
      "train loss:0.0185533299172\n",
      "train loss:0.0296160809666\n",
      "train loss:0.0549194940313\n",
      "train loss:0.0502751052889\n",
      "train loss:0.0719209714263\n",
      "train loss:0.0248707556054\n",
      "train loss:0.0173013570914\n",
      "train loss:0.0748495301324\n",
      "train loss:0.165654078117\n",
      "train loss:0.058047818905\n",
      "train loss:0.0475065503863\n",
      "train loss:0.0341619982438\n",
      "train loss:0.0781606156463\n",
      "train loss:0.0505261760006\n",
      "train loss:0.0320625609208\n",
      "train loss:0.0458180846855\n",
      "train loss:0.0556687510033\n",
      "train loss:0.0580574176674\n",
      "train loss:0.0745538994782\n",
      "train loss:0.031669122076\n",
      "train loss:0.0285062771026\n",
      "train loss:0.017780229353\n",
      "train loss:0.063517248756\n",
      "train loss:0.0607970120604\n",
      "train loss:0.0331108410807\n",
      "train loss:0.0187546803098\n",
      "train loss:0.139566881119\n",
      "train loss:0.0655746703118\n",
      "train loss:0.033891727175\n",
      "train loss:0.0600091067413\n",
      "train loss:0.0886907130896\n",
      "train loss:0.0159967448804\n",
      "train loss:0.0190493606733\n",
      "train loss:0.0182793014425\n",
      "train loss:0.0418862113064\n",
      "train loss:0.166530009335\n",
      "train loss:0.132855173617\n",
      "train loss:0.0694479808423\n",
      "train loss:0.0759422720031\n",
      "train loss:0.109607313353\n",
      "train loss:0.0847950581543\n",
      "train loss:0.0491765010266\n",
      "train loss:0.0275555032566\n",
      "train loss:0.0345237221058\n",
      "train loss:0.0315070505367\n",
      "train loss:0.016581033138\n",
      "train loss:0.00859373346579\n",
      "train loss:0.0905712289565\n",
      "train loss:0.111971573106\n",
      "train loss:0.0571177620626\n",
      "train loss:0.0750591209202\n",
      "train loss:0.0531112648784\n",
      "train loss:0.165248024641\n",
      "train loss:0.0371740100095\n",
      "train loss:0.0351456367688\n",
      "train loss:0.0905992046547\n",
      "train loss:0.0339064684698\n",
      "train loss:0.179720447958\n",
      "train loss:0.0231571535858\n",
      "train loss:0.0498209480216\n",
      "train loss:0.0504098927533\n",
      "train loss:0.0121994119921\n",
      "train loss:0.0336272809602\n",
      "train loss:0.0101932783293\n",
      "train loss:0.0174835074146\n",
      "train loss:0.063491323794\n",
      "train loss:0.0215278841916\n",
      "train loss:0.0521601276603\n",
      "train loss:0.0304761194199\n",
      "train loss:0.0363015240666\n",
      "train loss:0.0886451763593\n",
      "train loss:0.149799742184\n",
      "train loss:0.057122288474\n",
      "train loss:0.0649529996351\n",
      "train loss:0.0886325813493\n",
      "train loss:0.0385017492441\n",
      "train loss:0.0664379139996\n",
      "train loss:0.0455027272686\n",
      "train loss:0.0487467969666\n",
      "train loss:0.0410774350431\n",
      "train loss:0.0570166758976\n",
      "train loss:0.0721508135814\n",
      "train loss:0.0463060254909\n",
      "train loss:0.0544559780072\n",
      "train loss:0.0500796674553\n",
      "train loss:0.0321613926301\n",
      "train loss:0.084003834811\n",
      "train loss:0.0222698961979\n",
      "train loss:0.0125861699127\n",
      "train loss:0.0153872620744\n",
      "train loss:0.0660262895719\n",
      "train loss:0.0203925295922\n",
      "train loss:0.0213481627619\n",
      "train loss:0.0610973597838\n",
      "train loss:0.0340747893734\n",
      "train loss:0.0396077592167\n",
      "train loss:0.0179488086398\n",
      "train loss:0.0357090353774\n",
      "train loss:0.0437942618304\n",
      "train loss:0.0197996382948\n",
      "train loss:0.0737441376857\n",
      "train loss:0.0583857719674\n",
      "train loss:0.058625533043\n",
      "train loss:0.0246375014838\n",
      "train loss:0.0215460054289\n",
      "train loss:0.0370425214389\n",
      "train loss:0.0480202527511\n",
      "train loss:0.0480280048502\n",
      "train loss:0.0685964817009\n",
      "train loss:0.0653083273672\n",
      "train loss:0.0266823456338\n",
      "train loss:0.0173828099811\n",
      "train loss:0.0233185691319\n",
      "train loss:0.0121971629854\n",
      "train loss:0.0467277847119\n",
      "train loss:0.044708466912\n",
      "train loss:0.0173670126608\n",
      "train loss:0.0270216901269\n",
      "train loss:0.121373673895\n",
      "train loss:0.0300966198593\n",
      "train loss:0.0370474082212\n",
      "train loss:0.144112430668\n",
      "train loss:0.0283995809427\n",
      "train loss:0.0442762103028\n",
      "train loss:0.125762392305\n",
      "train loss:0.0601739113246\n",
      "train loss:0.146927115258\n",
      "train loss:0.014051357771\n",
      "train loss:0.0268984100655\n",
      "train loss:0.0556438158915\n",
      "train loss:0.0699334071331\n",
      "train loss:0.0458064276917\n",
      "train loss:0.0585847025201\n",
      "train loss:0.0460437568756\n",
      "train loss:0.0329048690032\n",
      "train loss:0.177389099369\n",
      "train loss:0.0331031606286\n",
      "train loss:0.0584935012666\n",
      "train loss:0.0485009141938\n",
      "train loss:0.0327987768201\n",
      "train loss:0.00886620101327\n",
      "train loss:0.0168884977025\n",
      "train loss:0.0631014709988\n",
      "train loss:0.0232328919928\n",
      "train loss:0.0633427403587\n",
      "train loss:0.153591146759\n",
      "train loss:0.0884312738819\n",
      "train loss:0.0223953341333\n",
      "train loss:0.0368402560219\n",
      "train loss:0.0102704614421\n",
      "train loss:0.0234194615466\n",
      "train loss:0.206013654048\n",
      "train loss:0.0179425175541\n",
      "train loss:0.0236970482234\n",
      "train loss:0.0146581289624\n",
      "train loss:0.0117324730371\n",
      "train loss:0.0297015147224\n",
      "train loss:0.0239178900318\n",
      "train loss:0.106196008643\n",
      "train loss:0.0289398032905\n",
      "train loss:0.0161824198293\n",
      "train loss:0.0643019707904\n",
      "train loss:0.0610358361848\n",
      "train loss:0.0673335615781\n",
      "train loss:0.0432061805334\n",
      "train loss:0.0244445268188\n",
      "train loss:0.123688813383\n",
      "train loss:0.0470591482389\n",
      "train loss:0.0442412209773\n",
      "train loss:0.0251066652674\n",
      "train loss:0.00829530521999\n",
      "train loss:0.0147521632576\n",
      "train loss:0.0125347791021\n",
      "train loss:0.0442426394132\n",
      "train loss:0.0375212150468\n",
      "train loss:0.0549092299096\n",
      "train loss:0.0232622357973\n",
      "train loss:0.0187307957555\n",
      "train loss:0.0269216902648\n",
      "train loss:0.0442357213777\n",
      "train loss:0.0106833964068\n",
      "train loss:0.0227102831143\n",
      "train loss:0.085078646017\n",
      "train loss:0.153818268378\n",
      "train loss:0.0254438149104\n",
      "train loss:0.0340477549026\n",
      "train loss:0.0690305884229\n",
      "train loss:0.0310093573212\n",
      "train loss:0.0310960983629\n",
      "train loss:0.0263820685225\n",
      "train loss:0.0171887747713\n",
      "train loss:0.0209454932201\n",
      "train loss:0.0838586774032\n",
      "train loss:0.0573982146139\n",
      "train loss:0.0173338700618\n",
      "train loss:0.0238199400173\n",
      "train loss:0.0523837962144\n",
      "train loss:0.0174389075973\n",
      "train loss:0.180349995246\n",
      "train loss:0.093718430394\n",
      "train loss:0.0654782236447\n",
      "train loss:0.0477902515531\n",
      "train loss:0.0597612580921\n",
      "train loss:0.0517178477969\n",
      "train loss:0.0274026681855\n",
      "train loss:0.0403179141405\n",
      "train loss:0.0217360715601\n",
      "train loss:0.0250820423771\n",
      "train loss:0.0262886924315\n",
      "train loss:0.0596679443746\n",
      "train loss:0.0701560354989\n",
      "train loss:0.0773871291928\n",
      "train loss:0.0115912086368\n",
      "train loss:0.0320770327954\n",
      "train loss:0.043929508665\n",
      "train loss:0.0383654148681\n",
      "train loss:0.0857501030076\n",
      "train loss:0.110357207786\n",
      "train loss:0.04581657303\n",
      "train loss:0.0240043996565\n",
      "train loss:0.0482393653055\n",
      "train loss:0.0260802856394\n",
      "train loss:0.0219778043123\n",
      "train loss:0.023717743612\n",
      "train loss:0.0141076019382\n",
      "train loss:0.0993365297256\n",
      "train loss:0.0752539495381\n",
      "train loss:0.0299842300711\n",
      "train loss:0.0158204365791\n",
      "train loss:0.0356726597246\n",
      "train loss:0.05639772932\n",
      "train loss:0.139856665566\n",
      "train loss:0.0431922236357\n",
      "train loss:0.0346111099836\n",
      "train loss:0.0687946353094\n",
      "train loss:0.10734320008\n",
      "train loss:0.0263591539951\n",
      "train loss:0.124063176306\n",
      "train loss:0.0441775842117\n",
      "train loss:0.0306595151363\n",
      "train loss:0.102968922579\n",
      "train loss:0.0710426966995\n",
      "train loss:0.0717185937428\n",
      "train loss:0.0469238111232\n",
      "train loss:0.0685825253299\n",
      "train loss:0.0534584620144\n",
      "train loss:0.020670912766\n",
      "train loss:0.170938790203\n",
      "train loss:0.00632437784888\n",
      "train loss:0.0643840860439\n",
      "train loss:0.0339862549076\n",
      "train loss:0.0572118775139\n",
      "train loss:0.080350160077\n",
      "train loss:0.0419488492657\n",
      "train loss:0.0712066155902\n",
      "train loss:0.0547150258797\n",
      "train loss:0.0240507029308\n",
      "train loss:0.028862929216\n",
      "train loss:0.0379237243869\n",
      "train loss:0.0207232407087\n",
      "train loss:0.0477893499937\n",
      "train loss:0.0597399347345\n",
      "train loss:0.0204393296948\n",
      "train loss:0.0827973673067\n",
      "train loss:0.0526589062357\n",
      "train loss:0.0136004895048\n",
      "train loss:0.11184132978\n",
      "train loss:0.0358268961666\n",
      "train loss:0.0381053009587\n",
      "train loss:0.0434611796006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0343452096321\n",
      "train loss:0.0440036172914\n",
      "train loss:0.022106051105\n",
      "train loss:0.0329651883124\n",
      "train loss:0.0498363731325\n",
      "train loss:0.0184092652535\n",
      "train loss:0.0920491021498\n",
      "train loss:0.0165490390516\n",
      "train loss:0.0337501613278\n",
      "train loss:0.0600713212468\n",
      "train loss:0.0399745283849\n",
      "train loss:0.141202977895\n",
      "train loss:0.0656496910617\n",
      "train loss:0.0235124529538\n",
      "train loss:0.0726269249678\n",
      "train loss:0.0503749119081\n",
      "train loss:0.0172851408455\n",
      "train loss:0.0421797396638\n",
      "train loss:0.0680954088583\n",
      "train loss:0.0142427950391\n",
      "train loss:0.0233726779828\n",
      "train loss:0.0313417728458\n",
      "train loss:0.0378387693086\n",
      "train loss:0.0787935753059\n",
      "train loss:0.0543035110276\n",
      "train loss:0.0491907453612\n",
      "train loss:0.0258536705645\n",
      "train loss:0.105512493279\n",
      "train loss:0.0251191900988\n",
      "train loss:0.0282350860091\n",
      "train loss:0.0521257228342\n",
      "train loss:0.0427811991649\n",
      "train loss:0.0105840732892\n",
      "train loss:0.0349138291142\n",
      "train loss:0.084189399538\n",
      "train loss:0.0332336397303\n",
      "train loss:0.0630240348054\n",
      "train loss:0.0127607468625\n",
      "train loss:0.0232911632423\n",
      "train loss:0.0167716497829\n",
      "train loss:0.0376850117676\n",
      "train loss:0.0384747970997\n",
      "train loss:0.0181593812786\n",
      "train loss:0.0180863340181\n",
      "train loss:0.0492700385258\n",
      "train loss:0.0372461703122\n",
      "train loss:0.020476385542\n",
      "train loss:0.0215552659673\n",
      "train loss:0.0228424325485\n",
      "train loss:0.05052563484\n",
      "train loss:0.069660333085\n",
      "train loss:0.0919412637938\n",
      "train loss:0.0792119278261\n",
      "train loss:0.053355970244\n",
      "train loss:0.0923353109218\n",
      "train loss:0.0568807279342\n",
      "train loss:0.0237686611996\n",
      "train loss:0.124568320373\n",
      "train loss:0.0399224006404\n",
      "train loss:0.0312937209267\n",
      "train loss:0.028988720071\n",
      "train loss:0.0583891246451\n",
      "train loss:0.0351950782583\n",
      "train loss:0.0144752699829\n",
      "train loss:0.0233540591754\n",
      "train loss:0.0472680966343\n",
      "train loss:0.0195606559091\n",
      "train loss:0.0524631691258\n",
      "train loss:0.0356813575668\n",
      "train loss:0.0299187553505\n",
      "train loss:0.0649994415611\n",
      "train loss:0.0418297725507\n",
      "train loss:0.101377758107\n",
      "train loss:0.0239535917105\n",
      "train loss:0.0164185578681\n",
      "train loss:0.022356582169\n",
      "train loss:0.0549084238094\n",
      "train loss:0.0443744944851\n",
      "train loss:0.0539419904074\n",
      "train loss:0.0273485878668\n",
      "train loss:0.0121758909735\n",
      "train loss:0.0942457683459\n",
      "train loss:0.032930231532\n",
      "train loss:0.0526901138146\n",
      "train loss:0.0217618002992\n",
      "train loss:0.0230886042889\n",
      "train loss:0.0431710491647\n",
      "train loss:0.0125914734849\n",
      "train loss:0.0933897433817\n",
      "train loss:0.0522796748782\n",
      "train loss:0.055601044623\n",
      "train loss:0.00542176610575\n",
      "train loss:0.0152589291654\n",
      "train loss:0.00935242972406\n",
      "train loss:0.0632370706163\n",
      "train loss:0.0208350793319\n",
      "train loss:0.09389750562\n",
      "train loss:0.0370885145636\n",
      "train loss:0.112186322384\n",
      "train loss:0.0152600214178\n",
      "train loss:0.0236113121137\n",
      "train loss:0.0149545585109\n",
      "train loss:0.0243423358436\n",
      "train loss:0.0590241750545\n",
      "train loss:0.0356561326222\n",
      "train loss:0.0373074152776\n",
      "train loss:0.0740816672163\n",
      "train loss:0.0780378348919\n",
      "train loss:0.0203295972302\n",
      "train loss:0.0656469694354\n",
      "train loss:0.0428749405226\n",
      "train loss:0.0568480477166\n",
      "train loss:0.0232711965721\n",
      "train loss:0.00788030171385\n",
      "train loss:0.0203198954857\n",
      "train loss:0.0906651068304\n",
      "train loss:0.0067947409946\n",
      "train loss:0.0122064406345\n",
      "train loss:0.0299058957414\n",
      "train loss:0.026689541703\n",
      "train loss:0.0201340285617\n",
      "train loss:0.0752366699412\n",
      "train loss:0.0982470864681\n",
      "train loss:0.00730084868108\n",
      "train loss:0.0117769370896\n",
      "train loss:0.0194906284532\n",
      "train loss:0.0201434579523\n",
      "train loss:0.118839025426\n",
      "train loss:0.0404361079807\n",
      "train loss:0.0459321661335\n",
      "train loss:0.031853845056\n",
      "train loss:0.00934787305807\n",
      "train loss:0.0224397274226\n",
      "train loss:0.0117950308316\n",
      "train loss:0.0184290818324\n",
      "train loss:0.0183190469874\n",
      "train loss:0.015175757365\n",
      "train loss:0.0310302985592\n",
      "train loss:0.0268243817041\n",
      "train loss:0.0170523682521\n",
      "train loss:0.0278840843743\n",
      "train loss:0.0534534102335\n",
      "train loss:0.0427108869182\n",
      "train loss:0.0621314767844\n",
      "train loss:0.0116630513349\n",
      "train loss:0.0306199119153\n",
      "train loss:0.0316661857654\n",
      "train loss:0.0796678185292\n",
      "train loss:0.0287664607466\n",
      "train loss:0.0260266774269\n",
      "train loss:0.0360628659646\n",
      "train loss:0.0223435093932\n",
      "train loss:0.0436121878319\n",
      "train loss:0.0174996490297\n",
      "train loss:0.129713030449\n",
      "train loss:0.0531800627902\n",
      "train loss:0.0643941056645\n",
      "train loss:0.0216968744129\n",
      "train loss:0.0161915243041\n",
      "train loss:0.0745771485251\n",
      "train loss:0.046609653378\n",
      "train loss:0.0272581721225\n",
      "train loss:0.0410897014915\n",
      "train loss:0.0676823288142\n",
      "train loss:0.0512335140533\n",
      "train loss:0.0818380766882\n",
      "train loss:0.0665994962624\n",
      "train loss:0.00604781963127\n",
      "train loss:0.0150391652802\n",
      "train loss:0.0235226003964\n",
      "train loss:0.0958686212586\n",
      "train loss:0.0184581425086\n",
      "train loss:0.0189030084355\n",
      "train loss:0.0462564217775\n",
      "train loss:0.0151334696677\n",
      "train loss:0.0421322276371\n",
      "train loss:0.0423306866894\n",
      "train loss:0.0239171342797\n",
      "train loss:0.0164576900117\n",
      "train loss:0.0311655208521\n",
      "train loss:0.0568600488314\n",
      "train loss:0.0328006398268\n",
      "train loss:0.0379519038459\n",
      "train loss:0.0088478421477\n",
      "train loss:0.0520045763726\n",
      "train loss:0.0324215109351\n",
      "train loss:0.0215501656109\n",
      "train loss:0.0266729417009\n",
      "train loss:0.0151824238509\n",
      "train loss:0.0105912991166\n",
      "train loss:0.0138750796238\n",
      "train loss:0.207869216047\n",
      "train loss:0.0458912272334\n",
      "train loss:0.0255833510163\n",
      "train loss:0.0520829182076\n",
      "train loss:0.0263701903081\n",
      "train loss:0.0616456101216\n",
      "train loss:0.061598737524\n",
      "train loss:0.0237652906004\n",
      "train loss:0.031753588404\n",
      "train loss:0.0764854824441\n",
      "train loss:0.0287879078694\n",
      "train loss:0.0430977443219\n",
      "train loss:0.0379070298818\n",
      "train loss:0.148032751367\n",
      "train loss:0.0867421142214\n",
      "train loss:0.0965141260632\n",
      "train loss:0.0453406093182\n",
      "train loss:0.0215491878849\n",
      "train loss:0.17384247548\n",
      "train loss:0.0942808764989\n",
      "train loss:0.00928495733356\n",
      "train loss:0.0332253195912\n",
      "train loss:0.0595380912288\n",
      "train loss:0.125713373427\n",
      "train loss:0.0640166952456\n",
      "train loss:0.0316884644196\n",
      "train loss:0.0347891604811\n",
      "train loss:0.0362278589201\n",
      "train loss:0.0672132456373\n",
      "train loss:0.144987693322\n",
      "train loss:0.0762504864658\n",
      "train loss:0.0745964402746\n",
      "train loss:0.0188862445103\n",
      "train loss:0.0195162583091\n",
      "train loss:0.0153387601239\n",
      "train loss:0.0756046121058\n",
      "train loss:0.0430476884391\n",
      "train loss:0.0156372970255\n",
      "train loss:0.0254619726053\n",
      "train loss:0.0147430615366\n",
      "train loss:0.100235021525\n",
      "train loss:0.0171740670686\n",
      "train loss:0.0492449712736\n",
      "train loss:0.0354024670954\n",
      "train loss:0.0497916230687\n",
      "train loss:0.0290376731825\n",
      "train loss:0.0422919908446\n",
      "train loss:0.0225750490909\n",
      "train loss:0.068248678128\n",
      "train loss:0.00867805386248\n",
      "train loss:0.0110505637206\n",
      "train loss:0.057733410459\n",
      "train loss:0.0262312174589\n",
      "train loss:0.0490910819521\n",
      "train loss:0.0431678789982\n",
      "train loss:0.136292802414\n",
      "train loss:0.0302594000665\n",
      "train loss:0.0902599046657\n",
      "train loss:0.0685717731803\n",
      "train loss:0.0273919503625\n",
      "train loss:0.093640177879\n",
      "train loss:0.0203825978656\n",
      "=== epoch:4, train acc:0.982, test acc:0.981 ===\n",
      "train loss:0.0114658132293\n",
      "train loss:0.017283681363\n",
      "train loss:0.0193618807609\n",
      "train loss:0.10573358624\n",
      "train loss:0.0505572174715\n",
      "train loss:0.0371362230549\n",
      "train loss:0.140197826042\n",
      "train loss:0.0257456860828\n",
      "train loss:0.0523414360568\n",
      "train loss:0.026741214318\n",
      "train loss:0.0531653101063\n",
      "train loss:0.039757213793\n",
      "train loss:0.0211189513913\n",
      "train loss:0.0243810203757\n",
      "train loss:0.0217420179681\n",
      "train loss:0.0310728696477\n",
      "train loss:0.0220140951105\n",
      "train loss:0.0284534038181\n",
      "train loss:0.0222532680464\n",
      "train loss:0.0393630855436\n",
      "train loss:0.129854587959\n",
      "train loss:0.0292247447493\n",
      "train loss:0.0144457309077\n",
      "train loss:0.00870733933935\n",
      "train loss:0.0573227817437\n",
      "train loss:0.0707459136056\n",
      "train loss:0.0207915458409\n",
      "train loss:0.0662872018689\n",
      "train loss:0.0663753066706\n",
      "train loss:0.0280970192838\n",
      "train loss:0.054486969005\n",
      "train loss:0.027053102936\n",
      "train loss:0.0289360583379\n",
      "train loss:0.0511531190431\n",
      "train loss:0.138049825975\n",
      "train loss:0.0500200023931\n",
      "train loss:0.0311071553827\n",
      "train loss:0.0633770102082\n",
      "train loss:0.0474771464193\n",
      "train loss:0.0119727439189\n",
      "train loss:0.0154204531199\n",
      "train loss:0.0108208535482\n",
      "train loss:0.0251135785691\n",
      "train loss:0.0809407347359\n",
      "train loss:0.065053615776\n",
      "train loss:0.0174615900219\n",
      "train loss:0.121536237189\n",
      "train loss:0.00518546556519\n",
      "train loss:0.0647163068908\n",
      "train loss:0.0576794113134\n",
      "train loss:0.07413864236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0137715459766\n",
      "train loss:0.0292482620668\n",
      "train loss:0.021634852762\n",
      "train loss:0.0842644883661\n",
      "train loss:0.0424439948741\n",
      "train loss:0.0100771672929\n",
      "train loss:0.0432995904589\n",
      "train loss:0.0195773663655\n",
      "train loss:0.0229951703242\n",
      "train loss:0.0504503946427\n",
      "train loss:0.0589089433845\n",
      "train loss:0.105693582712\n",
      "train loss:0.0810127943574\n",
      "train loss:0.0315701251771\n",
      "train loss:0.0275058050266\n",
      "train loss:0.0177734895255\n",
      "train loss:0.0318631103369\n",
      "train loss:0.022294038805\n",
      "train loss:0.0309698070659\n",
      "train loss:0.0215887719609\n",
      "train loss:0.0253929074688\n",
      "train loss:0.0656142239684\n",
      "train loss:0.0160056747989\n",
      "train loss:0.00809246418951\n",
      "train loss:0.0164223617266\n",
      "train loss:0.0402638973523\n",
      "train loss:0.0193890427915\n",
      "train loss:0.0592562050812\n",
      "train loss:0.029883169379\n",
      "train loss:0.0746581953444\n",
      "train loss:0.020298808358\n",
      "train loss:0.0696484021136\n",
      "train loss:0.031930728359\n",
      "train loss:0.0297411669672\n",
      "train loss:0.0321766783786\n",
      "train loss:0.0261608252801\n",
      "train loss:0.0385648853084\n",
      "train loss:0.0196178551654\n",
      "train loss:0.0395281128652\n",
      "train loss:0.0249274271736\n",
      "train loss:0.033294365739\n",
      "train loss:0.0485832492057\n",
      "train loss:0.014761276367\n",
      "train loss:0.0661526823627\n",
      "train loss:0.0161428481669\n",
      "train loss:0.0275960873696\n",
      "train loss:0.0866186136643\n",
      "train loss:0.0145280006056\n",
      "train loss:0.0660505586826\n",
      "train loss:0.0500512865681\n",
      "train loss:0.017004310056\n",
      "train loss:0.0223658952108\n",
      "train loss:0.0108972076628\n",
      "train loss:0.0258698901411\n",
      "train loss:0.0928555667745\n",
      "train loss:0.0237108900267\n",
      "train loss:0.0281830348222\n",
      "train loss:0.0647432629982\n",
      "train loss:0.0644868223527\n",
      "train loss:0.0296030948606\n",
      "train loss:0.015843167372\n",
      "train loss:0.0172144514847\n",
      "train loss:0.0238765403602\n",
      "train loss:0.0238348427774\n",
      "train loss:0.00882269173277\n",
      "train loss:0.0308194279511\n",
      "train loss:0.038890418903\n",
      "train loss:0.0207837838705\n",
      "train loss:0.0248181801479\n",
      "train loss:0.0531991911064\n",
      "train loss:0.0847577087869\n",
      "train loss:0.110103022481\n",
      "train loss:0.0237517634181\n",
      "train loss:0.0511174769594\n",
      "train loss:0.0180600645069\n",
      "train loss:0.0279631517107\n",
      "train loss:0.0648076091689\n",
      "train loss:0.0921977874577\n",
      "train loss:0.0299754006618\n",
      "train loss:0.0546471521488\n",
      "train loss:0.160803848648\n",
      "train loss:0.164334402633\n",
      "train loss:0.0971142788835\n",
      "train loss:0.0658573337851\n",
      "train loss:0.0166802500801\n",
      "train loss:0.0483444372572\n",
      "train loss:0.137466844449\n",
      "train loss:0.0793307401591\n",
      "train loss:0.0339504812932\n",
      "train loss:0.0115617518651\n",
      "train loss:0.0484350918648\n",
      "train loss:0.0489977298157\n",
      "train loss:0.0278747104307\n",
      "train loss:0.0567154642532\n",
      "train loss:0.0615175690073\n",
      "train loss:0.0856251659564\n",
      "train loss:0.0428142550471\n",
      "train loss:0.0238753074913\n",
      "train loss:0.0174211556922\n",
      "train loss:0.0585340031008\n",
      "train loss:0.0488831174254\n",
      "train loss:0.0180835884\n",
      "train loss:0.0117600290098\n",
      "train loss:0.0178697956904\n",
      "train loss:0.0936303978436\n",
      "train loss:0.0238534927838\n",
      "train loss:0.0798236337949\n",
      "train loss:0.066125501453\n",
      "train loss:0.0298453213946\n",
      "train loss:0.0433760001637\n",
      "train loss:0.0261405977913\n",
      "train loss:0.0794918413277\n",
      "train loss:0.0143971060414\n",
      "train loss:0.0339675141053\n",
      "train loss:0.0265299888624\n",
      "train loss:0.0622747311772\n",
      "train loss:0.0235710839836\n",
      "train loss:0.0206763914704\n",
      "train loss:0.0153414546095\n",
      "train loss:0.0178097502774\n",
      "train loss:0.0272503636222\n",
      "train loss:0.0186876794911\n",
      "train loss:0.0505377914419\n",
      "train loss:0.0583616224673\n",
      "train loss:0.00592036054734\n",
      "train loss:0.047670708744\n",
      "train loss:0.0244386571013\n",
      "train loss:0.0161438035768\n",
      "train loss:0.0551081117164\n",
      "train loss:0.0134170075212\n",
      "train loss:0.0323782975645\n",
      "train loss:0.0206162830448\n",
      "train loss:0.0182243119987\n",
      "train loss:0.0111635853535\n",
      "train loss:0.0247550277269\n",
      "train loss:0.114283060246\n",
      "train loss:0.00977042174463\n",
      "train loss:0.019768984075\n",
      "train loss:0.0216955419732\n",
      "train loss:0.0441142240252\n",
      "train loss:0.0277415657401\n",
      "train loss:0.0126051370124\n",
      "train loss:0.0437716323733\n",
      "train loss:0.0294875921773\n",
      "train loss:0.023662953859\n",
      "train loss:0.029048507624\n",
      "train loss:0.0105041808977\n",
      "train loss:0.0147542682675\n",
      "train loss:0.0926786872255\n",
      "train loss:0.0610871515724\n",
      "train loss:0.0881773234128\n",
      "train loss:0.0869227208217\n",
      "train loss:0.030376355691\n",
      "train loss:0.0230919953131\n",
      "train loss:0.0275986734185\n",
      "train loss:0.0416832825786\n",
      "train loss:0.0302233261476\n",
      "train loss:0.0309748625559\n",
      "train loss:0.139614799294\n",
      "train loss:0.0476820636508\n",
      "train loss:0.0284025150627\n",
      "train loss:0.0481225422597\n",
      "train loss:0.0245170053879\n",
      "train loss:0.0364093864132\n",
      "train loss:0.0382863272775\n",
      "train loss:0.0643094185955\n",
      "train loss:0.0348793571937\n",
      "train loss:0.0254169058117\n",
      "train loss:0.029746573136\n",
      "train loss:0.0480455245031\n",
      "train loss:0.00982588489558\n",
      "train loss:0.0297674147352\n",
      "train loss:0.0189200381303\n",
      "train loss:0.0362153745853\n",
      "train loss:0.0160908811989\n",
      "train loss:0.0475703162682\n",
      "train loss:0.0705576283335\n",
      "train loss:0.0239072638894\n",
      "train loss:0.0407559805583\n",
      "train loss:0.0200941755703\n",
      "train loss:0.0255821564906\n",
      "train loss:0.023755772139\n",
      "train loss:0.0235843250911\n",
      "train loss:0.0430672695521\n",
      "train loss:0.0291033493025\n",
      "train loss:0.0547139711146\n",
      "train loss:0.0154176028391\n",
      "train loss:0.0579861686028\n",
      "train loss:0.0599314541488\n",
      "train loss:0.061683030666\n",
      "train loss:0.0315309393578\n",
      "train loss:0.0141487739414\n",
      "train loss:0.0426811835025\n",
      "train loss:0.0131414852605\n",
      "train loss:0.00652395165182\n",
      "train loss:0.0274270869887\n",
      "train loss:0.0154597833608\n",
      "train loss:0.00815894651539\n",
      "train loss:0.158275223519\n",
      "train loss:0.0127752439466\n",
      "train loss:0.0829963018383\n",
      "train loss:0.0273455516135\n",
      "train loss:0.0571219356774\n",
      "train loss:0.0157565655298\n",
      "train loss:0.0478128981447\n",
      "train loss:0.103822502802\n",
      "train loss:0.0443365921331\n",
      "train loss:0.0853139201464\n",
      "train loss:0.0821185027093\n",
      "train loss:0.0304006198741\n",
      "train loss:0.0268831766686\n",
      "train loss:0.0184871338534\n",
      "train loss:0.0277079719825\n",
      "train loss:0.0567061028589\n",
      "train loss:0.069036852504\n",
      "train loss:0.0348870916666\n",
      "train loss:0.0485434983688\n",
      "train loss:0.030550641434\n",
      "train loss:0.139030299089\n",
      "train loss:0.0321771312923\n",
      "train loss:0.0646957658475\n",
      "train loss:0.134208665567\n",
      "train loss:0.030718106391\n",
      "train loss:0.0685687941929\n",
      "train loss:0.0529633655406\n",
      "train loss:0.0549009705904\n",
      "train loss:0.0958218391714\n",
      "train loss:0.0304077040959\n",
      "train loss:0.0222516627349\n",
      "train loss:0.0035023754116\n",
      "train loss:0.014524598392\n",
      "train loss:0.0613663005805\n",
      "train loss:0.0459404298254\n",
      "train loss:0.0507019094504\n",
      "train loss:0.0391507659099\n",
      "train loss:0.127091170963\n",
      "train loss:0.0343152623549\n",
      "train loss:0.00653648476012\n",
      "train loss:0.00965542876988\n",
      "train loss:0.0231992028221\n",
      "train loss:0.122171390228\n",
      "train loss:0.0170238425109\n",
      "train loss:0.0324253302503\n",
      "train loss:0.0669101778663\n",
      "train loss:0.0278859805833\n",
      "train loss:0.0129868949226\n",
      "train loss:0.0404141381115\n",
      "train loss:0.057807305967\n",
      "train loss:0.0101814525407\n",
      "train loss:0.0100311775802\n",
      "train loss:0.0735956028982\n",
      "train loss:0.0171869208758\n",
      "train loss:0.098384849883\n",
      "train loss:0.0205502617384\n",
      "train loss:0.0485203893873\n",
      "train loss:0.047988240733\n",
      "train loss:0.0345432612347\n",
      "train loss:0.0707512737733\n",
      "train loss:0.0471668919519\n",
      "train loss:0.0859283074624\n",
      "train loss:0.0266638194896\n",
      "train loss:0.0403868006123\n",
      "train loss:0.034975564427\n",
      "train loss:0.0310923615076\n",
      "train loss:0.0467922343793\n",
      "train loss:0.0330733905986\n",
      "train loss:0.0494103837765\n",
      "train loss:0.0166754219892\n",
      "train loss:0.0125279644344\n",
      "train loss:0.0892786132074\n",
      "train loss:0.0288793984853\n",
      "train loss:0.0626042999192\n",
      "train loss:0.0258526061108\n",
      "train loss:0.0531722151287\n",
      "train loss:0.0268366602781\n",
      "train loss:0.0676845202933\n",
      "train loss:0.0333855766247\n",
      "train loss:0.025167587363\n",
      "train loss:0.045465152845\n",
      "train loss:0.0227519210861\n",
      "train loss:0.0232174153709\n",
      "train loss:0.0156760281756\n",
      "train loss:0.0262648414816\n",
      "train loss:0.0134279768865\n",
      "train loss:0.014173173146\n",
      "train loss:0.0311139065591\n",
      "train loss:0.023265779514\n",
      "train loss:0.0376094714378\n",
      "train loss:0.0422494909644\n",
      "train loss:0.102661313167\n",
      "train loss:0.0862125686342\n",
      "train loss:0.0133862738989\n",
      "train loss:0.0241402860188\n",
      "train loss:0.0398140087074\n",
      "train loss:0.0290889042037\n",
      "train loss:0.0280154579739\n",
      "train loss:0.00969851814439\n",
      "train loss:0.0479332788861\n",
      "train loss:0.0500361256796\n",
      "train loss:0.00538476666366\n",
      "train loss:0.0281054832831\n",
      "train loss:0.0156094790819\n",
      "train loss:0.0410301415602\n",
      "train loss:0.0430471174651\n",
      "train loss:0.0240720127534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0190614349927\n",
      "train loss:0.0146276885645\n",
      "train loss:0.0200485095175\n",
      "train loss:0.0453989199729\n",
      "train loss:0.0612668712753\n",
      "train loss:0.0367015963311\n",
      "train loss:0.0209499453042\n",
      "train loss:0.00398383888214\n",
      "train loss:0.023628487439\n",
      "train loss:0.00797132918317\n",
      "train loss:0.0551049232191\n",
      "train loss:0.0206915059756\n",
      "train loss:0.0809736990281\n",
      "train loss:0.0422975261159\n",
      "train loss:0.0307946220416\n",
      "train loss:0.0387549710213\n",
      "train loss:0.00950422144219\n",
      "train loss:0.0181681593363\n",
      "train loss:0.00637134731401\n",
      "train loss:0.0105789362672\n",
      "train loss:0.0457737925451\n",
      "train loss:0.0470970914443\n",
      "train loss:0.0222450081071\n",
      "train loss:0.0120911797869\n",
      "train loss:0.0703469421367\n",
      "train loss:0.0135589724376\n",
      "train loss:0.0274095361972\n",
      "train loss:0.0211667029481\n",
      "train loss:0.0342895570279\n",
      "train loss:0.0442736415407\n",
      "train loss:0.00987335484977\n",
      "train loss:0.012485236636\n",
      "train loss:0.0294288012712\n",
      "train loss:0.0377617024862\n",
      "train loss:0.0341159257404\n",
      "train loss:0.0090991958371\n",
      "train loss:0.0208042338519\n",
      "train loss:0.021805688257\n",
      "train loss:0.012982289213\n",
      "train loss:0.0124420905284\n",
      "train loss:0.0276464712134\n",
      "train loss:0.0310614634435\n",
      "train loss:0.0351163752987\n",
      "train loss:0.00812024491679\n",
      "train loss:0.01354703028\n",
      "train loss:0.00896543579208\n",
      "train loss:0.0119017315316\n",
      "train loss:0.0516518772679\n",
      "train loss:0.0282580942704\n",
      "train loss:0.0409602099694\n",
      "train loss:0.00961288324601\n",
      "train loss:0.028937741512\n",
      "train loss:0.0232190575151\n",
      "train loss:0.0108922622889\n",
      "train loss:0.00671198609006\n",
      "train loss:0.0165428274333\n",
      "train loss:0.0230342909093\n",
      "train loss:0.0120858768031\n",
      "train loss:0.0139431058851\n",
      "train loss:0.0561723472559\n",
      "train loss:0.0435214970004\n",
      "train loss:0.0365671064561\n",
      "train loss:0.121249389199\n",
      "train loss:0.0492373006492\n",
      "train loss:0.00847287009745\n",
      "train loss:0.0317682480272\n",
      "train loss:0.0146800980984\n",
      "train loss:0.0863318116642\n",
      "train loss:0.0762481261501\n",
      "train loss:0.0270193011404\n",
      "train loss:0.00537819050643\n",
      "train loss:0.098028288839\n",
      "train loss:0.0444709622632\n",
      "train loss:0.0249668130427\n",
      "train loss:0.0690209041655\n",
      "train loss:0.0727805624831\n",
      "train loss:0.0171591932172\n",
      "train loss:0.0257629017729\n",
      "train loss:0.0603884645282\n",
      "train loss:0.00878179656004\n",
      "train loss:0.0148339117075\n",
      "train loss:0.0224777742238\n",
      "train loss:0.0404937520193\n",
      "train loss:0.0247005116552\n",
      "train loss:0.0261294046146\n",
      "train loss:0.0233706842345\n",
      "train loss:0.0193766400287\n",
      "train loss:0.0145020224521\n",
      "train loss:0.0423728786906\n",
      "train loss:0.0173854934701\n",
      "train loss:0.0494944590653\n",
      "train loss:0.0090855640639\n",
      "train loss:0.0175655137165\n",
      "train loss:0.0831061637053\n",
      "train loss:0.0669248570296\n",
      "train loss:0.0166100746506\n",
      "train loss:0.0292279881408\n",
      "train loss:0.0118174306291\n",
      "train loss:0.0518189759015\n",
      "train loss:0.00959393483965\n",
      "train loss:0.0219167322114\n",
      "train loss:0.0231758370877\n",
      "train loss:0.00537911965807\n",
      "train loss:0.0257555031375\n",
      "train loss:0.018549738618\n",
      "train loss:0.038084321093\n",
      "train loss:0.0207665856236\n",
      "train loss:0.0114794174342\n",
      "train loss:0.0651682442245\n",
      "train loss:0.00915802358273\n",
      "train loss:0.0188123878119\n",
      "train loss:0.00912614718817\n",
      "train loss:0.00943122169394\n",
      "train loss:0.0103750094421\n",
      "train loss:0.0253701103131\n",
      "train loss:0.0118370226077\n",
      "train loss:0.0551421352649\n",
      "train loss:0.0173389663935\n",
      "train loss:0.0359498337892\n",
      "train loss:0.0319342784032\n",
      "train loss:0.0187128297208\n",
      "train loss:0.0258531309259\n",
      "train loss:0.0515431763575\n",
      "train loss:0.0452328340801\n",
      "train loss:0.0415436195987\n",
      "train loss:0.0182755538139\n",
      "train loss:0.0106418111093\n",
      "train loss:0.00657237794732\n",
      "train loss:0.0374316112938\n",
      "train loss:0.0156416659326\n",
      "train loss:0.0691869221261\n",
      "train loss:0.0308008384194\n",
      "train loss:0.0388655388851\n",
      "train loss:0.00671015848148\n",
      "train loss:0.0409910736952\n",
      "train loss:0.0132559934697\n",
      "train loss:0.0279580705929\n",
      "train loss:0.0156827187159\n",
      "train loss:0.0332419124136\n",
      "train loss:0.0408076920197\n",
      "train loss:0.0112340258934\n",
      "train loss:0.0035114132857\n",
      "train loss:0.0280125934043\n",
      "train loss:0.017087120394\n",
      "train loss:0.0100852325253\n",
      "train loss:0.0149471696395\n",
      "train loss:0.0417541575003\n",
      "train loss:0.0110477400805\n",
      "train loss:0.0602671886524\n",
      "train loss:0.00426621966445\n",
      "train loss:0.0642233660002\n",
      "train loss:0.0609763620741\n",
      "train loss:0.0281669594138\n",
      "train loss:0.0283232830859\n",
      "train loss:0.0184734277339\n",
      "train loss:0.0069240427885\n",
      "train loss:0.0181878095436\n",
      "train loss:0.0680620667065\n",
      "train loss:0.0676761730105\n",
      "train loss:0.0508970805973\n",
      "train loss:0.0216329541752\n",
      "train loss:0.0454351591252\n",
      "train loss:0.00449738657761\n",
      "train loss:0.0179464608666\n",
      "train loss:0.0158727592735\n",
      "train loss:0.0555602110092\n",
      "train loss:0.00940804302725\n",
      "train loss:0.0226987690466\n",
      "train loss:0.00527604564151\n",
      "train loss:0.0449995082837\n",
      "train loss:0.0408635264589\n",
      "train loss:0.0290675933625\n",
      "train loss:0.0195514206412\n",
      "train loss:0.0151170055367\n",
      "train loss:0.0072010174695\n",
      "train loss:0.0151833409157\n",
      "train loss:0.0152678420544\n",
      "train loss:0.0387630586683\n",
      "train loss:0.0199280318796\n",
      "train loss:0.0179645872175\n",
      "train loss:0.00601443733722\n",
      "train loss:0.0413088538962\n",
      "train loss:0.0245876931904\n",
      "train loss:0.0457825636427\n",
      "train loss:0.0578337269665\n",
      "train loss:0.00807423365024\n",
      "train loss:0.0462375894633\n",
      "train loss:0.0529468619864\n",
      "train loss:0.0726563124254\n",
      "train loss:0.00717085536145\n",
      "train loss:0.0101225176276\n",
      "train loss:0.0301318665673\n",
      "train loss:0.0198345281837\n",
      "train loss:0.0232750998016\n",
      "train loss:0.0157078961219\n",
      "train loss:0.00491704368655\n",
      "train loss:0.0664559360211\n",
      "train loss:0.0209821633335\n",
      "train loss:0.0822518242829\n",
      "train loss:0.042576701805\n",
      "train loss:0.01227393166\n",
      "train loss:0.00768393422203\n",
      "train loss:0.0320032714003\n",
      "train loss:0.0144063555617\n",
      "train loss:0.0287386025111\n",
      "train loss:0.00683698698456\n",
      "train loss:0.0177961873772\n",
      "train loss:0.0457421270907\n",
      "train loss:0.00794772297363\n",
      "train loss:0.00985710063023\n",
      "train loss:0.0142628505349\n",
      "train loss:0.074830858421\n",
      "train loss:0.0141472800585\n",
      "train loss:0.0610924365269\n",
      "train loss:0.0702982449098\n",
      "train loss:0.0203402030343\n",
      "train loss:0.0257448087602\n",
      "train loss:0.0130353342312\n",
      "train loss:0.0286843685361\n",
      "train loss:0.00199584948682\n",
      "train loss:0.0237494833129\n",
      "train loss:0.0731291201069\n",
      "train loss:0.0534135694991\n",
      "train loss:0.0501791032074\n",
      "train loss:0.00372273040606\n",
      "train loss:0.00965728075635\n",
      "train loss:0.0388480467572\n",
      "train loss:0.0461073670635\n",
      "train loss:0.0289670616931\n",
      "train loss:0.0274168034753\n",
      "train loss:0.0390337011861\n",
      "train loss:0.00407580281007\n",
      "train loss:0.0100183665657\n",
      "train loss:0.0165639323627\n",
      "train loss:0.027539910417\n",
      "train loss:0.0290737605001\n",
      "train loss:0.0314574790891\n",
      "train loss:0.0190428075574\n",
      "train loss:0.0141426724394\n",
      "train loss:0.064570769123\n",
      "train loss:0.0376951647921\n",
      "train loss:0.0198730675841\n",
      "train loss:0.0125845314996\n",
      "train loss:0.0353946665705\n",
      "=== epoch:5, train acc:0.985, test acc:0.983 ===\n",
      "train loss:0.00536331477866\n",
      "train loss:0.023251288421\n",
      "train loss:0.0125744809407\n",
      "train loss:0.035482585473\n",
      "train loss:0.0312404451237\n",
      "train loss:0.00606670392405\n",
      "train loss:0.0665227209395\n",
      "train loss:0.0413361836283\n",
      "train loss:0.055783363228\n",
      "train loss:0.0312298159016\n",
      "train loss:0.0476539598163\n",
      "train loss:0.128374017488\n",
      "train loss:0.0569030432654\n",
      "train loss:0.0266211864912\n",
      "train loss:0.0113842534307\n",
      "train loss:0.0301330236468\n",
      "train loss:0.0273470268226\n",
      "train loss:0.0325794672223\n",
      "train loss:0.0265113159957\n",
      "train loss:0.00900917457163\n",
      "train loss:0.0357319607926\n",
      "train loss:0.0133121707322\n",
      "train loss:0.0251714549379\n",
      "train loss:0.0121935157706\n",
      "train loss:0.037959237109\n",
      "train loss:0.0481141578829\n",
      "train loss:0.0184112287741\n",
      "train loss:0.0218469514693\n",
      "train loss:0.0040999209103\n",
      "train loss:0.0392416678712\n",
      "train loss:0.0773048550689\n",
      "train loss:0.0246985461163\n",
      "train loss:0.0421876905181\n",
      "train loss:0.0253531610116\n",
      "train loss:0.0668582604924\n",
      "train loss:0.0402594248889\n",
      "train loss:0.0349998586125\n",
      "train loss:0.0718369716616\n",
      "train loss:0.0259706080511\n",
      "train loss:0.0280698115314\n",
      "train loss:0.0157479421453\n",
      "train loss:0.310391394724\n",
      "train loss:0.0377951060175\n",
      "train loss:0.00669926189903\n",
      "train loss:0.0193536253311\n",
      "train loss:0.00501731212439\n",
      "train loss:0.0093548427643\n",
      "train loss:0.0155782938433\n",
      "train loss:0.042587781582\n",
      "train loss:0.020644075364\n",
      "train loss:0.0141771496111\n",
      "train loss:0.0230313556392\n",
      "train loss:0.0294677324952\n",
      "train loss:0.0486097209274\n",
      "train loss:0.048887566178\n",
      "train loss:0.0219888675774\n",
      "train loss:0.030203628838\n",
      "train loss:0.0199115902811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0209537653284\n",
      "train loss:0.0173092369398\n",
      "train loss:0.0479228808906\n",
      "train loss:0.0146668766919\n",
      "train loss:0.00550514215284\n",
      "train loss:0.0517347594398\n",
      "train loss:0.00741237438378\n",
      "train loss:0.0747071725385\n",
      "train loss:0.0342447294999\n",
      "train loss:0.0377906682759\n",
      "train loss:0.0124464056287\n",
      "train loss:0.021462626042\n",
      "train loss:0.0183527415541\n",
      "train loss:0.0122977920976\n",
      "train loss:0.125540944342\n",
      "train loss:0.04145985742\n",
      "train loss:0.0101457898708\n",
      "train loss:0.0193655943042\n",
      "train loss:0.0228192188466\n",
      "train loss:0.0237873845837\n",
      "train loss:0.100688221326\n",
      "train loss:0.00557456930024\n",
      "train loss:0.0152500771525\n",
      "train loss:0.0110907947129\n",
      "train loss:0.0246676293157\n",
      "train loss:0.0153798772105\n",
      "train loss:0.0132855720162\n",
      "train loss:0.0268906330041\n",
      "train loss:0.032182885049\n",
      "train loss:0.0598358131134\n",
      "train loss:0.0288850152262\n",
      "train loss:0.0210474182273\n",
      "train loss:0.0397481786969\n",
      "train loss:0.00959883210166\n",
      "train loss:0.132701620189\n",
      "train loss:0.156581571384\n",
      "train loss:0.0917081145095\n",
      "train loss:0.0364069924075\n",
      "train loss:0.0132076641849\n",
      "train loss:0.0211914623219\n",
      "train loss:0.066359632412\n",
      "train loss:0.0464056476381\n",
      "train loss:0.0128032963654\n",
      "train loss:0.0130231678847\n",
      "train loss:0.0169251790434\n",
      "train loss:0.01777144558\n",
      "train loss:0.0228329359054\n",
      "train loss:0.00557846976441\n",
      "train loss:0.0136868327407\n",
      "train loss:0.0196767736162\n",
      "train loss:0.012564840595\n",
      "train loss:0.00264505178945\n",
      "train loss:0.0233765925324\n",
      "train loss:0.0474748298667\n",
      "train loss:0.04754818131\n",
      "train loss:0.0258691388935\n",
      "train loss:0.0643629595538\n",
      "train loss:0.0330664049599\n",
      "train loss:0.0402319770434\n",
      "train loss:0.0442961499959\n",
      "train loss:0.0260595491234\n",
      "train loss:0.125724641347\n",
      "train loss:0.0146337615258\n",
      "train loss:0.028067850012\n",
      "train loss:0.0615899746447\n",
      "train loss:0.0180571148187\n",
      "train loss:0.0164806095896\n",
      "train loss:0.0270291205741\n",
      "train loss:0.0223669567082\n",
      "train loss:0.0219628198101\n",
      "train loss:0.0101787843378\n",
      "train loss:0.0403682472092\n",
      "train loss:0.0161817352325\n",
      "train loss:0.0192380862287\n",
      "train loss:0.0270100718014\n",
      "train loss:0.0372947907233\n",
      "train loss:0.0130289681933\n",
      "train loss:0.0552525187281\n",
      "train loss:0.0302833645385\n",
      "train loss:0.00544500306629\n",
      "train loss:0.0287017353456\n",
      "train loss:0.0195394781133\n",
      "train loss:0.0552091618962\n",
      "train loss:0.0110475011366\n",
      "train loss:0.0451688460094\n",
      "train loss:0.0795702620316\n",
      "train loss:0.0210370886745\n",
      "train loss:0.0362706126131\n",
      "train loss:0.0093970679908\n",
      "train loss:0.00651599563843\n",
      "train loss:0.00971817204288\n",
      "train loss:0.0177617466776\n",
      "train loss:0.0565081298855\n",
      "train loss:0.0429584525943\n",
      "train loss:0.0260381992214\n",
      "train loss:0.012792835294\n",
      "train loss:0.0322811754248\n",
      "train loss:0.0204048781959\n",
      "train loss:0.0122495665615\n",
      "train loss:0.0439900557666\n",
      "train loss:0.0102859863032\n",
      "train loss:0.0116905418356\n",
      "train loss:0.0688024679876\n",
      "train loss:0.0135257632759\n",
      "train loss:0.033940555552\n",
      "train loss:0.0345848054615\n",
      "train loss:0.0687229963712\n",
      "train loss:0.0569778032616\n",
      "train loss:0.115367714543\n",
      "train loss:0.042335559658\n",
      "train loss:0.00681830436167\n",
      "train loss:0.0169118746201\n",
      "train loss:0.00618015712308\n",
      "train loss:0.0268846932343\n",
      "train loss:0.00600265339988\n",
      "train loss:0.0807024260076\n",
      "train loss:0.0383339480158\n",
      "train loss:0.063021829564\n",
      "train loss:0.0364191329671\n",
      "train loss:0.00979525530528\n",
      "train loss:0.0166297448479\n",
      "train loss:0.029347930453\n",
      "train loss:0.00817024817712\n",
      "train loss:0.045435603481\n",
      "train loss:0.0215439125584\n",
      "train loss:0.00742983324375\n",
      "train loss:0.0226574906331\n",
      "train loss:0.0180760765543\n",
      "train loss:0.0209067970113\n",
      "train loss:0.0694912726696\n",
      "train loss:0.0100755003183\n",
      "train loss:0.0258591378199\n",
      "train loss:0.173526435043\n",
      "train loss:0.0751388485789\n",
      "train loss:0.082896304979\n",
      "train loss:0.0396526997004\n",
      "train loss:0.0180126462996\n",
      "train loss:0.0193891180739\n",
      "train loss:0.073792440277\n",
      "train loss:0.0136278431385\n",
      "train loss:0.0130998695781\n",
      "train loss:0.015651761581\n",
      "train loss:0.0259438464861\n",
      "train loss:0.0754308197975\n",
      "train loss:0.00488856666436\n",
      "train loss:0.0693753274484\n",
      "train loss:0.0212792192096\n",
      "train loss:0.0152997326955\n",
      "train loss:0.027837938303\n",
      "train loss:0.00482366827101\n",
      "train loss:0.00797804766307\n",
      "train loss:0.0173892325725\n",
      "train loss:0.00998208049363\n",
      "train loss:0.0567760825109\n",
      "train loss:0.00441083195301\n",
      "train loss:0.0140481322553\n",
      "train loss:0.0264428225616\n",
      "train loss:0.0135976970749\n",
      "train loss:0.0109825295274\n",
      "train loss:0.115025571023\n",
      "train loss:0.0523712554217\n",
      "train loss:0.0281347274519\n",
      "train loss:0.0507864498933\n",
      "train loss:0.0289075170492\n",
      "train loss:0.013704858361\n",
      "train loss:0.00824551490845\n",
      "train loss:0.0289569602582\n",
      "train loss:0.103916475195\n",
      "train loss:0.0326931385755\n",
      "train loss:0.0628324424037\n",
      "train loss:0.0265199704922\n",
      "train loss:0.00892485440546\n",
      "train loss:0.064747387583\n",
      "train loss:0.0388719547092\n",
      "train loss:0.0316740576282\n",
      "train loss:0.0107991828492\n",
      "train loss:0.0168313319971\n",
      "train loss:0.0107646451217\n",
      "train loss:0.0210198553476\n",
      "train loss:0.0234762580812\n",
      "train loss:0.0210584033849\n",
      "train loss:0.00918211010333\n",
      "train loss:0.0160666618883\n",
      "train loss:0.0246879993741\n",
      "train loss:0.0325041783626\n",
      "train loss:0.0154938450742\n",
      "train loss:0.0446200425956\n",
      "train loss:0.0360325996698\n",
      "train loss:0.00232042197372\n",
      "train loss:0.0664748863707\n",
      "train loss:0.0796322849427\n",
      "train loss:0.00579025822104\n",
      "train loss:0.0139763369308\n",
      "train loss:0.0119601702683\n",
      "train loss:0.0239896312486\n",
      "train loss:0.0153414093839\n",
      "train loss:0.0381349553317\n",
      "train loss:0.0155260866781\n",
      "train loss:0.0581521045477\n",
      "train loss:0.0286351293127\n",
      "train loss:0.0794217385878\n",
      "train loss:0.0201740830036\n",
      "train loss:0.116424605144\n",
      "train loss:0.01565498455\n",
      "train loss:0.0218412448558\n",
      "train loss:0.0124209386122\n",
      "train loss:0.0767184233248\n",
      "train loss:0.00872444201777\n",
      "train loss:0.0153533815998\n",
      "train loss:0.0243482131903\n",
      "train loss:0.060446761885\n",
      "train loss:0.0115574823798\n",
      "train loss:0.0191496701117\n",
      "train loss:0.0113964577783\n",
      "train loss:0.0383323066073\n",
      "train loss:0.0172748509179\n",
      "train loss:0.0605065427046\n",
      "train loss:0.0154626226534\n",
      "train loss:0.0138300129108\n",
      "train loss:0.00641188900251\n",
      "train loss:0.00895732973554\n",
      "train loss:0.131159240136\n",
      "train loss:0.0136416095736\n",
      "train loss:0.0196200469827\n",
      "train loss:0.0175950345507\n",
      "train loss:0.00504835004481\n",
      "train loss:0.00758081834567\n",
      "train loss:0.0135548706222\n",
      "train loss:0.0138154525336\n",
      "train loss:0.00721000125913\n",
      "train loss:0.121519580113\n",
      "train loss:0.0816844771224\n",
      "train loss:0.0216120162617\n",
      "train loss:0.0120161208647\n",
      "train loss:0.0193176078746\n",
      "train loss:0.00998148400531\n",
      "train loss:0.0786242005457\n",
      "train loss:0.00953781408248\n",
      "train loss:0.00678542290247\n",
      "train loss:0.0228767536266\n",
      "train loss:0.00421013750693\n",
      "train loss:0.027682377284\n",
      "train loss:0.0579682906807\n",
      "train loss:0.0475253335341\n",
      "train loss:0.015348776108\n",
      "train loss:0.0333904716613\n",
      "train loss:0.036344733323\n",
      "train loss:0.0202627938871\n",
      "train loss:0.0108876609237\n",
      "train loss:0.0567918956077\n",
      "train loss:0.00895687243343\n",
      "train loss:0.0367888524467\n",
      "train loss:0.00634648082688\n",
      "train loss:0.0314358506015\n",
      "train loss:0.0120505451659\n",
      "train loss:0.00622938892106\n",
      "train loss:0.0193856426261\n",
      "train loss:0.0549981065713\n",
      "train loss:0.0356382638382\n",
      "train loss:0.0634984989861\n",
      "train loss:0.0443554283758\n",
      "train loss:0.0579009955284\n",
      "train loss:0.0101969540602\n",
      "train loss:0.0522108777928\n",
      "train loss:0.0253121199811\n",
      "train loss:0.0128832314529\n",
      "train loss:0.045291659346\n",
      "train loss:0.0203535560357\n",
      "train loss:0.00511311397469\n",
      "train loss:0.0200728756587\n",
      "train loss:0.023715433368\n",
      "train loss:0.0333224142852\n",
      "train loss:0.0152883119159\n",
      "train loss:0.0422563919761\n",
      "train loss:0.0255724627207\n",
      "train loss:0.0589394527166\n",
      "train loss:0.0120878489766\n",
      "train loss:0.097754541937\n",
      "train loss:0.0973151457837\n",
      "train loss:0.0669902234748\n",
      "train loss:0.0523795365581\n",
      "train loss:0.0287047786639\n",
      "train loss:0.0106659228915\n",
      "train loss:0.165700772494\n",
      "train loss:0.0186889752496\n",
      "train loss:0.0291803980599\n",
      "train loss:0.0397170950224\n",
      "train loss:0.047560990982\n",
      "train loss:0.00859106787097\n",
      "train loss:0.0511136767533\n",
      "train loss:0.00788280130328\n",
      "train loss:0.030560137607\n",
      "train loss:0.108717526856\n",
      "train loss:0.0156044957743\n",
      "train loss:0.0442135868047\n",
      "train loss:0.0657539256351\n",
      "train loss:0.0492663310107\n",
      "train loss:0.0638088631351\n",
      "train loss:0.00324449602966\n",
      "train loss:0.0339873647584\n",
      "train loss:0.0978244707757\n",
      "train loss:0.0745420045614\n",
      "train loss:0.0384062023142\n",
      "train loss:0.0100681081178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0440065146526\n",
      "train loss:0.10826125075\n",
      "train loss:0.0331018740698\n",
      "train loss:0.00963159578001\n",
      "train loss:0.031209029907\n",
      "train loss:0.0204206783478\n",
      "train loss:0.0287883959555\n",
      "train loss:0.0242074954043\n",
      "train loss:0.0328989426266\n",
      "train loss:0.0169814451281\n",
      "train loss:0.0131340225675\n",
      "train loss:0.028786760702\n",
      "train loss:0.0139760375109\n",
      "train loss:0.034150201669\n",
      "train loss:0.0163009652764\n",
      "train loss:0.00358652178404\n",
      "train loss:0.0175405855794\n",
      "train loss:0.00808945048128\n",
      "train loss:0.00502564538783\n",
      "train loss:0.0174663107259\n",
      "train loss:0.02400232999\n",
      "train loss:0.0209120183777\n",
      "train loss:0.0119855667629\n",
      "train loss:0.0174195021458\n",
      "train loss:0.0514145735249\n",
      "train loss:0.0163447202187\n",
      "train loss:0.102022671617\n",
      "train loss:0.0397236872335\n",
      "train loss:0.0387485460677\n",
      "train loss:0.0365722580931\n",
      "train loss:0.00947222107493\n",
      "train loss:0.0105406731708\n",
      "train loss:0.0109274496643\n",
      "train loss:0.0108424752704\n",
      "train loss:0.00834323906386\n",
      "train loss:0.00487980331556\n",
      "train loss:0.0270197266417\n",
      "train loss:0.00488919457739\n",
      "train loss:0.0100466183375\n",
      "train loss:0.0281236841525\n",
      "train loss:0.036077827927\n",
      "train loss:0.0101362513993\n",
      "train loss:0.0116498542965\n",
      "train loss:0.00474830717024\n",
      "train loss:0.00826806903856\n",
      "train loss:0.0397754541892\n",
      "train loss:0.00356527720899\n",
      "train loss:0.00693236395381\n",
      "train loss:0.0402689922034\n",
      "train loss:0.00623355889955\n",
      "train loss:0.0255052182888\n",
      "train loss:0.00726945670847\n",
      "train loss:0.00252885523645\n",
      "train loss:0.0293691883454\n",
      "train loss:0.0163548290305\n",
      "train loss:0.00955131683395\n",
      "train loss:0.0103086929821\n",
      "train loss:0.0247013675281\n",
      "train loss:0.00235604440737\n",
      "train loss:0.0158830824638\n",
      "train loss:0.0128377633685\n",
      "train loss:0.00716525440781\n",
      "train loss:0.0523959723557\n",
      "train loss:0.011490425462\n",
      "train loss:0.0621352674\n",
      "train loss:0.00473635868665\n",
      "train loss:0.0439511175056\n",
      "train loss:0.00718613911055\n",
      "train loss:0.0130091693719\n",
      "train loss:0.0203770761036\n",
      "train loss:0.117630193362\n",
      "train loss:0.0651534765985\n",
      "train loss:0.0234426239805\n",
      "train loss:0.0144425761603\n",
      "train loss:0.0139886513392\n",
      "train loss:0.00765756581178\n",
      "train loss:0.0540605118545\n",
      "train loss:0.0162257654514\n",
      "train loss:0.0247370806936\n",
      "train loss:0.00336668464352\n",
      "train loss:0.031639796172\n",
      "train loss:0.0191197870165\n",
      "train loss:0.0237685761318\n",
      "train loss:0.00843243095365\n",
      "train loss:0.0190074149943\n",
      "train loss:0.0111177314831\n",
      "train loss:0.0239433193701\n",
      "train loss:0.0107323377796\n",
      "train loss:0.00706444754193\n",
      "train loss:0.00286437558833\n",
      "train loss:0.0635744058062\n",
      "train loss:0.00732448344434\n",
      "train loss:0.0631199118302\n",
      "train loss:0.0132365320415\n",
      "train loss:0.0225612275118\n",
      "train loss:0.00189033989554\n",
      "train loss:0.0082661101943\n",
      "train loss:0.0273722453567\n",
      "train loss:0.0742553956378\n",
      "train loss:0.0158488093168\n",
      "train loss:0.0405513631209\n",
      "train loss:0.0286456379762\n",
      "train loss:0.0560694333569\n",
      "train loss:0.0105093563859\n",
      "train loss:0.0159516417009\n",
      "train loss:0.0238728897268\n",
      "train loss:0.00765418727627\n",
      "train loss:0.00345998736771\n",
      "train loss:0.00803258372174\n",
      "train loss:0.0153152196444\n",
      "train loss:0.00595042290049\n",
      "train loss:0.0249226004757\n",
      "train loss:0.00146235852748\n",
      "train loss:0.0465891406541\n",
      "train loss:0.0181464596531\n",
      "train loss:0.00804736804354\n",
      "train loss:0.0196889708646\n",
      "train loss:0.00822337468434\n",
      "train loss:0.0120571074088\n",
      "train loss:0.0196097304366\n",
      "train loss:0.0242870521785\n",
      "train loss:0.0355152608316\n",
      "train loss:0.0195779437522\n",
      "train loss:0.00686932606137\n",
      "train loss:0.0396657480293\n",
      "train loss:0.00689033107863\n",
      "train loss:0.0359971663325\n",
      "train loss:0.0063712703835\n",
      "train loss:0.0297961804008\n",
      "train loss:0.0088618894917\n",
      "train loss:0.00667170368772\n",
      "train loss:0.0232144720008\n",
      "train loss:0.0039015576682\n",
      "train loss:0.0347242034019\n",
      "train loss:0.0166718481377\n",
      "train loss:0.0127661017725\n",
      "train loss:0.00690028243355\n",
      "train loss:0.019508714257\n",
      "train loss:0.0877396866605\n",
      "train loss:0.0160381331422\n",
      "train loss:0.00971662447199\n",
      "train loss:0.0801108233466\n",
      "train loss:0.0182927051896\n",
      "train loss:0.0141654106099\n",
      "train loss:0.0283816096209\n",
      "train loss:0.0634725883595\n",
      "train loss:0.0686706537163\n",
      "train loss:0.018066627012\n",
      "train loss:0.00987700923801\n",
      "train loss:0.0074715727688\n",
      "train loss:0.0220835373795\n",
      "train loss:0.00585152062528\n",
      "train loss:0.0120902849138\n",
      "train loss:0.00325236218609\n",
      "train loss:0.0137132762811\n",
      "train loss:0.0326447324089\n",
      "train loss:0.0113892314977\n",
      "train loss:0.021651976355\n",
      "train loss:0.0139406654212\n",
      "train loss:0.0200339606046\n",
      "train loss:0.0318350010375\n",
      "train loss:0.0336746090587\n",
      "train loss:0.0279511102009\n",
      "train loss:0.00350189540146\n",
      "train loss:0.00659986707265\n",
      "train loss:0.132434624183\n",
      "train loss:0.00895197436831\n",
      "train loss:0.0805399337382\n",
      "train loss:0.0225174226353\n",
      "train loss:0.071460093555\n",
      "train loss:0.0154898028494\n",
      "train loss:0.0435159626218\n",
      "train loss:0.0148815646327\n",
      "train loss:0.0198473540913\n",
      "train loss:0.0334544637895\n",
      "train loss:0.0139611931894\n",
      "train loss:0.0182188825465\n",
      "train loss:0.0263290625141\n",
      "train loss:0.0137328002397\n",
      "train loss:0.0321141787123\n",
      "train loss:0.0066260981385\n",
      "train loss:0.0168139826296\n",
      "train loss:0.0340937740533\n",
      "train loss:0.0210366956892\n",
      "train loss:0.00847097421686\n",
      "train loss:0.00839855791481\n",
      "train loss:0.0280599484619\n",
      "train loss:0.0777672026149\n",
      "train loss:0.0295663594912\n",
      "train loss:0.00849027737967\n",
      "train loss:0.00451727260966\n",
      "train loss:0.0275146024019\n",
      "train loss:0.0268694574804\n",
      "train loss:0.0387368779894\n",
      "train loss:0.0082932820814\n",
      "train loss:0.00668230051293\n",
      "train loss:0.0311732088364\n",
      "train loss:0.0210772377156\n",
      "train loss:0.00769773284216\n",
      "train loss:0.0309623931786\n",
      "train loss:0.0106499015752\n",
      "train loss:0.0157760487547\n",
      "train loss:0.00333564019146\n",
      "train loss:0.0197954206219\n",
      "train loss:0.0158394750918\n",
      "train loss:0.0785677612123\n",
      "train loss:0.00649717247371\n",
      "train loss:0.00770798443796\n",
      "train loss:0.0128278903136\n",
      "train loss:0.0285691656208\n",
      "train loss:0.00887476037248\n",
      "train loss:0.00227298099092\n",
      "train loss:0.0281744787156\n",
      "train loss:0.116765016883\n",
      "train loss:0.00556601885185\n",
      "train loss:0.0412964065722\n",
      "train loss:0.0303708562687\n",
      "train loss:0.0136473826703\n",
      "train loss:0.030222426852\n",
      "train loss:0.0360001976384\n",
      "train loss:0.00438566907257\n",
      "train loss:0.0301246627299\n",
      "train loss:0.00326981173585\n",
      "train loss:0.0231899141204\n",
      "train loss:0.0386939634087\n",
      "train loss:0.0195417397683\n",
      "train loss:0.0305106164434\n",
      "train loss:0.0286093869284\n",
      "train loss:0.0273883706233\n",
      "train loss:0.0784649860762\n",
      "train loss:0.0148689924912\n",
      "train loss:0.0322365233303\n",
      "train loss:0.00913947878436\n",
      "train loss:0.0374262346301\n",
      "train loss:0.0299215693281\n",
      "train loss:0.0143384919607\n",
      "train loss:0.0103987806196\n",
      "train loss:0.00956818703732\n",
      "=== epoch:6, train acc:0.985, test acc:0.986 ===\n",
      "train loss:0.00933690935872\n",
      "train loss:0.0121807084005\n",
      "train loss:0.0349680195613\n",
      "train loss:0.00922722525292\n",
      "train loss:0.0104521710938\n",
      "train loss:0.014364884104\n",
      "train loss:0.0102600414464\n",
      "train loss:0.0434654671549\n",
      "train loss:0.0118983912889\n",
      "train loss:0.054190230652\n",
      "train loss:0.00683620411653\n",
      "train loss:0.0293764102362\n",
      "train loss:0.00779492120527\n",
      "train loss:0.017169732489\n",
      "train loss:0.0181177065013\n",
      "train loss:0.0409857835579\n",
      "train loss:0.0115967302034\n",
      "train loss:0.0110353953717\n",
      "train loss:0.0121953354342\n",
      "train loss:0.00596682781731\n",
      "train loss:0.0341782573458\n",
      "train loss:0.0108052924711\n",
      "train loss:0.00587882031679\n",
      "train loss:0.0248646886956\n",
      "train loss:0.00878274200553\n",
      "train loss:0.0121233118702\n",
      "train loss:0.00743059871951\n",
      "train loss:0.0177696271132\n",
      "train loss:0.0300243601756\n",
      "train loss:0.0157841196258\n",
      "train loss:0.0085925700161\n",
      "train loss:0.0182372786227\n",
      "train loss:0.0614610356917\n",
      "train loss:0.0483962894662\n",
      "train loss:0.0417123886231\n",
      "train loss:0.0307173047072\n",
      "train loss:0.00818948472839\n",
      "train loss:0.0177226380408\n",
      "train loss:0.0112158831657\n",
      "train loss:0.0336015099698\n",
      "train loss:0.00567886261706\n",
      "train loss:0.00447229748186\n",
      "train loss:0.0187760152834\n",
      "train loss:0.00312874559053\n",
      "train loss:0.0142916482417\n",
      "train loss:0.0139282294558\n",
      "train loss:0.0215886195737\n",
      "train loss:0.019374354305\n",
      "train loss:0.0249826183878\n",
      "train loss:0.0400337996192\n",
      "train loss:0.00461934063379\n",
      "train loss:0.00821979777403\n",
      "train loss:0.00430628984777\n",
      "train loss:0.0644765390578\n",
      "train loss:0.0016549379539\n",
      "train loss:0.0524141058777\n",
      "train loss:0.0205594368654\n",
      "train loss:0.0118232658975\n",
      "train loss:0.00943645809772\n",
      "train loss:0.0160652295988\n",
      "train loss:0.0746734375734\n",
      "train loss:0.00634492614014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0544623131766\n",
      "train loss:0.00369689687477\n",
      "train loss:0.00976804715688\n",
      "train loss:0.00189490555817\n",
      "train loss:0.0105580836338\n",
      "train loss:0.00670897646617\n",
      "train loss:0.0111524597726\n",
      "train loss:0.00219520009096\n",
      "train loss:0.0130223848194\n",
      "train loss:0.00118603150672\n",
      "train loss:0.0139551178753\n",
      "train loss:0.0295014495897\n",
      "train loss:0.0457505322905\n",
      "train loss:0.0158996939613\n",
      "train loss:0.0203518404868\n",
      "train loss:0.00356739148578\n",
      "train loss:0.00780200613025\n",
      "train loss:0.0602697849631\n",
      "train loss:0.0352915447563\n",
      "train loss:0.00542580927329\n",
      "train loss:0.0325748064379\n",
      "train loss:0.0285584571706\n",
      "train loss:0.0370130359264\n",
      "train loss:0.00972040188661\n",
      "train loss:0.043426038625\n",
      "train loss:0.00672445954341\n",
      "train loss:0.0148163722373\n",
      "train loss:0.122277500321\n",
      "train loss:0.0404223612423\n",
      "train loss:0.0225665597004\n",
      "train loss:0.0079230905836\n",
      "train loss:0.0156084484602\n",
      "train loss:0.0160614885578\n",
      "train loss:0.0570722081184\n",
      "train loss:0.0275227198214\n",
      "train loss:0.0503551331289\n",
      "train loss:0.0111760476848\n",
      "train loss:0.0246120159033\n",
      "train loss:0.0040096247195\n",
      "train loss:0.0246992874095\n",
      "train loss:0.0202110188592\n",
      "train loss:0.0421326694636\n",
      "train loss:0.0473491686832\n",
      "train loss:0.012875127118\n",
      "train loss:0.00261754066851\n",
      "train loss:0.00666802303476\n",
      "train loss:0.00647631149766\n",
      "train loss:0.0219060007937\n",
      "train loss:0.0286629715439\n",
      "train loss:0.0935701753403\n",
      "train loss:0.0314932574269\n",
      "train loss:0.00358681728401\n",
      "train loss:0.0258461549676\n",
      "train loss:0.0392966835901\n",
      "train loss:0.018175960467\n",
      "train loss:0.0219136632971\n",
      "train loss:0.010872019653\n",
      "train loss:0.0272163952188\n",
      "train loss:0.0029451425117\n",
      "train loss:0.00564521172704\n",
      "train loss:0.101813437169\n",
      "train loss:0.0127613208014\n",
      "train loss:0.0106969289653\n",
      "train loss:0.00841878918223\n",
      "train loss:0.00796859385726\n",
      "train loss:0.0232184861953\n",
      "train loss:0.0126581311198\n",
      "train loss:0.029158055121\n",
      "train loss:0.027498394488\n",
      "train loss:0.00646757801518\n",
      "train loss:0.0107902473476\n",
      "train loss:0.0313003227519\n",
      "train loss:0.0317391989804\n",
      "train loss:0.00428491205508\n",
      "train loss:0.0325029739442\n",
      "train loss:0.109881772915\n",
      "train loss:0.00197420728834\n",
      "train loss:0.0229200437484\n",
      "train loss:0.0106565737331\n",
      "train loss:0.0215468719903\n",
      "train loss:0.00958902856838\n",
      "train loss:0.00636281254743\n",
      "train loss:0.00553043374076\n",
      "train loss:0.0241797217156\n",
      "train loss:0.00699883801726\n",
      "train loss:0.00415747677961\n",
      "train loss:0.0159490493725\n",
      "train loss:0.019574329115\n",
      "train loss:0.00889483128759\n",
      "train loss:0.0120423777826\n",
      "train loss:0.0160430330191\n",
      "train loss:0.0776983998621\n",
      "train loss:0.013636582838\n",
      "train loss:0.013575418684\n",
      "train loss:0.0106527509455\n",
      "train loss:0.0111291821119\n",
      "train loss:0.019827033331\n",
      "train loss:0.0112254628541\n",
      "train loss:0.0174312418566\n",
      "train loss:0.0188330052845\n",
      "train loss:0.0146787302229\n",
      "train loss:0.00454706775848\n",
      "train loss:0.0219414257774\n",
      "train loss:0.0351509548884\n",
      "train loss:0.0157945401481\n",
      "train loss:0.0381211758398\n",
      "train loss:0.0032038476478\n",
      "train loss:0.0164691955271\n",
      "train loss:0.068789682977\n",
      "train loss:0.0151605897249\n",
      "train loss:0.0429865754297\n",
      "train loss:0.0470612866698\n",
      "train loss:0.0296171010094\n",
      "train loss:0.032055429931\n",
      "train loss:0.0234268353192\n",
      "train loss:0.0291166420913\n",
      "train loss:0.011633118867\n",
      "train loss:0.00837843184685\n",
      "train loss:0.0195556029133\n",
      "train loss:0.060976417344\n",
      "train loss:0.0218207530308\n",
      "train loss:0.00721211913713\n",
      "train loss:0.0669785412751\n",
      "train loss:0.0144931095611\n",
      "train loss:0.0174987292361\n",
      "train loss:0.0127347021123\n",
      "train loss:0.0104522254212\n",
      "train loss:0.0220240660379\n",
      "train loss:0.0111546303074\n",
      "train loss:0.0323901256258\n",
      "train loss:0.012214412034\n",
      "train loss:0.0649060706343\n",
      "train loss:0.0978314155381\n",
      "train loss:0.0575895593074\n",
      "train loss:0.0060936921003\n",
      "train loss:0.0216182050115\n",
      "train loss:0.0269546095314\n",
      "train loss:0.0044294303555\n",
      "train loss:0.00630844881382\n",
      "train loss:0.00768776489819\n",
      "train loss:0.0750800309741\n",
      "train loss:0.167528617148\n",
      "train loss:0.0235576193594\n",
      "train loss:0.0112398833165\n",
      "train loss:0.0298241529001\n",
      "train loss:0.0115890703014\n",
      "train loss:0.0232437914576\n",
      "train loss:0.00327456387399\n",
      "train loss:0.00796217907992\n",
      "train loss:0.00748830209554\n",
      "train loss:0.0521548833372\n",
      "train loss:0.0628141529346\n",
      "train loss:0.011079139873\n",
      "train loss:0.0247256604542\n",
      "train loss:0.00847355905423\n",
      "train loss:0.0121639050581\n",
      "train loss:0.0130840325116\n",
      "train loss:0.0104170494286\n",
      "train loss:0.0773620226476\n",
      "train loss:0.011764648823\n",
      "train loss:0.0430032475949\n",
      "train loss:0.0197110361859\n",
      "train loss:0.00632736847312\n",
      "train loss:0.00257674783886\n",
      "train loss:0.0274894648729\n",
      "train loss:0.00830461220317\n",
      "train loss:0.00855897984652\n",
      "train loss:0.00897009642121\n",
      "train loss:0.0155101813247\n",
      "train loss:0.0124180326241\n",
      "train loss:0.0074764005485\n",
      "train loss:0.00808438488532\n",
      "train loss:0.00642525290984\n",
      "train loss:0.0191758590791\n",
      "train loss:0.0233839057197\n",
      "train loss:0.0116784438156\n",
      "train loss:0.0108305990956\n",
      "train loss:0.0151530192507\n",
      "train loss:0.0250843210316\n",
      "train loss:0.0155885426068\n",
      "train loss:0.0143436815265\n",
      "train loss:0.0189364278901\n",
      "train loss:0.0131114684578\n",
      "train loss:0.0260732073301\n",
      "train loss:0.0367528148475\n",
      "train loss:0.0295952157854\n",
      "train loss:0.0262097005105\n",
      "train loss:0.0183657848443\n",
      "train loss:0.0346826307917\n",
      "train loss:0.0162523470322\n",
      "train loss:0.0405334568221\n",
      "train loss:0.00918931554786\n",
      "train loss:0.0205771620877\n",
      "train loss:0.0196054713655\n",
      "train loss:0.0411764400602\n",
      "train loss:0.0398764183421\n",
      "train loss:0.0220052197953\n",
      "train loss:0.00854338767952\n",
      "train loss:0.0256562988862\n",
      "train loss:0.00964414299782\n",
      "train loss:0.0281220357424\n",
      "train loss:0.00824147480072\n",
      "train loss:0.0164679890717\n",
      "train loss:0.0221342357798\n",
      "train loss:0.0178891698518\n",
      "train loss:0.0622584054977\n",
      "train loss:0.0119109441483\n",
      "train loss:0.014175594549\n",
      "train loss:0.144215638027\n",
      "train loss:0.0182895089697\n",
      "train loss:0.01551233798\n",
      "train loss:0.128912512991\n",
      "train loss:0.00970857048186\n",
      "train loss:0.00560466188846\n",
      "train loss:0.0270736789017\n",
      "train loss:0.00823697132996\n",
      "train loss:0.0076729046424\n",
      "train loss:0.0487941344515\n",
      "train loss:0.0168967352385\n",
      "train loss:0.00814959300706\n",
      "train loss:0.00329834352846\n",
      "train loss:0.0114980239123\n",
      "train loss:0.00305247785832\n",
      "train loss:0.0248843285922\n",
      "train loss:0.00536801918486\n",
      "train loss:0.029515409545\n",
      "train loss:0.0178525387981\n",
      "train loss:0.0204970972945\n",
      "train loss:0.0428454488692\n",
      "train loss:0.0168230186023\n",
      "train loss:0.0041482957555\n",
      "train loss:0.0352091107005\n",
      "train loss:0.0133034157701\n",
      "train loss:0.00976832547189\n",
      "train loss:0.0452889070664\n",
      "train loss:0.0149654910276\n",
      "train loss:0.0123376728303\n",
      "train loss:0.0589108605225\n",
      "train loss:0.0245723625782\n",
      "train loss:0.0785462935489\n",
      "train loss:0.0121742468806\n",
      "train loss:0.0468180025297\n",
      "train loss:0.019741008809\n",
      "train loss:0.0527478060211\n",
      "train loss:0.0195399479672\n",
      "train loss:0.0178998348913\n",
      "train loss:0.0203424656139\n",
      "train loss:0.0256514614468\n",
      "train loss:0.0108355261477\n",
      "train loss:0.0178487003825\n",
      "train loss:0.0342040721643\n",
      "train loss:0.00680602166092\n",
      "train loss:0.049216612638\n",
      "train loss:0.019593713919\n",
      "train loss:0.0282200615293\n",
      "train loss:0.0150215860029\n",
      "train loss:0.0299662082732\n",
      "train loss:0.0126337421153\n",
      "train loss:0.1396181547\n",
      "train loss:0.0232334564181\n",
      "train loss:0.00471036228663\n",
      "train loss:0.0217468858385\n",
      "train loss:0.155027308334\n",
      "train loss:0.022272779404\n",
      "train loss:0.0138884418514\n",
      "train loss:0.0139983533181\n",
      "train loss:0.00607901816453\n",
      "train loss:0.0258630986908\n",
      "train loss:0.00565517106877\n",
      "train loss:0.024867390624\n",
      "train loss:0.00583960765298\n",
      "train loss:0.0163652664495\n",
      "train loss:0.0106221761412\n",
      "train loss:0.00960693833638\n",
      "train loss:0.00680097336269\n",
      "train loss:0.0182252066432\n",
      "train loss:0.00860868951261\n",
      "train loss:0.00991821751079\n",
      "train loss:0.0420037822627\n",
      "train loss:0.0185113892243\n",
      "train loss:0.0381619355097\n",
      "train loss:0.00552075590204\n",
      "train loss:0.00687479834481\n",
      "train loss:0.0284042350891\n",
      "train loss:0.0257252599687\n",
      "train loss:0.04519233374\n",
      "train loss:0.0175922988809\n",
      "train loss:0.00341419638241\n",
      "train loss:0.0526128603357\n",
      "train loss:0.00818475549478\n",
      "train loss:0.0202319594616\n",
      "train loss:0.0105376088697\n",
      "train loss:0.0102415545547\n",
      "train loss:0.0186154572783\n",
      "train loss:0.0121824013588\n",
      "train loss:0.00887312084579\n",
      "train loss:0.00654443639628\n",
      "train loss:0.00889930334372\n",
      "train loss:0.00532495095982\n",
      "train loss:0.00430247130175\n",
      "train loss:0.0248670868657\n",
      "train loss:0.0184028684472\n",
      "train loss:0.0128698799122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0583097901588\n",
      "train loss:0.0477981175302\n",
      "train loss:0.00993401001799\n",
      "train loss:0.0216286950774\n",
      "train loss:0.0222990395304\n",
      "train loss:0.00899865603543\n",
      "train loss:0.00890011664681\n",
      "train loss:0.00900541574931\n",
      "train loss:0.0176842587641\n",
      "train loss:0.0884982101644\n",
      "train loss:0.00675264399752\n",
      "train loss:0.027074253628\n",
      "train loss:0.00395942787666\n",
      "train loss:0.0430532391962\n",
      "train loss:0.0150547206935\n",
      "train loss:0.0185314654023\n",
      "train loss:0.0297560570227\n",
      "train loss:0.0487779085398\n",
      "train loss:0.0335913875079\n",
      "train loss:0.00790575828011\n",
      "train loss:0.0586742803094\n",
      "train loss:0.0529410028485\n",
      "train loss:0.00995865269727\n",
      "train loss:0.0122452420215\n",
      "train loss:0.0259620561067\n",
      "train loss:0.0232696253492\n",
      "train loss:0.0312888369198\n",
      "train loss:0.00689899246725\n",
      "train loss:0.0255126761363\n",
      "train loss:0.00643197082698\n",
      "train loss:0.00940745107772\n",
      "train loss:0.0155403160375\n",
      "train loss:0.035673851055\n",
      "train loss:0.0259390100056\n",
      "train loss:0.0141008481579\n",
      "train loss:0.00728441573569\n",
      "train loss:0.0310070700883\n",
      "train loss:0.0186266936154\n",
      "train loss:0.00813147791003\n",
      "train loss:0.0103944126258\n",
      "train loss:0.00562831653718\n",
      "train loss:0.000804042225595\n",
      "train loss:0.045823574204\n",
      "train loss:0.0433363214394\n",
      "train loss:0.0125354129777\n",
      "train loss:0.00356432706362\n",
      "train loss:0.0153199010817\n",
      "train loss:0.00462438340519\n",
      "train loss:0.0111117172382\n",
      "train loss:0.00724291391054\n",
      "train loss:0.0136660487074\n",
      "train loss:0.0119366092227\n",
      "train loss:0.0252045854733\n",
      "train loss:0.00528178625072\n",
      "train loss:0.0145744872765\n",
      "train loss:0.00721896838332\n",
      "train loss:0.0239618567293\n",
      "train loss:0.00662186663461\n",
      "train loss:0.00913934085935\n",
      "train loss:0.0154666406311\n",
      "train loss:0.0348376159037\n",
      "train loss:0.00599442473371\n",
      "train loss:0.00399785533201\n",
      "train loss:0.00882333725129\n",
      "train loss:0.0148644293597\n",
      "train loss:0.00645105572645\n",
      "train loss:0.0234797483458\n",
      "train loss:0.00283017859719\n",
      "train loss:0.00725782426262\n",
      "train loss:0.00336145603342\n",
      "train loss:0.00669737073877\n",
      "train loss:0.0388612327974\n",
      "train loss:0.00248991410711\n",
      "train loss:0.0158627833573\n",
      "train loss:0.00362941241709\n",
      "train loss:0.0188976257813\n",
      "train loss:0.017565872896\n",
      "train loss:0.0487234132884\n",
      "train loss:0.00701773248319\n",
      "train loss:0.00665041203894\n",
      "train loss:0.0312007216463\n",
      "train loss:0.00400175660953\n",
      "train loss:0.00947540469694\n",
      "train loss:0.00183526924833\n",
      "train loss:0.0158976142865\n",
      "train loss:0.033377125806\n",
      "train loss:0.0169215973306\n",
      "train loss:0.0233224513403\n",
      "train loss:0.0248824878905\n",
      "train loss:0.0112732429685\n",
      "train loss:0.0313894894706\n",
      "train loss:0.0244123571036\n",
      "train loss:0.0119510738893\n",
      "train loss:0.02976082304\n",
      "train loss:0.00920182951207\n",
      "train loss:0.00107744217643\n",
      "train loss:0.076267360834\n",
      "train loss:0.00799535804128\n",
      "train loss:0.00404218619329\n",
      "train loss:0.0227039248665\n",
      "train loss:0.0202688465079\n",
      "train loss:0.00705454545866\n",
      "train loss:0.0279943018444\n",
      "train loss:0.0232604495653\n",
      "train loss:0.00419419964495\n",
      "train loss:0.0158967176929\n",
      "train loss:0.0136424459934\n",
      "train loss:0.00980589708102\n",
      "train loss:0.016397263965\n",
      "train loss:0.0135516074773\n",
      "train loss:0.00668889969589\n",
      "train loss:0.0082490579332\n",
      "train loss:0.0507071469072\n",
      "train loss:0.0483841399276\n",
      "train loss:0.00459346259512\n",
      "train loss:0.0145503977536\n",
      "train loss:0.012067264809\n",
      "train loss:0.00444249690245\n",
      "train loss:0.0055196227601\n",
      "train loss:0.00305886937855\n",
      "train loss:0.0314236754205\n",
      "train loss:0.0186191747423\n",
      "train loss:0.0380050121274\n",
      "train loss:0.0427479298374\n",
      "train loss:0.0167374180029\n",
      "train loss:0.00631620654952\n",
      "train loss:0.0205465265179\n",
      "train loss:0.00535638523354\n",
      "train loss:0.0458375126429\n",
      "train loss:0.0218173234196\n",
      "train loss:0.00675698920286\n",
      "train loss:0.0290088172963\n",
      "train loss:0.0222895382665\n",
      "train loss:0.0018025629765\n",
      "train loss:0.0409009125293\n",
      "train loss:0.028598968827\n",
      "train loss:0.0224444699759\n",
      "train loss:0.0274112890971\n",
      "train loss:0.0118307684658\n",
      "train loss:0.00699512331131\n",
      "train loss:0.0105541343466\n",
      "train loss:0.0268495326172\n",
      "train loss:0.00291035819753\n",
      "train loss:0.00926558957317\n",
      "train loss:0.0121441682044\n",
      "train loss:0.0131423703002\n",
      "train loss:0.00336095194215\n",
      "train loss:0.00299565586647\n",
      "train loss:0.00690655567632\n",
      "train loss:0.00518053476761\n",
      "train loss:0.0141624298818\n",
      "train loss:0.0098464147424\n",
      "train loss:0.0190022232608\n",
      "train loss:0.00865732006498\n",
      "train loss:0.0257021469644\n",
      "train loss:0.00803018518351\n",
      "train loss:0.00671536904343\n",
      "train loss:0.0501857357252\n",
      "train loss:0.0462114962392\n",
      "train loss:0.000799619831401\n",
      "train loss:0.0174952500411\n",
      "train loss:0.018666842623\n",
      "train loss:0.00996235351667\n",
      "train loss:0.0167259009742\n",
      "train loss:0.036329971539\n",
      "train loss:0.013902149566\n",
      "train loss:0.0204881289324\n",
      "train loss:0.0629406465577\n",
      "train loss:0.0227719714198\n",
      "train loss:0.0178981871154\n",
      "train loss:0.00963225339572\n",
      "train loss:0.00955904434512\n",
      "train loss:0.0103342749191\n",
      "train loss:0.0167122573597\n",
      "train loss:0.00595037482543\n",
      "train loss:0.034147393644\n",
      "train loss:0.0116420319608\n",
      "train loss:0.0363186004748\n",
      "train loss:0.0119357918071\n",
      "train loss:0.00792963079228\n",
      "train loss:0.0102604177556\n",
      "train loss:0.0276464597687\n",
      "train loss:0.0566542602737\n",
      "train loss:0.0418765114815\n",
      "train loss:0.0500351401562\n",
      "train loss:0.031049700903\n",
      "train loss:0.0588350701109\n",
      "train loss:0.040041932972\n",
      "train loss:0.0167632505772\n",
      "train loss:0.00360630486042\n",
      "train loss:0.0526585029577\n",
      "train loss:0.0124047601212\n",
      "train loss:0.0447495019307\n",
      "train loss:0.0241400361108\n",
      "train loss:0.00568475938642\n",
      "train loss:0.011176003765\n",
      "train loss:0.00983089392542\n",
      "train loss:0.0393004397265\n",
      "train loss:0.0297940787723\n",
      "train loss:0.0143121743336\n",
      "train loss:0.0779984172908\n",
      "train loss:0.00420393713188\n",
      "train loss:0.0191683382849\n",
      "train loss:0.00523479857322\n",
      "train loss:0.0148425821643\n",
      "train loss:0.0260034468449\n",
      "train loss:0.0111545440743\n",
      "train loss:0.00937980773329\n",
      "train loss:0.0698661485533\n",
      "train loss:0.0651065954384\n",
      "train loss:0.0129506446099\n",
      "train loss:0.0124347838419\n",
      "train loss:0.0167757670243\n",
      "train loss:0.00317365968229\n",
      "train loss:0.0118118664786\n",
      "train loss:0.0153294874724\n",
      "train loss:0.00199261944174\n",
      "train loss:0.0483201629366\n",
      "train loss:0.0233301392401\n",
      "train loss:0.0120481525964\n",
      "train loss:0.0234833180687\n",
      "train loss:0.0179945232211\n",
      "train loss:0.0180648216337\n",
      "train loss:0.00315782130308\n",
      "train loss:0.0213933785666\n",
      "train loss:0.0107960304197\n",
      "train loss:0.0119420597398\n",
      "train loss:0.0087463669567\n",
      "train loss:0.0380693069071\n",
      "train loss:0.0130867492021\n",
      "train loss:0.0162153609009\n",
      "train loss:0.0293396704746\n",
      "train loss:0.0135581936755\n",
      "train loss:0.00815476754105\n",
      "train loss:0.00551481286005\n",
      "=== epoch:7, train acc:0.986, test acc:0.987 ===\n",
      "train loss:0.0112185549058\n",
      "train loss:0.0198041036078\n",
      "train loss:0.0513000834361\n",
      "train loss:0.0185831359432\n",
      "train loss:0.00294929530422\n",
      "train loss:0.0273721723128\n",
      "train loss:0.0203930195994\n",
      "train loss:0.00642039125734\n",
      "train loss:0.0867102568405\n",
      "train loss:0.0173388000294\n",
      "train loss:0.0350812626789\n",
      "train loss:0.0122370120667\n",
      "train loss:0.00339686552777\n",
      "train loss:0.00783672011867\n",
      "train loss:0.0101501861042\n",
      "train loss:0.0130099155737\n",
      "train loss:0.00874115805526\n",
      "train loss:0.0041658914866\n",
      "train loss:0.0366521159096\n",
      "train loss:0.0272882168881\n",
      "train loss:0.0283694323317\n",
      "train loss:0.00288751257933\n",
      "train loss:0.00383076799458\n",
      "train loss:0.0385195316765\n",
      "train loss:0.0196176027716\n",
      "train loss:0.00329766583072\n",
      "train loss:0.00764390842859\n",
      "train loss:0.00206637029769\n",
      "train loss:0.0296621796174\n",
      "train loss:0.0174009772026\n",
      "train loss:0.0109758016957\n",
      "train loss:0.0143797893186\n",
      "train loss:0.0667349005452\n",
      "train loss:0.0202892893222\n",
      "train loss:0.00909320005882\n",
      "train loss:0.0218037315414\n",
      "train loss:0.0013120579426\n",
      "train loss:0.00694673416884\n",
      "train loss:0.023377903813\n",
      "train loss:0.00847104036223\n",
      "train loss:0.0219365016101\n",
      "train loss:0.00363664157987\n",
      "train loss:0.0137001935167\n",
      "train loss:0.00413662095312\n",
      "train loss:0.0461118099171\n",
      "train loss:0.0349686067264\n",
      "train loss:0.0101054151669\n",
      "train loss:0.00359288130885\n",
      "train loss:0.00739345487458\n",
      "train loss:0.00483158226026\n",
      "train loss:0.0481727634566\n",
      "train loss:0.00496989928042\n",
      "train loss:0.0125179281824\n",
      "train loss:0.00989432539697\n",
      "train loss:0.0167863184269\n",
      "train loss:0.0141633868696\n",
      "train loss:0.0525193827462\n",
      "train loss:0.0061637173972\n",
      "train loss:0.00705774746133\n",
      "train loss:0.0148423218967\n",
      "train loss:0.00213159381656\n",
      "train loss:0.0143740019501\n",
      "train loss:0.00897466284772\n",
      "train loss:0.0459439385097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0223536867858\n",
      "train loss:0.0113816608612\n",
      "train loss:0.00974326679514\n",
      "train loss:0.0016284054372\n",
      "train loss:0.0126128134103\n",
      "train loss:0.00466583658592\n",
      "train loss:0.0172658332418\n",
      "train loss:0.00168526189497\n",
      "train loss:0.00464488152807\n",
      "train loss:0.0236976600113\n",
      "train loss:0.0172645995578\n",
      "train loss:0.00315756446707\n",
      "train loss:0.016708485563\n",
      "train loss:0.0413528552085\n",
      "train loss:0.0201466834384\n",
      "train loss:0.0164885538541\n",
      "train loss:0.00978435239774\n",
      "train loss:0.0175147018501\n",
      "train loss:0.00786671237974\n",
      "train loss:0.0204843569305\n",
      "train loss:0.00853011199973\n",
      "train loss:0.00236281398767\n",
      "train loss:0.020739469484\n",
      "train loss:0.0126398786117\n",
      "train loss:0.00510341044575\n",
      "train loss:0.00540477721689\n",
      "train loss:0.00176249292661\n",
      "train loss:0.00818071397922\n",
      "train loss:0.0103888581341\n",
      "train loss:0.00626346125359\n",
      "train loss:0.0123068993218\n",
      "train loss:0.0109250393884\n",
      "train loss:0.0135415798068\n",
      "train loss:0.00649910265257\n",
      "train loss:0.00234559767599\n",
      "train loss:0.00706347263523\n",
      "train loss:0.00742806790803\n",
      "train loss:0.0121498186028\n",
      "train loss:0.00286086667572\n",
      "train loss:0.0589133834376\n",
      "train loss:0.0650000646245\n",
      "train loss:0.0139594784129\n",
      "train loss:0.0358030023846\n",
      "train loss:0.0111401849412\n",
      "train loss:0.00886013902208\n",
      "train loss:0.00140107893193\n",
      "train loss:0.0287130667349\n",
      "train loss:0.015862605452\n",
      "train loss:0.00285571879694\n",
      "train loss:0.0160196770313\n",
      "train loss:0.0125202606679\n",
      "train loss:0.00252184520175\n",
      "train loss:0.0211477917318\n",
      "train loss:0.0145353096286\n",
      "train loss:0.00697997110768\n",
      "train loss:0.0296293931819\n",
      "train loss:0.00375645834545\n",
      "train loss:0.00646186116394\n",
      "train loss:0.0105897737456\n",
      "train loss:0.0529421003923\n",
      "train loss:0.00235726616227\n",
      "train loss:0.0122674576963\n",
      "train loss:0.00951858980643\n",
      "train loss:0.0160528644745\n",
      "train loss:0.00288177762836\n",
      "train loss:0.0086644421574\n",
      "train loss:0.0110445095637\n",
      "train loss:0.0220753150724\n",
      "train loss:0.0190022973311\n",
      "train loss:0.0181842299652\n",
      "train loss:0.00295301393642\n",
      "train loss:0.00936672272428\n",
      "train loss:0.0195760209605\n",
      "train loss:0.0137928988982\n",
      "train loss:0.0126413973946\n",
      "train loss:0.0628685368974\n",
      "train loss:0.00752782189428\n",
      "train loss:0.00697073486024\n",
      "train loss:0.0149675814129\n",
      "train loss:0.00234046142094\n",
      "train loss:0.0630901889836\n",
      "train loss:0.00865774717338\n",
      "train loss:0.0129154806113\n",
      "train loss:0.0231460743052\n",
      "train loss:0.00385648751505\n",
      "train loss:0.00760979425043\n",
      "train loss:0.00481612648584\n",
      "train loss:0.0130429757192\n",
      "train loss:0.033530570307\n",
      "train loss:0.00469532038388\n",
      "train loss:0.00491686125664\n",
      "train loss:0.00617060896105\n",
      "train loss:0.014936910737\n",
      "train loss:0.00725405653878\n",
      "train loss:0.00179336735587\n",
      "train loss:0.0031921168849\n",
      "train loss:0.027333702278\n",
      "train loss:0.00903490833049\n",
      "train loss:0.024820653909\n",
      "train loss:0.0197803505511\n",
      "train loss:0.00881385012684\n",
      "train loss:0.0126068207712\n",
      "train loss:0.00286916470451\n",
      "train loss:0.039914038829\n",
      "train loss:0.0620921859484\n",
      "train loss:0.00138816996761\n",
      "train loss:0.013690863618\n",
      "train loss:0.0834022968365\n",
      "train loss:0.000947200059472\n",
      "train loss:0.0035743122204\n",
      "train loss:0.0294831995753\n",
      "train loss:0.026988087893\n",
      "train loss:0.0333163278624\n",
      "train loss:0.0222430678177\n",
      "train loss:0.0232293317807\n",
      "train loss:0.0115504632376\n",
      "train loss:0.0479028540449\n",
      "train loss:0.0912820934675\n",
      "train loss:0.0502457737665\n",
      "train loss:0.0168678841159\n",
      "train loss:0.0180583413354\n",
      "train loss:0.00458780237156\n",
      "train loss:0.0257627674406\n",
      "train loss:0.00420311266069\n",
      "train loss:0.0105686842293\n",
      "train loss:0.00185874394755\n",
      "train loss:0.0778854479266\n",
      "train loss:0.0170296020985\n",
      "train loss:0.0166376154166\n",
      "train loss:0.00935133015526\n",
      "train loss:0.00721621407356\n",
      "train loss:0.0258329755029\n",
      "train loss:0.0154542212174\n",
      "train loss:0.0280870156018\n",
      "train loss:0.00667404903403\n",
      "train loss:0.00927528687152\n",
      "train loss:0.0240499296886\n",
      "train loss:0.020450741556\n",
      "train loss:0.00933194100571\n",
      "train loss:0.0119293993314\n",
      "train loss:0.0282090496002\n",
      "train loss:0.0136532011342\n",
      "train loss:0.00673622463959\n",
      "train loss:0.0234408956144\n",
      "train loss:0.00381954763596\n",
      "train loss:0.00709938305685\n",
      "train loss:0.00185696604295\n",
      "train loss:0.00628010848352\n",
      "train loss:0.0140920910306\n",
      "train loss:0.00870250095319\n",
      "train loss:0.0601656393887\n",
      "train loss:0.00270175260648\n",
      "train loss:0.0024621481018\n",
      "train loss:0.00582027815629\n",
      "train loss:0.0139374798337\n",
      "train loss:0.0581696909699\n",
      "train loss:0.00382989828242\n",
      "train loss:0.0290254643692\n",
      "train loss:0.0210059249097\n",
      "train loss:0.0199025985525\n",
      "train loss:0.0128472470934\n",
      "train loss:0.00829309880699\n",
      "train loss:0.0131076966734\n",
      "train loss:0.00700961179442\n",
      "train loss:0.00658862965996\n",
      "train loss:0.0129529563108\n",
      "train loss:0.00443744889956\n",
      "train loss:0.0123673242623\n",
      "train loss:0.012528042717\n",
      "train loss:0.00519421164955\n",
      "train loss:0.00455230293564\n",
      "train loss:0.00862402867877\n",
      "train loss:0.0046149596476\n",
      "train loss:0.0100633308669\n",
      "train loss:0.00861345429704\n",
      "train loss:0.00691391942842\n",
      "train loss:0.0569873199552\n",
      "train loss:0.00340484227247\n",
      "train loss:0.00227488629249\n",
      "train loss:0.00306107757921\n",
      "train loss:0.0252443135788\n",
      "train loss:0.029598045507\n",
      "train loss:0.00751575969995\n",
      "train loss:0.0124635784841\n",
      "train loss:0.0185945733981\n",
      "train loss:0.00734459791392\n",
      "train loss:0.0328608780112\n",
      "train loss:0.125043279597\n",
      "train loss:0.0112006065154\n",
      "train loss:0.0193330013799\n",
      "train loss:0.0159668164359\n",
      "train loss:0.00485533577385\n",
      "train loss:0.0355673760976\n",
      "train loss:0.0368084906568\n",
      "train loss:0.00442136417284\n",
      "train loss:0.0164359977184\n",
      "train loss:0.021474045765\n",
      "train loss:0.0187953859401\n",
      "train loss:0.0100155650226\n",
      "train loss:0.0269370382142\n",
      "train loss:0.0105936627381\n",
      "train loss:0.00304525217748\n",
      "train loss:0.0543194294657\n",
      "train loss:0.0131472266392\n",
      "train loss:0.0178502246359\n",
      "train loss:0.0561606409154\n",
      "train loss:0.0115360539396\n",
      "train loss:0.0171775537341\n",
      "train loss:0.0138386600418\n",
      "train loss:0.0208861891487\n",
      "train loss:0.0195426256226\n",
      "train loss:0.00324058213577\n",
      "train loss:0.00655070285194\n",
      "train loss:0.0195972949354\n",
      "train loss:0.00712720586852\n",
      "train loss:0.00628298167139\n",
      "train loss:0.0106644529068\n",
      "train loss:0.00123362801654\n",
      "train loss:0.0145150946337\n",
      "train loss:0.00359225104176\n",
      "train loss:0.0239696134764\n",
      "train loss:0.00253949964248\n",
      "train loss:0.0092104525922\n",
      "train loss:0.00397009934294\n",
      "train loss:0.00813966520463\n",
      "train loss:0.0222708320442\n",
      "train loss:0.0289346993058\n",
      "train loss:0.0503172355169\n",
      "train loss:0.017746961432\n",
      "train loss:0.0132263657274\n",
      "train loss:0.0853358492958\n",
      "train loss:0.00937671364871\n",
      "train loss:0.0142438599907\n",
      "train loss:0.00951459059341\n",
      "train loss:0.00429492490837\n",
      "train loss:0.0141507686436\n",
      "train loss:0.0112062668318\n",
      "train loss:0.0646881919102\n",
      "train loss:0.00535596818554\n",
      "train loss:0.020886188088\n",
      "train loss:0.00529263366773\n",
      "train loss:0.0238901071153\n",
      "train loss:0.0023234524091\n",
      "train loss:0.00496902425875\n",
      "train loss:0.009391573166\n",
      "train loss:0.00948427967277\n",
      "train loss:0.00647275167758\n",
      "train loss:0.0184174472394\n",
      "train loss:0.0161312703551\n",
      "train loss:0.00644525269198\n",
      "train loss:0.00709132270664\n",
      "train loss:0.00435079576076\n",
      "train loss:0.0105158330908\n",
      "train loss:0.00404259337229\n",
      "train loss:0.00780115895661\n",
      "train loss:0.00517909933557\n",
      "train loss:0.00579708753906\n",
      "train loss:0.00748445521034\n",
      "train loss:0.0072342078517\n",
      "train loss:0.0275839597108\n",
      "train loss:0.00611827027277\n",
      "train loss:0.00152578696818\n",
      "train loss:0.00616564091924\n",
      "train loss:0.00665889648656\n",
      "train loss:0.00794374822966\n",
      "train loss:0.0940232480149\n",
      "train loss:0.0152768444505\n",
      "train loss:0.0110709065363\n",
      "train loss:0.0109826008978\n",
      "train loss:0.00466040526807\n",
      "train loss:0.00557620301507\n",
      "train loss:0.00386792015445\n",
      "train loss:0.00633057726831\n",
      "train loss:0.072266679504\n",
      "train loss:0.00356133175448\n",
      "train loss:0.0056337820251\n",
      "train loss:0.00238736416098\n",
      "train loss:0.0107116485124\n",
      "train loss:0.00523514615992\n",
      "train loss:0.00606290465333\n",
      "train loss:0.00595721896298\n",
      "train loss:0.0519573554098\n",
      "train loss:0.035479324424\n",
      "train loss:0.00939986680753\n",
      "train loss:0.0445061026698\n",
      "train loss:0.00316668831026\n",
      "train loss:0.00793460309205\n",
      "train loss:0.0117539203346\n",
      "train loss:0.00748201895383\n",
      "train loss:0.0712609458489\n",
      "train loss:0.0178328596738\n",
      "train loss:0.0142288696515\n",
      "train loss:0.00948373597849\n",
      "train loss:0.00194786193973\n",
      "train loss:0.0122331463633\n",
      "train loss:0.00742291288975\n",
      "train loss:0.0195774612139\n",
      "train loss:0.00584818542939\n",
      "train loss:0.00144055700637\n",
      "train loss:0.00424079590116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0186054512638\n",
      "train loss:0.011627659195\n",
      "train loss:0.0313951052772\n",
      "train loss:0.0100317229116\n",
      "train loss:0.00395172425491\n",
      "train loss:0.00810656937736\n",
      "train loss:0.00696786520276\n",
      "train loss:0.0758451997783\n",
      "train loss:0.0111667884541\n",
      "train loss:0.0227047805991\n",
      "train loss:0.0433036940394\n",
      "train loss:0.016488639337\n",
      "train loss:0.0251268510712\n",
      "train loss:0.0131581803378\n",
      "train loss:0.0113583984112\n",
      "train loss:0.00539697833218\n",
      "train loss:0.0156739727762\n",
      "train loss:0.010156632401\n",
      "train loss:0.0283745110589\n",
      "train loss:0.0121219398384\n",
      "train loss:0.0128531100148\n",
      "train loss:0.0164745174582\n",
      "train loss:0.0055544255687\n",
      "train loss:0.0219563565871\n",
      "train loss:0.0202810135863\n",
      "train loss:0.00427994567799\n",
      "train loss:0.00165163725912\n",
      "train loss:0.00219185529591\n",
      "train loss:0.00731790131541\n",
      "train loss:0.00765503824274\n",
      "train loss:0.0200485405312\n",
      "train loss:0.0188326330161\n",
      "train loss:0.0064331945219\n",
      "train loss:0.0721557159759\n",
      "train loss:0.00716887719506\n",
      "train loss:0.0206775431227\n",
      "train loss:0.00953807259012\n",
      "train loss:0.00503220269778\n",
      "train loss:0.00972301728689\n",
      "train loss:0.0124021322238\n",
      "train loss:0.0497493659265\n",
      "train loss:0.00466621777927\n",
      "train loss:0.0192326979888\n",
      "train loss:0.000890887824119\n",
      "train loss:0.00775977030073\n",
      "train loss:0.00339202812529\n",
      "train loss:0.0115197950683\n",
      "train loss:0.00222965581993\n",
      "train loss:0.0268889083246\n",
      "train loss:0.0789923935606\n",
      "train loss:0.0241761112138\n",
      "train loss:0.00390545581027\n",
      "train loss:0.0276741729365\n",
      "train loss:0.00301809988735\n",
      "train loss:0.0257649259727\n",
      "train loss:0.0246734788203\n",
      "train loss:0.00503676190448\n",
      "train loss:0.0245492629667\n",
      "train loss:0.0107988954853\n",
      "train loss:0.00980575038482\n",
      "train loss:0.0448380074096\n",
      "train loss:0.0296307232828\n",
      "train loss:0.0250327912093\n",
      "train loss:0.00401096569271\n",
      "train loss:0.0103336380429\n",
      "train loss:0.00230824068246\n",
      "train loss:0.0239488680381\n",
      "train loss:0.0159230267626\n",
      "train loss:0.001015536081\n",
      "train loss:0.0115661071959\n",
      "train loss:0.0783291911295\n",
      "train loss:0.0134111973291\n",
      "train loss:0.00483583134027\n",
      "train loss:0.0113193136615\n",
      "train loss:0.0164063166048\n",
      "train loss:0.0460738792805\n",
      "train loss:0.00755252847087\n",
      "train loss:0.010144215413\n",
      "train loss:0.0467980262414\n",
      "train loss:0.00447809569339\n",
      "train loss:0.0102969111604\n",
      "train loss:0.00346385536422\n",
      "train loss:0.0301830917672\n",
      "train loss:0.0156894553066\n",
      "train loss:0.0279667157268\n",
      "train loss:0.00594443760767\n",
      "train loss:0.0529956331917\n",
      "train loss:0.00232268548951\n",
      "train loss:0.00927497875067\n",
      "train loss:0.00974171661747\n",
      "train loss:0.0161727404924\n",
      "train loss:0.0183907250455\n",
      "train loss:0.0125503499853\n",
      "train loss:0.0101695088695\n",
      "train loss:0.00550650942239\n",
      "train loss:0.00986775335183\n",
      "train loss:0.00896328844362\n",
      "train loss:0.0076759047751\n",
      "train loss:0.0212909249111\n",
      "train loss:0.00310712194173\n",
      "train loss:0.0165672167456\n",
      "train loss:0.0103730744661\n",
      "train loss:0.00308615403927\n",
      "train loss:0.0107088016207\n",
      "train loss:0.0131119220997\n",
      "train loss:0.0229638300074\n",
      "train loss:0.00248100363756\n",
      "train loss:0.00515686297335\n",
      "train loss:0.00634274971975\n",
      "train loss:0.0150147184104\n",
      "train loss:0.0567906618206\n",
      "train loss:0.00167433483942\n",
      "train loss:0.0148978905518\n",
      "train loss:0.0102704269974\n",
      "train loss:0.0124831313212\n",
      "train loss:0.0102227251278\n",
      "train loss:0.00635955081812\n",
      "train loss:0.00806512329199\n",
      "train loss:0.0121693791154\n",
      "train loss:0.00372356598567\n",
      "train loss:0.0128268813881\n",
      "train loss:0.0172314041726\n",
      "train loss:0.00129648040805\n",
      "train loss:0.0132117832252\n",
      "train loss:0.0332514596678\n",
      "train loss:0.0117435484157\n",
      "train loss:0.00812026902362\n",
      "train loss:0.00343697106874\n",
      "train loss:0.027204381853\n",
      "train loss:0.0379020521887\n",
      "train loss:0.0206796041692\n",
      "train loss:0.00957323864927\n",
      "train loss:0.0161116019265\n",
      "train loss:0.00619827414393\n",
      "train loss:0.00459062110445\n",
      "train loss:0.0828855284142\n",
      "train loss:0.00179890185265\n",
      "train loss:0.0220918928219\n",
      "train loss:0.00659612602995\n",
      "train loss:0.104509085901\n",
      "train loss:0.00581878651127\n",
      "train loss:0.0176376494164\n",
      "train loss:0.0144067923297\n",
      "train loss:0.0161379365347\n",
      "train loss:0.00456015405843\n",
      "train loss:0.0053307655604\n",
      "train loss:0.0228535396964\n",
      "train loss:0.0382966901335\n",
      "train loss:0.00777403705153\n",
      "train loss:0.0166469716986\n",
      "train loss:0.0140387948715\n",
      "train loss:0.0127953302776\n",
      "train loss:0.0184602301765\n",
      "train loss:0.0363724583727\n",
      "train loss:0.00792807362001\n",
      "train loss:0.00819854953061\n",
      "train loss:0.0288897242577\n",
      "train loss:0.0198601835419\n",
      "train loss:0.0221949255959\n",
      "train loss:0.00497694261602\n",
      "train loss:0.0103691999362\n",
      "train loss:0.00432530835396\n",
      "train loss:0.00963861971607\n",
      "train loss:0.00518352075716\n",
      "train loss:0.00710021179231\n",
      "train loss:0.00236706138871\n",
      "train loss:0.0237130961761\n",
      "train loss:0.0238789653838\n",
      "train loss:0.0363860611566\n",
      "train loss:0.00552974677497\n",
      "train loss:0.00434015486583\n",
      "train loss:0.00109096154119\n",
      "train loss:0.00892252042616\n",
      "train loss:0.0112204939639\n",
      "train loss:0.00882797703978\n",
      "train loss:0.044468195967\n",
      "train loss:0.0135922975339\n",
      "train loss:0.00516391403288\n",
      "train loss:0.0310443842522\n",
      "train loss:0.00397654485486\n",
      "train loss:0.0276221597239\n",
      "train loss:0.0138844909708\n",
      "train loss:0.0145937295683\n",
      "train loss:0.00659050245157\n",
      "train loss:0.0598625584701\n",
      "train loss:0.0103322354515\n",
      "train loss:0.00770366950282\n",
      "train loss:0.00817889535214\n",
      "train loss:0.0101217362997\n",
      "train loss:0.0102864016497\n",
      "train loss:0.0205096886001\n",
      "train loss:0.0644136776586\n",
      "train loss:0.00803709861664\n",
      "train loss:0.00812775589571\n",
      "train loss:0.00184379643944\n",
      "train loss:0.0169214099406\n",
      "train loss:0.0354456710646\n",
      "train loss:0.0126311985144\n",
      "train loss:0.0128997384101\n",
      "train loss:0.0221327815898\n",
      "train loss:0.0156846503512\n",
      "train loss:0.019561326411\n",
      "train loss:0.00423782436964\n",
      "train loss:0.00687512436818\n",
      "train loss:0.00150993787693\n",
      "train loss:0.00479144181745\n",
      "train loss:0.0177019284384\n",
      "train loss:0.04390583082\n",
      "train loss:0.00507549421492\n",
      "train loss:0.00187246598987\n",
      "train loss:0.016722053082\n",
      "train loss:0.00482803478153\n",
      "train loss:0.00635434872222\n",
      "train loss:0.00534460074642\n",
      "train loss:0.003919148772\n",
      "train loss:0.00201019945808\n",
      "train loss:0.00629556055\n",
      "train loss:0.00256288962397\n",
      "train loss:0.00724346239452\n",
      "train loss:0.00365637114862\n",
      "train loss:0.00811779517939\n",
      "train loss:0.0312310659537\n",
      "train loss:0.0353203510376\n",
      "train loss:0.00942438276187\n",
      "train loss:0.0134159681954\n",
      "train loss:0.0041948197696\n",
      "train loss:0.00236173460474\n",
      "train loss:0.00918788333564\n",
      "train loss:0.0181999480757\n",
      "train loss:0.00940245835059\n",
      "train loss:0.00720475857421\n",
      "train loss:0.0122237939141\n",
      "train loss:0.00736094151329\n",
      "train loss:0.00623334350941\n",
      "train loss:0.00254113678814\n",
      "train loss:0.00684836958107\n",
      "=== epoch:8, train acc:0.99, test acc:0.987 ===\n",
      "train loss:0.00412809023538\n",
      "train loss:0.00622921027843\n",
      "train loss:0.00462207984207\n",
      "train loss:0.00393257743055\n",
      "train loss:0.00342204125369\n",
      "train loss:0.0089987455611\n",
      "train loss:0.0104353980968\n",
      "train loss:0.0271935209814\n",
      "train loss:0.00174994490274\n",
      "train loss:0.0560113635514\n",
      "train loss:0.00637424501897\n",
      "train loss:0.00382615875935\n",
      "train loss:0.00713607215357\n",
      "train loss:0.00295081063168\n",
      "train loss:0.0063631835812\n",
      "train loss:0.00855670571838\n",
      "train loss:0.00485595865947\n",
      "train loss:0.0062458513361\n",
      "train loss:0.00373791548458\n",
      "train loss:0.00797768477617\n",
      "train loss:0.00448539062867\n",
      "train loss:0.0637836129779\n",
      "train loss:0.00213284759275\n",
      "train loss:0.0515665294927\n",
      "train loss:0.0114380818497\n",
      "train loss:0.031885457294\n",
      "train loss:0.0101922943488\n",
      "train loss:0.00308199437953\n",
      "train loss:0.0081258219379\n",
      "train loss:0.00577858623729\n",
      "train loss:0.00789049264188\n",
      "train loss:0.00637519135423\n",
      "train loss:0.013240208221\n",
      "train loss:0.0052104887408\n",
      "train loss:0.00218005911386\n",
      "train loss:0.00762797746315\n",
      "train loss:0.00619087670056\n",
      "train loss:0.049152407365\n",
      "train loss:0.0150870449567\n",
      "train loss:0.0051689327554\n",
      "train loss:0.00173192015854\n",
      "train loss:0.0369328240247\n",
      "train loss:0.00746076560487\n",
      "train loss:0.0382814696509\n",
      "train loss:0.0257697308212\n",
      "train loss:0.0064706581301\n",
      "train loss:0.00188252047411\n",
      "train loss:0.00765080067322\n",
      "train loss:0.00800637136373\n",
      "train loss:0.0317547956556\n",
      "train loss:0.0750394258654\n",
      "train loss:0.00572581179208\n",
      "train loss:0.0128914720618\n",
      "train loss:0.0885095569777\n",
      "train loss:0.0119440823162\n",
      "train loss:0.0204906945926\n",
      "train loss:0.021520017135\n",
      "train loss:0.0155364996921\n",
      "train loss:0.00400743969688\n",
      "train loss:0.00913760489317\n",
      "train loss:0.00400910060704\n",
      "train loss:0.00437051391015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00778857992803\n",
      "train loss:0.0026447748689\n",
      "train loss:0.0277583086055\n",
      "train loss:0.0119110806104\n",
      "train loss:0.0126570295778\n",
      "train loss:0.0113676322535\n",
      "train loss:0.0158103842217\n",
      "train loss:0.00812664631183\n",
      "train loss:0.0149548701672\n",
      "train loss:0.00322050584688\n",
      "train loss:0.0274053129499\n",
      "train loss:0.00341873720039\n",
      "train loss:0.0227114188315\n",
      "train loss:0.0127136646815\n",
      "train loss:0.00580430449533\n",
      "train loss:0.0104978479456\n",
      "train loss:0.00350014916493\n",
      "train loss:0.00622127899131\n",
      "train loss:0.0155590707843\n",
      "train loss:0.0518331590871\n",
      "train loss:0.00177700116727\n",
      "train loss:0.0098683868546\n",
      "train loss:0.0025189036247\n",
      "train loss:0.0194320394044\n",
      "train loss:0.00616988955731\n",
      "train loss:0.023142079508\n",
      "train loss:0.0600285432866\n",
      "train loss:0.0185505341787\n",
      "train loss:0.00403018088255\n",
      "train loss:0.00833108109876\n",
      "train loss:0.0142277470665\n",
      "train loss:0.00428410398153\n",
      "train loss:0.00399085407651\n",
      "train loss:0.00361252631891\n",
      "train loss:0.0156932897399\n",
      "train loss:0.00566400125829\n",
      "train loss:0.00950577700553\n",
      "train loss:0.00404866085623\n",
      "train loss:0.00382305866555\n",
      "train loss:0.00375302831449\n",
      "train loss:0.00696921247581\n",
      "train loss:0.00609190599215\n",
      "train loss:0.0265723468299\n",
      "train loss:0.0282411872453\n",
      "train loss:0.00172896125463\n",
      "train loss:0.0132929388115\n",
      "train loss:0.0181433224605\n",
      "train loss:0.00441357047481\n",
      "train loss:0.00632641553761\n",
      "train loss:0.011341767984\n",
      "train loss:0.044514364293\n",
      "train loss:0.00479453145181\n",
      "train loss:0.00405063428452\n",
      "train loss:0.00941317375968\n",
      "train loss:0.00344643895856\n",
      "train loss:0.0178809113678\n",
      "train loss:0.0108934585727\n",
      "train loss:0.0429915513735\n",
      "train loss:0.0160050980918\n",
      "train loss:0.0069448140566\n",
      "train loss:0.00978738481772\n",
      "train loss:0.0363038983587\n",
      "train loss:0.00907886698697\n",
      "train loss:0.00310279236882\n",
      "train loss:0.0265480357069\n",
      "train loss:0.0150344898171\n",
      "train loss:0.0246468826905\n",
      "train loss:0.000863381494453\n",
      "train loss:0.00675093465628\n",
      "train loss:0.0379070649166\n",
      "train loss:0.00387502157014\n",
      "train loss:0.00239974640553\n",
      "train loss:0.0230762027872\n",
      "train loss:0.00484201577829\n",
      "train loss:0.0113797686223\n",
      "train loss:0.00408271453867\n",
      "train loss:0.0136890519703\n",
      "train loss:0.0149163907272\n",
      "train loss:0.00780742008446\n",
      "train loss:0.0234443310072\n",
      "train loss:0.0111980980602\n",
      "train loss:0.00224529801186\n",
      "train loss:0.0185210651013\n",
      "train loss:0.0139353759801\n",
      "train loss:0.00824637758297\n",
      "train loss:0.0197433714679\n",
      "train loss:0.0077980431598\n",
      "train loss:0.0201347240182\n",
      "train loss:0.0023896294792\n",
      "train loss:0.0122436235851\n",
      "train loss:0.014993114183\n",
      "train loss:0.00319917565725\n",
      "train loss:0.00745544890225\n",
      "train loss:0.00633808629\n",
      "train loss:0.0515042103891\n",
      "train loss:0.000430432984075\n",
      "train loss:0.0138472371211\n",
      "train loss:0.00578662274582\n",
      "train loss:0.00482448295043\n",
      "train loss:0.0206216608376\n",
      "train loss:0.0502730538773\n",
      "train loss:0.115654519077\n",
      "train loss:0.0308331955022\n",
      "train loss:0.0223710086902\n",
      "train loss:0.00525636233005\n",
      "train loss:0.0237189616359\n",
      "train loss:0.0032688414633\n",
      "train loss:0.0519593393598\n",
      "train loss:0.00530311636167\n",
      "train loss:0.0604558136483\n",
      "train loss:0.00642220714068\n",
      "train loss:0.0107370020324\n",
      "train loss:0.0169533478224\n",
      "train loss:0.011128927496\n",
      "train loss:0.00895928473293\n",
      "train loss:0.0180565324281\n",
      "train loss:0.00235549245938\n",
      "train loss:0.0678844637202\n",
      "train loss:0.0137300999374\n",
      "train loss:0.00747156496238\n",
      "train loss:0.00685908548442\n",
      "train loss:0.00704686665245\n",
      "train loss:0.00484321627176\n",
      "train loss:0.0278718846543\n",
      "train loss:0.00620864827656\n",
      "train loss:0.00412974439687\n",
      "train loss:0.0130578250478\n",
      "train loss:0.00490181135969\n",
      "train loss:0.00685144302295\n",
      "train loss:0.0082859722753\n",
      "train loss:0.0325819070322\n",
      "train loss:0.0152069573654\n",
      "train loss:0.0250479006708\n",
      "train loss:0.0846730035543\n",
      "train loss:0.00484225016921\n",
      "train loss:0.0145194270438\n",
      "train loss:0.0078572834145\n",
      "train loss:0.00998596997851\n",
      "train loss:0.0125100768942\n",
      "train loss:0.00851257338781\n",
      "train loss:0.0080228390837\n",
      "train loss:0.0280993044875\n",
      "train loss:0.00244304380559\n",
      "train loss:0.00368738077595\n",
      "train loss:0.00770957871541\n",
      "train loss:0.00389016966031\n",
      "train loss:0.00975043585393\n",
      "train loss:0.010553307361\n",
      "train loss:0.00629365691514\n",
      "train loss:0.0243506364567\n",
      "train loss:0.0201425172779\n",
      "train loss:0.004535711971\n",
      "train loss:0.00544928691119\n",
      "train loss:0.0153347170683\n",
      "train loss:0.00263837113008\n",
      "train loss:0.00133072730806\n",
      "train loss:0.00671768301724\n",
      "train loss:0.0059067910343\n",
      "train loss:0.052463782658\n",
      "train loss:0.00622020562369\n",
      "train loss:0.0203745938569\n",
      "train loss:0.00357966723832\n",
      "train loss:0.00438459074779\n",
      "train loss:0.00579455014459\n",
      "train loss:0.0106301335705\n",
      "train loss:0.00437059301414\n",
      "train loss:0.00520809080758\n",
      "train loss:0.00384022895862\n",
      "train loss:0.00527441204402\n",
      "train loss:0.00482992213799\n",
      "train loss:0.0121024570811\n",
      "train loss:0.0439765212487\n",
      "train loss:0.00876241640044\n",
      "train loss:0.00914226911438\n",
      "train loss:0.275287410175\n",
      "train loss:0.00356835435587\n",
      "train loss:0.0277167728585\n",
      "train loss:0.004346350688\n",
      "train loss:0.0142597694394\n",
      "train loss:0.0154945573295\n",
      "train loss:0.00426672493871\n",
      "train loss:0.0159299637695\n",
      "train loss:0.024598769825\n",
      "train loss:0.00465855785448\n",
      "train loss:0.0092068143681\n",
      "train loss:0.00999479480965\n",
      "train loss:0.00701995937062\n",
      "train loss:0.0193020050193\n",
      "train loss:0.00675502019834\n",
      "train loss:0.00936438141276\n",
      "train loss:0.00649902449701\n",
      "train loss:0.00803021176681\n",
      "train loss:0.00982952274446\n",
      "train loss:0.00129457879012\n",
      "train loss:0.00411894989358\n",
      "train loss:0.0168217610086\n",
      "train loss:0.034693160197\n",
      "train loss:0.00296055024526\n",
      "train loss:0.0165579665006\n",
      "train loss:0.00299051608816\n",
      "train loss:0.0198751612849\n",
      "train loss:0.0086226642892\n",
      "train loss:0.0199640769947\n",
      "train loss:0.00464836640897\n",
      "train loss:0.00866467048807\n",
      "train loss:0.0101620381147\n",
      "train loss:0.0154687491023\n",
      "train loss:0.0105067697619\n",
      "train loss:0.0159289886851\n",
      "train loss:0.00482081895366\n",
      "train loss:0.00648894919495\n",
      "train loss:0.00537723054275\n",
      "train loss:0.00403412576586\n",
      "train loss:0.0293798252394\n",
      "train loss:0.0184058622137\n",
      "train loss:0.00685634092713\n",
      "train loss:0.00806261999142\n",
      "train loss:0.0586706081642\n",
      "train loss:0.00952039723221\n",
      "train loss:0.0266984198754\n",
      "train loss:0.0052131576122\n",
      "train loss:0.00654361038612\n",
      "train loss:0.0433995450877\n",
      "train loss:0.00661040551828\n",
      "train loss:0.00303164594391\n",
      "train loss:0.00434656090683\n",
      "train loss:0.00455835555192\n",
      "train loss:0.00594872290668\n",
      "train loss:0.00513573119004\n",
      "train loss:0.00366621235016\n",
      "train loss:0.00856733267288\n",
      "train loss:0.00331430494849\n",
      "train loss:0.0248122630985\n",
      "train loss:0.0189692237493\n",
      "train loss:0.0104816286446\n",
      "train loss:0.00707396345264\n",
      "train loss:0.0093720449069\n",
      "train loss:0.00867324411299\n",
      "train loss:0.0158425581638\n",
      "train loss:0.0094608334106\n",
      "train loss:0.0450881891273\n",
      "train loss:0.00397030230549\n",
      "train loss:0.00062005450022\n",
      "train loss:0.014234848979\n",
      "train loss:0.00572272699102\n",
      "train loss:0.00858120012438\n",
      "train loss:0.00423814860676\n",
      "train loss:0.0361911820631\n",
      "train loss:0.00761338877746\n",
      "train loss:0.0051978246414\n",
      "train loss:0.0345904134323\n",
      "train loss:0.00485899402912\n",
      "train loss:0.00205372958251\n",
      "train loss:0.00890141754998\n",
      "train loss:0.00280420938526\n",
      "train loss:0.00138306172386\n",
      "train loss:0.0807443829554\n",
      "train loss:0.0073894683381\n",
      "train loss:0.022038947221\n",
      "train loss:0.00114962213716\n",
      "train loss:0.00252301047939\n",
      "train loss:0.0108699617056\n",
      "train loss:0.00810322722772\n",
      "train loss:0.0198431664356\n",
      "train loss:0.00213261077791\n",
      "train loss:0.0169447255967\n",
      "train loss:0.00140377180945\n",
      "train loss:0.015806976059\n",
      "train loss:0.00387674639581\n",
      "train loss:0.0063021487135\n",
      "train loss:0.00338173413494\n",
      "train loss:0.00671750202847\n",
      "train loss:0.00433574259736\n",
      "train loss:0.00871227549605\n",
      "train loss:0.0105989068223\n",
      "train loss:0.00289621173657\n",
      "train loss:0.00558581930729\n",
      "train loss:0.00233964298229\n",
      "train loss:0.0101255049542\n",
      "train loss:0.00515390384675\n",
      "train loss:0.0688650215745\n",
      "train loss:0.00898312602817\n",
      "train loss:0.00808291443778\n",
      "train loss:0.0187245235131\n",
      "train loss:0.221801149477\n",
      "train loss:0.0153712196788\n",
      "train loss:0.00649582441769\n",
      "train loss:0.0233897183673\n",
      "train loss:0.00675706741274\n",
      "train loss:0.0614500720103\n",
      "train loss:0.00524526633491\n",
      "train loss:0.00699532964448\n",
      "train loss:0.0342146615737\n",
      "train loss:0.00283569688113\n",
      "train loss:0.00465390903842\n",
      "train loss:0.0285561873319\n",
      "train loss:0.00554551049224\n",
      "train loss:0.00128821337404\n",
      "train loss:0.00107762324844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00182510165248\n",
      "train loss:0.00380891928314\n",
      "train loss:0.00446180420022\n",
      "train loss:0.00130873367405\n",
      "train loss:0.0148316754948\n",
      "train loss:0.00385574752798\n",
      "train loss:0.0429927597541\n",
      "train loss:0.00495173106664\n",
      "train loss:0.00844337242647\n",
      "train loss:0.00672040122116\n",
      "train loss:0.0152432679196\n",
      "train loss:0.0107481240203\n",
      "train loss:0.00362228610371\n",
      "train loss:0.00983588325352\n",
      "train loss:0.00161527503071\n",
      "train loss:0.00384121348593\n",
      "train loss:0.0182143604262\n",
      "train loss:0.0215573705143\n",
      "train loss:0.00560713213144\n",
      "train loss:0.00381940776058\n",
      "train loss:0.00873882908349\n",
      "train loss:0.0127537420709\n",
      "train loss:0.0380904136718\n",
      "train loss:0.00488080899139\n",
      "train loss:0.0113275490968\n",
      "train loss:0.00224604029867\n",
      "train loss:0.00562308242819\n",
      "train loss:0.00180909750807\n",
      "train loss:0.0316873991031\n",
      "train loss:0.0489543667315\n",
      "train loss:0.0130573431068\n",
      "train loss:0.00113676126138\n",
      "train loss:0.0152765955256\n",
      "train loss:0.0145769210814\n",
      "train loss:0.0148824108378\n",
      "train loss:0.000929074216508\n",
      "train loss:0.00906519099838\n",
      "train loss:0.0063433815796\n",
      "train loss:0.019067637027\n",
      "train loss:0.0422551798902\n",
      "train loss:0.00380404963346\n",
      "train loss:0.0121906858546\n",
      "train loss:0.0566684525212\n",
      "train loss:0.00716091953161\n",
      "train loss:0.00103722196026\n",
      "train loss:0.00902070727598\n",
      "train loss:0.00148701790881\n",
      "train loss:0.0157297271363\n",
      "train loss:0.00351663328627\n",
      "train loss:0.0057448002546\n",
      "train loss:0.00131682470878\n",
      "train loss:0.0141798824277\n",
      "train loss:0.0117315651152\n",
      "train loss:0.0568603228283\n",
      "train loss:0.0169547934971\n",
      "train loss:0.00544032787362\n",
      "train loss:0.00346679283324\n",
      "train loss:0.00510631180398\n",
      "train loss:0.00858426132361\n",
      "train loss:0.000973558539192\n",
      "train loss:0.00378839156745\n",
      "train loss:0.00653272629118\n",
      "train loss:0.00971155610246\n",
      "train loss:0.0297838565474\n",
      "train loss:0.00459429055484\n",
      "train loss:0.0124875030682\n",
      "train loss:0.00274911390546\n",
      "train loss:0.00261054796995\n",
      "train loss:0.00202920684609\n",
      "train loss:0.00695383656796\n",
      "train loss:0.00884113544246\n",
      "train loss:0.0257707231633\n",
      "train loss:0.0168879965573\n",
      "train loss:0.0133291763897\n",
      "train loss:0.0295795571818\n",
      "train loss:0.00106252304256\n",
      "train loss:0.00849000039983\n",
      "train loss:0.0131546698223\n",
      "train loss:0.0218507431307\n",
      "train loss:0.00215347098589\n",
      "train loss:0.00476380790409\n",
      "train loss:0.0107591132178\n",
      "train loss:0.0451313296462\n",
      "train loss:0.0179743676328\n",
      "train loss:0.00424473859168\n",
      "train loss:0.0147981460047\n",
      "train loss:0.016474608308\n",
      "train loss:0.0117668964583\n",
      "train loss:0.0153858044705\n",
      "train loss:0.0042141635742\n",
      "train loss:0.00135503119459\n",
      "train loss:0.0257614829847\n",
      "train loss:0.0149717692843\n",
      "train loss:0.00667345577091\n",
      "train loss:0.0192109120009\n",
      "train loss:0.0181980757724\n",
      "train loss:0.00650272688295\n",
      "train loss:0.00598127958661\n",
      "train loss:0.0247691681925\n",
      "train loss:0.00205408165729\n",
      "train loss:0.0365463083134\n",
      "train loss:0.045184579989\n",
      "train loss:0.00958258782255\n",
      "train loss:0.0182621518671\n",
      "train loss:0.00324512945585\n",
      "train loss:0.0081125925253\n",
      "train loss:0.0194302098718\n",
      "train loss:0.0254907486902\n",
      "train loss:0.0218479214244\n",
      "train loss:0.0086889654518\n",
      "train loss:0.00182453232012\n",
      "train loss:0.0207071341738\n",
      "train loss:0.0157849976294\n",
      "train loss:0.0014388663791\n",
      "train loss:0.00312766045698\n",
      "train loss:0.00589129562731\n",
      "train loss:0.00764392012922\n",
      "train loss:0.00368584589811\n",
      "train loss:0.0302632203495\n",
      "train loss:0.0175045925607\n",
      "train loss:0.00403768654888\n",
      "train loss:0.0112154636653\n",
      "train loss:0.0378219378187\n",
      "train loss:0.00737780764332\n",
      "train loss:0.00320369586838\n",
      "train loss:0.00586022782942\n",
      "train loss:0.00152073957442\n",
      "train loss:0.0037984741456\n",
      "train loss:0.0247168984717\n",
      "train loss:0.00502988594973\n",
      "train loss:0.00986677283705\n",
      "train loss:0.0106511008867\n",
      "train loss:0.0239643611508\n",
      "train loss:0.0130732965011\n",
      "train loss:0.0379781234197\n",
      "train loss:0.0032337894748\n",
      "train loss:0.00283064774707\n",
      "train loss:0.00629778376405\n",
      "train loss:0.00781981585125\n",
      "train loss:0.0145658365977\n",
      "train loss:0.00187472970005\n",
      "train loss:0.00674854092296\n",
      "train loss:0.0241781633625\n",
      "train loss:0.00564637587673\n",
      "train loss:0.00395047737259\n",
      "train loss:0.0080863589697\n",
      "train loss:0.0266643226311\n",
      "train loss:0.00921930622768\n",
      "train loss:0.00380065757911\n",
      "train loss:0.115526876618\n",
      "train loss:0.015620527833\n",
      "train loss:0.00563999275026\n",
      "train loss:0.0283804179763\n",
      "train loss:0.00328550394277\n",
      "train loss:0.0176653177452\n",
      "train loss:0.00741802203164\n",
      "train loss:0.072258377363\n",
      "train loss:0.0109558607704\n",
      "train loss:0.00756996571424\n",
      "train loss:0.0160973153331\n",
      "train loss:0.0184668778383\n",
      "train loss:0.00143576348658\n",
      "train loss:0.00534682073065\n",
      "train loss:0.027862850884\n",
      "train loss:0.0042188191964\n",
      "train loss:0.0260427270519\n",
      "train loss:0.0140788921816\n",
      "train loss:0.0117950196683\n",
      "train loss:0.00313490365307\n",
      "train loss:0.0131609871047\n",
      "train loss:0.00355369337627\n",
      "train loss:0.00908619753957\n",
      "train loss:0.0013950235591\n",
      "train loss:0.0143124122539\n",
      "train loss:0.00492679146771\n",
      "train loss:0.00487032942779\n",
      "train loss:0.00272698871277\n",
      "train loss:0.00671874429208\n",
      "train loss:0.00790222629923\n",
      "train loss:0.00719066014167\n",
      "train loss:0.00842378832836\n",
      "train loss:0.00136239366927\n",
      "train loss:0.0021495490657\n",
      "train loss:0.0090199441613\n",
      "train loss:0.0179948302102\n",
      "train loss:0.00232708122029\n",
      "train loss:0.0102052230789\n",
      "train loss:0.00130553748483\n",
      "train loss:0.00987570982221\n",
      "train loss:0.00210383052047\n",
      "train loss:0.0159516330818\n",
      "train loss:0.0240052373448\n",
      "train loss:0.00685145167856\n",
      "train loss:0.00473503544734\n",
      "train loss:0.00266819513756\n",
      "train loss:0.00535646200927\n",
      "train loss:0.0174689665703\n",
      "train loss:0.00412582222148\n",
      "train loss:0.00454699446729\n",
      "train loss:0.00581276090238\n",
      "train loss:0.0123154074627\n",
      "train loss:0.00539641178975\n",
      "train loss:0.00825699206556\n",
      "train loss:0.00169137624152\n",
      "train loss:0.0127633327612\n",
      "train loss:0.00612964860794\n",
      "train loss:0.00106545728866\n",
      "train loss:0.0042745705699\n",
      "train loss:0.00160316348612\n",
      "train loss:0.00296770605146\n",
      "train loss:0.0265295121977\n",
      "train loss:0.00150622634919\n",
      "train loss:0.00356747533924\n",
      "train loss:0.0036045681864\n",
      "train loss:0.00434598638808\n",
      "train loss:0.00140404339859\n",
      "train loss:0.0230662858222\n",
      "train loss:0.0163986212352\n",
      "train loss:0.0156462720324\n",
      "train loss:0.00470067155973\n",
      "train loss:0.00546561142685\n",
      "train loss:0.0198919697121\n",
      "train loss:0.00309994040963\n",
      "train loss:0.0763492198712\n",
      "train loss:0.0119146941557\n",
      "train loss:0.00213478981975\n",
      "train loss:0.0123155908644\n",
      "train loss:0.0549451599013\n",
      "train loss:0.00664572710649\n",
      "train loss:0.00346018308936\n",
      "train loss:0.00541537963081\n",
      "train loss:0.0415804379331\n",
      "train loss:0.0122825122501\n",
      "train loss:0.00431995030316\n",
      "train loss:0.0148626470561\n",
      "train loss:0.0138432133711\n",
      "train loss:0.0188641233511\n",
      "train loss:0.0387486560594\n",
      "train loss:0.0111382167661\n",
      "=== epoch:9, train acc:0.992, test acc:0.991 ===\n",
      "train loss:0.0187096127545\n",
      "train loss:0.00223041182094\n",
      "train loss:0.00380934483145\n",
      "train loss:0.00467101451509\n",
      "train loss:0.00144028973855\n",
      "train loss:0.0641090946091\n",
      "train loss:0.00320966934976\n",
      "train loss:0.011864168788\n",
      "train loss:0.0123232112116\n",
      "train loss:0.00710359575925\n",
      "train loss:0.0256477948338\n",
      "train loss:0.00335165762341\n",
      "train loss:0.0217677573464\n",
      "train loss:0.0135334446783\n",
      "train loss:0.00312691439234\n",
      "train loss:0.00203023736283\n",
      "train loss:0.00817056055006\n",
      "train loss:0.0399160417332\n",
      "train loss:0.0166976996397\n",
      "train loss:0.0113407991401\n",
      "train loss:0.00723343401961\n",
      "train loss:0.0112022635999\n",
      "train loss:0.00187075763031\n",
      "train loss:0.0223763852592\n",
      "train loss:0.00976352042032\n",
      "train loss:0.00766815559441\n",
      "train loss:0.0253599440929\n",
      "train loss:0.0136097123362\n",
      "train loss:0.00619517648673\n",
      "train loss:0.0197871776174\n",
      "train loss:0.0203153785549\n",
      "train loss:0.00313210623384\n",
      "train loss:0.00341262474957\n",
      "train loss:0.00671693101457\n",
      "train loss:0.056508127254\n",
      "train loss:0.00921240801647\n",
      "train loss:0.0166437586309\n",
      "train loss:0.00364862506763\n",
      "train loss:0.0150117785852\n",
      "train loss:0.00281267327829\n",
      "train loss:0.00368647478683\n",
      "train loss:0.00415003313697\n",
      "train loss:0.016987772254\n",
      "train loss:0.0162529278812\n",
      "train loss:0.00606795742254\n",
      "train loss:0.210861408094\n",
      "train loss:0.016523957663\n",
      "train loss:0.00604049579242\n",
      "train loss:0.00833073199072\n",
      "train loss:0.0239122732844\n",
      "train loss:0.00392552498209\n",
      "train loss:0.0165427467226\n",
      "train loss:0.00556754141431\n",
      "train loss:0.00626614566866\n",
      "train loss:0.0527534675056\n",
      "train loss:0.125889963015\n",
      "train loss:0.0108828735416\n",
      "train loss:0.0301235840933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00413985390569\n",
      "train loss:0.0350226100171\n",
      "train loss:0.0170755945682\n",
      "train loss:0.00564066062723\n",
      "train loss:0.00455065523294\n",
      "train loss:0.0161491013935\n",
      "train loss:0.0059603137711\n",
      "train loss:0.0164127851656\n",
      "train loss:0.00845215091826\n",
      "train loss:0.0174548558197\n",
      "train loss:0.0138623360702\n",
      "train loss:0.0236379001764\n",
      "train loss:0.00838944985872\n",
      "train loss:0.011997256632\n",
      "train loss:0.026954091247\n",
      "train loss:0.00440182162056\n",
      "train loss:0.00538236722091\n",
      "train loss:0.0176166790576\n",
      "train loss:0.0436568429325\n",
      "train loss:0.0054041800685\n",
      "train loss:0.0320307491197\n",
      "train loss:0.00950474786281\n",
      "train loss:0.00470707934701\n",
      "train loss:0.0124466661262\n",
      "train loss:0.00740362924595\n",
      "train loss:0.00331102773157\n",
      "train loss:0.0141787870381\n",
      "train loss:0.00473551085175\n",
      "train loss:0.00165267081527\n",
      "train loss:0.0100687226505\n",
      "train loss:0.00925973021154\n",
      "train loss:0.00688857857451\n",
      "train loss:0.00533910580359\n",
      "train loss:0.00118259488687\n",
      "train loss:0.0148104229466\n",
      "train loss:0.00315805658034\n",
      "train loss:0.0408958263973\n",
      "train loss:0.0130649612308\n",
      "train loss:0.00910417356858\n",
      "train loss:0.0106559604099\n",
      "train loss:0.0355175420129\n",
      "train loss:0.0110888996811\n",
      "train loss:0.0511224442821\n",
      "train loss:0.00510424249771\n",
      "train loss:0.0121238338053\n",
      "train loss:0.00941330673437\n",
      "train loss:0.00319816226546\n",
      "train loss:0.0245468277189\n",
      "train loss:0.06145474493\n",
      "train loss:0.00904737254256\n",
      "train loss:0.0376961880209\n",
      "train loss:0.00503332274808\n",
      "train loss:0.0079240669614\n",
      "train loss:0.00427875454787\n",
      "train loss:0.00886678661787\n",
      "train loss:0.00647203110748\n",
      "train loss:0.0183593847877\n",
      "train loss:0.014357980567\n",
      "train loss:0.0259426487802\n",
      "train loss:0.135152811442\n",
      "train loss:0.00402851422337\n",
      "train loss:0.0112854435117\n",
      "train loss:0.0184627285671\n",
      "train loss:0.0156831675579\n",
      "train loss:0.0145033806338\n",
      "train loss:0.0576361354941\n",
      "train loss:0.0157263615945\n",
      "train loss:0.00755273274771\n",
      "train loss:0.0187432182592\n",
      "train loss:0.00655116882755\n",
      "train loss:0.0311856768763\n",
      "train loss:0.00277182358506\n",
      "train loss:0.020985659075\n",
      "train loss:0.00293351396828\n",
      "train loss:0.0183872436297\n",
      "train loss:0.00152293288276\n",
      "train loss:0.00566897169124\n",
      "train loss:0.0201932810455\n",
      "train loss:0.00744409643484\n",
      "train loss:0.00529448239612\n",
      "train loss:0.00401973814763\n",
      "train loss:0.0109746559564\n",
      "train loss:0.00388772948138\n",
      "train loss:0.0031192198343\n",
      "train loss:0.00828623442774\n",
      "train loss:0.00188953882875\n",
      "train loss:0.00730100909948\n",
      "train loss:0.00451380048217\n",
      "train loss:0.054904025925\n",
      "train loss:0.00751095204298\n",
      "train loss:0.024343062913\n",
      "train loss:0.0122243295758\n",
      "train loss:0.00786794668999\n",
      "train loss:0.0317008530405\n",
      "train loss:0.00678893897832\n",
      "train loss:0.00843775278179\n",
      "train loss:0.0123066004623\n",
      "train loss:0.00936609379181\n",
      "train loss:0.00541696003502\n",
      "train loss:0.00219827922726\n",
      "train loss:0.0775254401418\n",
      "train loss:0.0059989467855\n",
      "train loss:0.00759206211892\n",
      "train loss:0.00928681048154\n",
      "train loss:0.0412275326062\n",
      "train loss:0.00476232503492\n",
      "train loss:0.00619817457747\n",
      "train loss:0.00649375539217\n",
      "train loss:0.00627427326701\n",
      "train loss:0.00663827455843\n",
      "train loss:0.000587569179483\n",
      "train loss:0.0110114232267\n",
      "train loss:0.00796085635523\n",
      "train loss:0.00205278984879\n",
      "train loss:0.0217893713516\n",
      "train loss:0.00525177078374\n",
      "train loss:0.0161147201917\n",
      "train loss:0.0317420468898\n",
      "train loss:0.00112532420931\n",
      "train loss:0.0184331511209\n",
      "train loss:0.0157016574902\n",
      "train loss:0.00725204571226\n",
      "train loss:0.00444292763633\n",
      "train loss:0.0133627017263\n",
      "train loss:0.00210661552401\n",
      "train loss:0.037852903954\n",
      "train loss:0.026849099908\n",
      "train loss:0.00241332118153\n",
      "train loss:0.00802171860085\n",
      "train loss:0.00654016288308\n",
      "train loss:0.00298227977539\n",
      "train loss:0.020243734447\n",
      "train loss:0.0192208971966\n",
      "train loss:0.00421632218273\n",
      "train loss:0.014951781107\n",
      "train loss:0.00819711848605\n",
      "train loss:0.000950405076943\n",
      "train loss:0.00443897789889\n",
      "train loss:0.000548296794511\n",
      "train loss:0.00257539233514\n",
      "train loss:0.0630837630652\n",
      "train loss:0.00325257050277\n",
      "train loss:0.0295620878175\n",
      "train loss:0.00755855013655\n",
      "train loss:0.00232373842684\n",
      "train loss:0.00154316330747\n",
      "train loss:0.0478084919235\n",
      "train loss:0.0418809611788\n",
      "train loss:0.069022829714\n",
      "train loss:0.00442184915822\n",
      "train loss:0.00539440313858\n",
      "train loss:0.0151259158804\n",
      "train loss:0.00142347518073\n",
      "train loss:0.00378279257421\n",
      "train loss:0.0255736905292\n",
      "train loss:0.00308049714502\n",
      "train loss:0.00694444108027\n",
      "train loss:0.040474412752\n",
      "train loss:0.00542056602426\n",
      "train loss:0.0148352460219\n",
      "train loss:0.0115542992019\n",
      "train loss:0.00635937882356\n",
      "train loss:0.00882249580752\n",
      "train loss:0.00635547955561\n",
      "train loss:0.00306993969518\n",
      "train loss:0.00670600932011\n",
      "train loss:0.00323654547204\n",
      "train loss:0.00492339739961\n",
      "train loss:0.00631881387275\n",
      "train loss:0.00589957427183\n",
      "train loss:0.0495195593099\n",
      "train loss:0.0227305095565\n",
      "train loss:0.0105629792029\n",
      "train loss:0.00791314912185\n",
      "train loss:0.012669889827\n",
      "train loss:0.00656017760082\n",
      "train loss:0.0512712625714\n",
      "train loss:0.0133187850777\n",
      "train loss:0.010934464116\n",
      "train loss:0.00594558583045\n",
      "train loss:0.0134193916464\n",
      "train loss:0.0101688614199\n",
      "train loss:0.00545915373385\n",
      "train loss:0.00136130817533\n",
      "train loss:0.00734330121808\n",
      "train loss:0.000628605897324\n",
      "train loss:0.00447359298253\n",
      "train loss:0.023709212118\n",
      "train loss:0.00338657954695\n",
      "train loss:0.00537081875979\n",
      "train loss:0.0491421434773\n",
      "train loss:0.0128849760565\n",
      "train loss:0.0080979839464\n",
      "train loss:0.00261999692643\n",
      "train loss:0.0147447013798\n",
      "train loss:0.00254895752914\n",
      "train loss:0.00664630378376\n",
      "train loss:0.00258018142733\n",
      "train loss:0.00634668575497\n",
      "train loss:0.00153250707631\n",
      "train loss:0.00325581779295\n",
      "train loss:0.00837250488286\n",
      "train loss:0.014459946834\n",
      "train loss:0.00347025160564\n",
      "train loss:0.0079710764908\n",
      "train loss:0.00854416200366\n",
      "train loss:0.0109403328028\n",
      "train loss:0.0014452366758\n",
      "train loss:0.00741767211626\n",
      "train loss:0.00327446562178\n",
      "train loss:0.00554691374641\n",
      "train loss:0.0113613048033\n",
      "train loss:0.00969608804688\n",
      "train loss:0.0036395827529\n",
      "train loss:0.00999607992058\n",
      "train loss:0.0226477180759\n",
      "train loss:0.00748483218724\n",
      "train loss:0.0108773853378\n",
      "train loss:0.00282361342386\n",
      "train loss:0.00561159722668\n",
      "train loss:0.0111270409051\n",
      "train loss:0.00394221760238\n",
      "train loss:0.00501938548742\n",
      "train loss:0.0357692722466\n",
      "train loss:0.00713437426401\n",
      "train loss:0.00565145529122\n",
      "train loss:0.0100405463687\n",
      "train loss:0.00788453157213\n",
      "train loss:0.00424646811589\n",
      "train loss:0.00643614260059\n",
      "train loss:0.00648488343604\n",
      "train loss:0.0051729867254\n",
      "train loss:0.00695880317547\n",
      "train loss:0.00235557050686\n",
      "train loss:0.00327682723273\n",
      "train loss:0.0177259294979\n",
      "train loss:0.00521847180399\n",
      "train loss:0.0941215492639\n",
      "train loss:0.00845589633604\n",
      "train loss:0.00434041839723\n",
      "train loss:0.00367544203736\n",
      "train loss:0.00982200869846\n",
      "train loss:0.0102503212425\n",
      "train loss:0.00852002559405\n",
      "train loss:0.00502220100949\n",
      "train loss:0.0132634815438\n",
      "train loss:0.0173659924798\n",
      "train loss:0.0260064089879\n",
      "train loss:0.0500318812947\n",
      "train loss:0.0313294712862\n",
      "train loss:0.00506698559159\n",
      "train loss:0.0051341034893\n",
      "train loss:0.0376537984508\n",
      "train loss:0.00779906485966\n",
      "train loss:0.0140048743588\n",
      "train loss:0.0034202063658\n",
      "train loss:0.00830279339682\n",
      "train loss:0.0144174287508\n",
      "train loss:0.0501053809446\n",
      "train loss:0.0197966648616\n",
      "train loss:0.0952453209429\n",
      "train loss:0.0110476496212\n",
      "train loss:0.00268167979121\n",
      "train loss:0.00650267724499\n",
      "train loss:0.00397114108772\n",
      "train loss:0.020965203945\n",
      "train loss:0.010037219282\n",
      "train loss:0.00628051100133\n",
      "train loss:0.0114929093045\n",
      "train loss:0.0112895899294\n",
      "train loss:0.0110313824595\n",
      "train loss:0.00472030197616\n",
      "train loss:0.0100021632661\n",
      "train loss:0.0240696540081\n",
      "train loss:0.00930191957732\n",
      "train loss:0.00335500450074\n",
      "train loss:0.00243869579561\n",
      "train loss:0.00266607555417\n",
      "train loss:0.0374191694134\n",
      "train loss:0.0382876652774\n",
      "train loss:0.0222430086262\n",
      "train loss:0.00760279156092\n",
      "train loss:0.0218601598653\n",
      "train loss:0.0277764714229\n",
      "train loss:0.0333283527146\n",
      "train loss:0.00339118100859\n",
      "train loss:0.00887807653425\n",
      "train loss:0.0147695556239\n",
      "train loss:0.013668916754\n",
      "train loss:0.0476340921113\n",
      "train loss:0.0109250021068\n",
      "train loss:0.0079309868617\n",
      "train loss:0.0244473002935\n",
      "train loss:0.0176514472405\n",
      "train loss:0.0126026068467\n",
      "train loss:0.0180336598303\n",
      "train loss:0.0055766672584\n",
      "train loss:0.0070651466212\n",
      "train loss:0.0177494825594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00475413126991\n",
      "train loss:0.00392799923746\n",
      "train loss:0.0364496297933\n",
      "train loss:0.0063714957709\n",
      "train loss:0.0297958751744\n",
      "train loss:0.0319232900721\n",
      "train loss:0.0711886117673\n",
      "train loss:0.00324261119539\n",
      "train loss:0.0283709018818\n",
      "train loss:0.0260506156208\n",
      "train loss:0.00236224695194\n",
      "train loss:0.00338236113997\n",
      "train loss:0.00770102264574\n",
      "train loss:0.0140275051092\n",
      "train loss:0.00712507193863\n",
      "train loss:0.0101836265306\n",
      "train loss:0.0131686499954\n",
      "train loss:0.00622679618881\n",
      "train loss:0.0383199904966\n",
      "train loss:0.0142242384046\n",
      "train loss:0.0141880796184\n",
      "train loss:0.0157552407297\n",
      "train loss:0.0137452835717\n",
      "train loss:0.00398875906522\n",
      "train loss:0.00515560692294\n",
      "train loss:0.0176553795534\n",
      "train loss:0.0136614511831\n",
      "train loss:0.00403787845391\n",
      "train loss:0.0127801037884\n",
      "train loss:0.00324813278434\n",
      "train loss:0.00387205134706\n",
      "train loss:0.0234435603135\n",
      "train loss:0.0127137570005\n",
      "train loss:0.00259209129376\n",
      "train loss:0.00442849781646\n",
      "train loss:0.0295461046964\n",
      "train loss:0.00266541625686\n",
      "train loss:0.00424182155836\n",
      "train loss:0.00524185255053\n",
      "train loss:0.00803623090691\n",
      "train loss:0.0197505660551\n",
      "train loss:0.0281242458084\n",
      "train loss:0.00627887764717\n",
      "train loss:0.000929162009987\n",
      "train loss:0.0183106202492\n",
      "train loss:0.00109976010765\n",
      "train loss:0.00282163679076\n",
      "train loss:0.0217850863442\n",
      "train loss:0.00455806452764\n",
      "train loss:0.0200584761684\n",
      "train loss:0.0050606356015\n",
      "train loss:0.00236501533203\n",
      "train loss:0.00371386805762\n",
      "train loss:0.00653779550145\n",
      "train loss:0.0134950440509\n",
      "train loss:0.00938204686532\n",
      "train loss:0.0104402527545\n",
      "train loss:0.0378883172118\n",
      "train loss:0.00223924237091\n",
      "train loss:0.00916357713011\n",
      "train loss:0.00628750905667\n",
      "train loss:0.00759459319978\n",
      "train loss:0.0603677679145\n",
      "train loss:0.00560378654463\n",
      "train loss:0.00458043821748\n",
      "train loss:0.00860953648605\n",
      "train loss:0.00541974009645\n",
      "train loss:0.000979462640583\n",
      "train loss:0.0073699860651\n",
      "train loss:0.00398904837854\n",
      "train loss:0.00385861974265\n",
      "train loss:0.00912134335584\n",
      "train loss:0.0288256304909\n",
      "train loss:0.00663038728542\n",
      "train loss:0.00634654934566\n",
      "train loss:0.0176927521082\n",
      "train loss:0.0125373992474\n",
      "train loss:0.00799820238772\n",
      "train loss:0.00342983556344\n",
      "train loss:0.00218006380078\n",
      "train loss:0.00216383663564\n",
      "train loss:0.00986857128136\n",
      "train loss:0.00324260779798\n",
      "train loss:0.010873405325\n",
      "train loss:0.0332255980329\n",
      "train loss:0.00510008783377\n",
      "train loss:0.00647645108105\n",
      "train loss:0.00918704845547\n",
      "train loss:0.00470197303347\n",
      "train loss:0.0067583358545\n",
      "train loss:0.0667463954657\n",
      "train loss:0.0181687771214\n",
      "train loss:0.00136369252495\n",
      "train loss:0.00337682936356\n",
      "train loss:0.0160597934838\n",
      "train loss:0.0199637746792\n",
      "train loss:0.00335899013415\n",
      "train loss:0.00463480881881\n",
      "train loss:0.00243052822436\n",
      "train loss:0.000816021289762\n",
      "train loss:0.0254430040311\n",
      "train loss:0.0201641860651\n",
      "train loss:0.00280652698782\n",
      "train loss:0.00141057281574\n",
      "train loss:0.0173091264316\n",
      "train loss:0.00568191040124\n",
      "train loss:0.129829775067\n",
      "train loss:0.0061475679708\n",
      "train loss:0.00277383904633\n",
      "train loss:0.00420367225418\n",
      "train loss:0.00198884880339\n",
      "train loss:0.00256116812286\n",
      "train loss:0.00964268585892\n",
      "train loss:0.007041154036\n",
      "train loss:0.00963580060103\n",
      "train loss:0.00570821961661\n",
      "train loss:0.00387371892597\n",
      "train loss:0.00743605186876\n",
      "train loss:0.0161614251961\n",
      "train loss:0.0028772976047\n",
      "train loss:0.00447488268062\n",
      "train loss:0.0250192670059\n",
      "train loss:0.0402893961686\n",
      "train loss:0.0084461730223\n",
      "train loss:0.00138795534134\n",
      "train loss:0.00654644185664\n",
      "train loss:0.0261026646865\n",
      "train loss:0.00332005567522\n",
      "train loss:0.00747961112551\n",
      "train loss:0.0204444022084\n",
      "train loss:0.00857522791862\n",
      "train loss:0.0295179077185\n",
      "train loss:0.035213157866\n",
      "train loss:0.00666322517493\n",
      "train loss:0.00474042188704\n",
      "train loss:0.0739171855678\n",
      "train loss:0.0269554109388\n",
      "train loss:0.00302028655301\n",
      "train loss:0.0184298343009\n",
      "train loss:0.0111000451491\n",
      "train loss:0.00466490907716\n",
      "train loss:0.00726042972389\n",
      "train loss:0.0210792523342\n",
      "train loss:0.00165486013399\n",
      "train loss:0.0107879403878\n",
      "train loss:0.0115163312719\n",
      "train loss:0.00545098220354\n",
      "train loss:0.00518617491946\n",
      "train loss:0.00541117778902\n",
      "train loss:0.00350840154436\n",
      "train loss:0.0155019478384\n",
      "train loss:0.0197940043692\n",
      "train loss:0.00796512728956\n",
      "train loss:0.00505111219205\n",
      "train loss:0.00139753859945\n",
      "train loss:0.00564589300484\n",
      "train loss:0.0143350495732\n",
      "train loss:0.00293766416652\n",
      "train loss:0.00504583318806\n",
      "train loss:0.0171283279126\n",
      "train loss:0.00107473752967\n",
      "train loss:0.0015839931013\n",
      "train loss:0.00203469417505\n",
      "train loss:0.00490369042164\n",
      "train loss:0.00943708986627\n",
      "train loss:0.00897006370542\n",
      "train loss:0.00659751841556\n",
      "train loss:0.011968223392\n",
      "train loss:0.0192381175249\n",
      "train loss:0.00533453318225\n",
      "train loss:0.0113210546127\n",
      "train loss:0.0176133707855\n",
      "train loss:0.00747372246778\n",
      "train loss:0.00730148620355\n",
      "train loss:0.0143963125388\n",
      "train loss:0.00137339947885\n",
      "train loss:0.00143165330721\n",
      "train loss:0.0148419499326\n",
      "train loss:0.00530857428309\n",
      "train loss:0.002336316368\n",
      "train loss:0.0155965052867\n",
      "train loss:0.0625520259204\n",
      "train loss:0.0229100593761\n",
      "train loss:0.00339221854874\n",
      "train loss:0.0152227837267\n",
      "train loss:0.0022256147323\n",
      "train loss:0.00488436976777\n",
      "train loss:0.0106907266343\n",
      "train loss:0.00680125549785\n",
      "train loss:0.0685122053289\n",
      "train loss:0.00872783244357\n",
      "train loss:0.0069425028076\n",
      "train loss:0.0271124014513\n",
      "train loss:0.00801384610851\n",
      "train loss:0.00504928679639\n",
      "train loss:0.013640785849\n",
      "train loss:0.0102040150848\n",
      "train loss:0.019836746273\n",
      "train loss:0.0185842164948\n",
      "train loss:0.0198971185344\n",
      "train loss:0.00743029498709\n",
      "train loss:0.00653081909144\n",
      "train loss:0.016324644189\n",
      "train loss:0.0116899200352\n",
      "train loss:0.010609344884\n",
      "train loss:0.00372815585939\n",
      "train loss:0.00633643445547\n",
      "train loss:0.0112896911552\n",
      "train loss:0.00170739874713\n",
      "train loss:0.0139359396956\n",
      "train loss:0.0494542155\n",
      "train loss:0.0631719651094\n",
      "train loss:0.00549501555943\n",
      "train loss:0.000820112487466\n",
      "train loss:0.0039033199888\n",
      "train loss:0.00928773992738\n",
      "train loss:0.0137208576541\n",
      "train loss:0.0401660183735\n",
      "train loss:0.00850769086029\n",
      "train loss:0.0021013378815\n",
      "train loss:0.0172683773864\n",
      "train loss:0.0059258353963\n",
      "train loss:0.00374102598318\n",
      "train loss:0.0277582034468\n",
      "train loss:0.0188443147133\n",
      "train loss:0.00328944611214\n",
      "train loss:0.00947689097214\n",
      "train loss:0.00903101282678\n",
      "train loss:0.000781651553193\n",
      "train loss:0.0011661801526\n",
      "train loss:0.00217236379124\n",
      "train loss:0.0427096543749\n",
      "train loss:0.0316167736465\n",
      "train loss:0.00167072420291\n",
      "train loss:0.040000870382\n",
      "train loss:0.00576933987899\n",
      "train loss:0.0110318552806\n",
      "train loss:0.00989384081877\n",
      "train loss:0.016165812974\n",
      "train loss:0.0230539797486\n",
      "train loss:0.0176944983035\n",
      "train loss:0.00207585039993\n",
      "train loss:0.0075888619629\n",
      "=== epoch:10, train acc:0.995, test acc:0.986 ===\n",
      "train loss:0.0162151429083\n",
      "train loss:0.00378985705071\n",
      "train loss:0.0134811609727\n",
      "train loss:0.0030208710077\n",
      "train loss:0.0216371923301\n",
      "train loss:0.00188162357724\n",
      "train loss:0.00306604575727\n",
      "train loss:0.0214261658221\n",
      "train loss:0.00214741963369\n",
      "train loss:0.00865191128394\n",
      "train loss:0.00436025954224\n",
      "train loss:0.00365106899726\n",
      "train loss:0.00433473662286\n",
      "train loss:0.00210170908292\n",
      "train loss:0.00933319327515\n",
      "train loss:0.0100687375195\n",
      "train loss:0.000919587382413\n",
      "train loss:0.00677945177896\n",
      "train loss:0.00544498877251\n",
      "train loss:0.00764561550302\n",
      "train loss:0.0200458390921\n",
      "train loss:0.0145108583536\n",
      "train loss:0.003553663955\n",
      "train loss:0.00831171794451\n",
      "train loss:0.00658894723576\n",
      "train loss:0.0021430563811\n",
      "train loss:0.00523390709377\n",
      "train loss:0.00747889601382\n",
      "train loss:0.00661069559921\n",
      "train loss:0.00438675537652\n",
      "train loss:0.00240009750132\n",
      "train loss:0.0102181059099\n",
      "train loss:0.00878317433585\n",
      "train loss:0.00733753891347\n",
      "train loss:0.0072529297186\n",
      "train loss:0.0019056045898\n",
      "train loss:0.00897720493919\n",
      "train loss:0.00903817587431\n",
      "train loss:0.004675421797\n",
      "train loss:0.0127706152679\n",
      "train loss:0.00477654570128\n",
      "train loss:0.00337819259195\n",
      "train loss:0.00516125798493\n",
      "train loss:0.00785332825292\n",
      "train loss:0.00710518359822\n",
      "train loss:0.00896769754259\n",
      "train loss:0.00913198624775\n",
      "train loss:0.00657203270842\n",
      "train loss:0.0027714954592\n",
      "train loss:0.00105453164095\n",
      "train loss:0.00710042902956\n",
      "train loss:0.00643253425303\n",
      "train loss:0.000936174445373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0254409816561\n",
      "train loss:0.00208698256571\n",
      "train loss:0.00693295323293\n",
      "train loss:0.0148272959115\n",
      "train loss:0.0275652352209\n",
      "train loss:0.0023696059513\n",
      "train loss:0.00111311304512\n",
      "train loss:0.0142347563885\n",
      "train loss:0.00230806769478\n",
      "train loss:0.0244070650807\n",
      "train loss:0.0128698287739\n",
      "train loss:0.0202454003846\n",
      "train loss:0.0236938116236\n",
      "train loss:0.000898156115483\n",
      "train loss:0.00775200731693\n",
      "train loss:0.000946890559541\n",
      "train loss:0.0193694883558\n",
      "train loss:0.00888892631115\n",
      "train loss:0.0100484199114\n",
      "train loss:0.0189202075707\n",
      "train loss:0.0027737167784\n",
      "train loss:0.00189361333483\n",
      "train loss:0.0255242892289\n",
      "train loss:0.00459131809085\n",
      "train loss:0.0058845825686\n",
      "train loss:0.00487712125695\n",
      "train loss:0.000722243962318\n",
      "train loss:0.00265141962765\n",
      "train loss:0.00272997436569\n",
      "train loss:0.00924600614459\n",
      "train loss:0.00342667142467\n",
      "train loss:0.00880531586256\n",
      "train loss:0.00270734631593\n",
      "train loss:0.0559945301683\n",
      "train loss:0.00675049520587\n",
      "train loss:0.00230935872583\n",
      "train loss:0.00593229848049\n",
      "train loss:0.00727339784164\n",
      "train loss:0.00104997829012\n",
      "train loss:0.0848754979851\n",
      "train loss:0.0178469492593\n",
      "train loss:0.00643556835014\n",
      "train loss:0.00565537833197\n",
      "train loss:0.00937769615489\n",
      "train loss:0.00718928570699\n",
      "train loss:0.00512839545858\n",
      "train loss:0.0115471390742\n",
      "train loss:0.04752456214\n",
      "train loss:0.00780435527404\n",
      "train loss:0.0255121055598\n",
      "train loss:0.00161560402639\n",
      "train loss:0.0179633109156\n",
      "train loss:0.0638423491154\n",
      "train loss:0.0164163273049\n",
      "train loss:0.00503511371095\n",
      "train loss:0.0582432605829\n",
      "train loss:0.0010002721741\n",
      "train loss:0.00353547642973\n",
      "train loss:0.00521330586952\n",
      "train loss:0.0178217594837\n",
      "train loss:0.00167884098037\n",
      "train loss:0.0231016122678\n",
      "train loss:0.00274995354111\n",
      "train loss:0.00814652750045\n",
      "train loss:0.00249018215259\n",
      "train loss:0.0346993446756\n",
      "train loss:0.0016036695056\n",
      "train loss:0.0109586215903\n",
      "train loss:0.00465594145772\n",
      "train loss:0.0497767855108\n",
      "train loss:0.017617230721\n",
      "train loss:0.000870300336766\n",
      "train loss:0.0256574139576\n",
      "train loss:0.0142772852369\n",
      "train loss:0.00334800653626\n",
      "train loss:0.00891327302133\n",
      "train loss:0.0153742516472\n",
      "train loss:0.00253282490498\n",
      "train loss:0.0050862780327\n",
      "train loss:0.00353466352538\n",
      "train loss:0.00359913850554\n",
      "train loss:0.0143550763366\n",
      "train loss:0.033789242635\n",
      "train loss:0.00635931456742\n",
      "train loss:0.00295436182041\n",
      "train loss:0.00336419036985\n",
      "train loss:0.0115257080431\n",
      "train loss:0.00761036843339\n",
      "train loss:0.00296005477136\n",
      "train loss:0.00199470776569\n",
      "train loss:0.00483287294532\n",
      "train loss:0.00391933805385\n",
      "train loss:0.000525253910788\n",
      "train loss:0.0156747896404\n",
      "train loss:0.000597977491557\n",
      "train loss:0.0210411006169\n",
      "train loss:0.00155470272779\n",
      "train loss:0.00140721223135\n",
      "train loss:0.0026310704777\n",
      "train loss:0.0050571695589\n",
      "train loss:0.00972259672987\n",
      "train loss:0.0117853636655\n",
      "train loss:0.00480092760487\n",
      "train loss:0.0152117493317\n",
      "train loss:0.00696994714999\n",
      "train loss:0.00189265701356\n",
      "train loss:0.00114100187502\n",
      "train loss:0.00216031895172\n",
      "train loss:0.0126131277335\n",
      "train loss:0.00533631672594\n",
      "train loss:0.0133064465479\n",
      "train loss:0.00272219566413\n",
      "train loss:0.0247400569314\n",
      "train loss:0.00301718454103\n",
      "train loss:0.000639340663629\n",
      "train loss:0.000821574547083\n",
      "train loss:0.0014350260574\n",
      "train loss:0.00649370313496\n",
      "train loss:0.0120751960448\n",
      "train loss:0.00420967067399\n",
      "train loss:0.0103143325268\n",
      "train loss:0.00338765397362\n",
      "train loss:0.0198781087097\n",
      "train loss:0.00187623028702\n",
      "train loss:0.0235096353802\n",
      "train loss:0.00111136315421\n",
      "train loss:0.00150282567038\n",
      "train loss:0.0079833213372\n",
      "train loss:0.00444139675136\n",
      "train loss:0.00737591379018\n",
      "train loss:0.00296482540919\n",
      "train loss:0.0158293211483\n",
      "train loss:0.00233683057713\n",
      "train loss:0.00312049310299\n",
      "train loss:0.0114104032122\n",
      "train loss:0.000592704418015\n",
      "train loss:0.0362633073885\n",
      "train loss:0.00137869192487\n",
      "train loss:0.00120186210657\n",
      "train loss:0.00811735725782\n",
      "train loss:0.0133384152909\n",
      "train loss:0.00304956615087\n",
      "train loss:0.00943121309961\n",
      "train loss:0.00339127609633\n",
      "train loss:0.00128537623096\n",
      "train loss:0.00611818288056\n",
      "train loss:0.00216072484249\n",
      "train loss:0.00745623707711\n",
      "train loss:0.012938583258\n",
      "train loss:0.0438517582823\n",
      "train loss:0.0128119169215\n",
      "train loss:0.0154902206588\n",
      "train loss:0.00985748935623\n",
      "train loss:0.000332858459023\n",
      "train loss:0.00162822472207\n",
      "train loss:0.00378647301423\n",
      "train loss:0.0526686836556\n",
      "train loss:0.00334738921238\n",
      "train loss:0.0103443381864\n",
      "train loss:0.0182289194275\n",
      "train loss:0.00665712020038\n",
      "train loss:0.000266792216714\n",
      "train loss:0.0139683751199\n",
      "train loss:0.00607810002532\n",
      "train loss:0.00596565072969\n",
      "train loss:0.00502500791921\n",
      "train loss:0.0180795445852\n",
      "train loss:0.00445442303469\n",
      "train loss:0.00574969263447\n",
      "train loss:0.0131621998264\n",
      "train loss:0.0178772959115\n",
      "train loss:0.0387792130664\n",
      "train loss:0.012157330746\n",
      "train loss:0.00356197066746\n",
      "train loss:0.0257721146826\n",
      "train loss:0.00796946701338\n",
      "train loss:0.015963840687\n",
      "train loss:0.0619890593039\n",
      "train loss:0.0137503306258\n",
      "train loss:0.0169789676774\n",
      "train loss:0.0228539202692\n",
      "train loss:0.00231903992093\n",
      "train loss:0.00277526549214\n",
      "train loss:0.00175910524115\n",
      "train loss:0.0117968626269\n",
      "train loss:0.00136261376758\n",
      "train loss:0.0184694270604\n",
      "train loss:0.0290992379786\n",
      "train loss:0.00345938526192\n",
      "train loss:0.0058132691955\n",
      "train loss:0.0119490667534\n",
      "train loss:0.0223095653092\n",
      "train loss:0.0144593277247\n",
      "train loss:0.016277937561\n",
      "train loss:0.00274829766689\n",
      "train loss:0.00351702701093\n",
      "train loss:0.00181538239154\n",
      "train loss:0.00505872483611\n",
      "train loss:0.0102261141358\n",
      "train loss:0.00586017473017\n",
      "train loss:0.00940718363931\n",
      "train loss:0.0210631159652\n",
      "train loss:0.0110633148649\n",
      "train loss:0.0091432681994\n",
      "train loss:0.00371173749164\n",
      "train loss:0.007804085427\n",
      "train loss:0.00521916156285\n",
      "train loss:0.0137821091856\n",
      "train loss:0.00777779267701\n",
      "train loss:0.00631995204773\n",
      "train loss:0.005170045873\n",
      "train loss:0.00108912315239\n",
      "train loss:0.00344510398057\n",
      "train loss:0.0030393876873\n",
      "train loss:0.00257568331178\n",
      "train loss:0.0171203623699\n",
      "train loss:0.00104514346023\n",
      "train loss:0.00151773377975\n",
      "train loss:0.00459307913948\n",
      "train loss:0.0095301324214\n",
      "train loss:0.00424462314194\n",
      "train loss:0.0457146128402\n",
      "train loss:0.0210645145209\n",
      "train loss:0.00391501226035\n",
      "train loss:0.000418411933424\n",
      "train loss:0.00451564143233\n",
      "train loss:0.0023873148256\n",
      "train loss:0.00810330535713\n",
      "train loss:0.00719359093189\n",
      "train loss:0.0138444777229\n",
      "train loss:0.00432500500768\n",
      "train loss:0.00776996208241\n",
      "train loss:0.00325254273596\n",
      "train loss:0.0106812639677\n",
      "train loss:0.0058390518042\n",
      "train loss:0.00680856227443\n",
      "train loss:0.0342667892926\n",
      "train loss:0.00394628864513\n",
      "train loss:0.00182655825199\n",
      "train loss:0.079881637745\n",
      "train loss:0.00775183051685\n",
      "train loss:0.00018021905454\n",
      "train loss:0.00236284302456\n",
      "train loss:0.00263437448137\n",
      "train loss:0.0161067092282\n",
      "train loss:0.0114554496756\n",
      "train loss:0.00121542162192\n",
      "train loss:0.000401440780536\n",
      "train loss:0.00283743888876\n",
      "train loss:0.00281494092663\n",
      "train loss:0.00195934768213\n",
      "train loss:0.0257688488225\n",
      "train loss:0.00518938573395\n",
      "train loss:0.00410705688297\n",
      "train loss:0.0119269461352\n",
      "train loss:0.00403389700846\n",
      "train loss:0.00886469016721\n",
      "train loss:0.00325001245758\n",
      "train loss:0.00468817110673\n",
      "train loss:0.00508095392105\n",
      "train loss:0.00779822637728\n",
      "train loss:0.00552918974338\n",
      "train loss:0.00323539875793\n",
      "train loss:0.0166830662068\n",
      "train loss:0.0110571736684\n",
      "train loss:0.0118301006632\n",
      "train loss:0.0209815505534\n",
      "train loss:0.00300425433392\n",
      "train loss:0.00276200442215\n",
      "train loss:0.000826925307595\n",
      "train loss:0.00109228089281\n",
      "train loss:0.0143001166144\n",
      "train loss:0.00706127455385\n",
      "train loss:0.0486491886302\n",
      "train loss:0.00246713265777\n",
      "train loss:0.00645768460981\n",
      "train loss:0.00250404614899\n",
      "train loss:0.0103999778676\n",
      "train loss:0.0179781168218\n",
      "train loss:0.00437066449773\n",
      "train loss:0.0126530946692\n",
      "train loss:0.00705618520002\n",
      "train loss:0.005238049527\n",
      "train loss:0.00336756728038\n",
      "train loss:0.00893623257535\n",
      "train loss:0.00492781322996\n",
      "train loss:0.000478099149253\n",
      "train loss:0.0114000806029\n",
      "train loss:0.00344693487707\n",
      "train loss:0.00478800284354\n",
      "train loss:0.00196735299462\n",
      "train loss:0.0229292271588\n",
      "train loss:0.00932165129357\n",
      "train loss:0.000810999672876\n",
      "train loss:0.00382847908282\n",
      "train loss:0.0185093150152\n",
      "train loss:0.00321898248158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000670387146331\n",
      "train loss:0.0436640485303\n",
      "train loss:0.0237402851291\n",
      "train loss:0.00498038282085\n",
      "train loss:0.00581534400294\n",
      "train loss:0.00991912929158\n",
      "train loss:0.00264596728788\n",
      "train loss:0.0161643803871\n",
      "train loss:0.00365322114355\n",
      "train loss:0.00229209576574\n",
      "train loss:0.00360219637941\n",
      "train loss:0.013846262941\n",
      "train loss:0.0155172108362\n",
      "train loss:0.00175585805903\n",
      "train loss:0.0032921147869\n",
      "train loss:0.00424210551809\n",
      "train loss:0.00844156276478\n",
      "train loss:0.0441907831427\n",
      "train loss:0.0165507607265\n",
      "train loss:0.0118585588363\n",
      "train loss:0.0107369721147\n",
      "train loss:0.00205922119293\n",
      "train loss:0.0261308892914\n",
      "train loss:0.00278064074651\n",
      "train loss:0.00102547442833\n",
      "train loss:0.0118825198266\n",
      "train loss:0.0141507462433\n",
      "train loss:0.0192200967801\n",
      "train loss:0.00675000632229\n",
      "train loss:0.000656053698002\n",
      "train loss:0.00260022592669\n",
      "train loss:0.00190099931031\n",
      "train loss:0.00117777750244\n",
      "train loss:0.00258522924828\n",
      "train loss:0.00847078350959\n",
      "train loss:0.00692800615785\n",
      "train loss:0.00610406416267\n",
      "train loss:0.00574033880537\n",
      "train loss:0.00415497231067\n",
      "train loss:0.017277368246\n",
      "train loss:0.00401865268945\n",
      "train loss:0.0055030583585\n",
      "train loss:0.0170762485509\n",
      "train loss:0.010308031402\n",
      "train loss:0.00184927711126\n",
      "train loss:0.00273161860481\n",
      "train loss:0.0262883874897\n",
      "train loss:0.00252591023818\n",
      "train loss:0.0102071439362\n",
      "train loss:0.00457160589495\n",
      "train loss:0.0134601040359\n",
      "train loss:0.00358930258865\n",
      "train loss:0.015648551662\n",
      "train loss:0.00239445337943\n",
      "train loss:0.0372667564812\n",
      "train loss:0.00974214392916\n",
      "train loss:0.00385670246278\n",
      "train loss:0.0114787502326\n",
      "train loss:0.0176149457596\n",
      "train loss:0.00225317412936\n",
      "train loss:0.0152604528311\n",
      "train loss:0.0110863036833\n",
      "train loss:0.00297758762671\n",
      "train loss:0.0162333613551\n",
      "train loss:0.00140129471725\n",
      "train loss:0.0011348921493\n",
      "train loss:0.0131632666806\n",
      "train loss:0.00668585701928\n",
      "train loss:0.00556850811469\n",
      "train loss:0.00215157122267\n",
      "train loss:0.00343312386035\n",
      "train loss:0.0300752123183\n",
      "train loss:0.00576429676632\n",
      "train loss:0.00724417019302\n",
      "train loss:0.02999079615\n",
      "train loss:0.00173672889503\n",
      "train loss:0.00246072306011\n",
      "train loss:0.00441017227404\n",
      "train loss:0.000389603953854\n",
      "train loss:0.0147153876357\n",
      "train loss:0.00438689345086\n",
      "train loss:0.00335738124966\n",
      "train loss:0.00528564037753\n",
      "train loss:0.00195553664727\n",
      "train loss:0.00336719171205\n",
      "train loss:0.014057455539\n",
      "train loss:0.0111027157178\n",
      "train loss:0.0213777669706\n",
      "train loss:0.00478726534928\n",
      "train loss:0.00371334459698\n",
      "train loss:0.027315702585\n",
      "train loss:0.00451499359239\n",
      "train loss:0.00366332629366\n",
      "train loss:0.00440473885853\n",
      "train loss:0.0347369703572\n",
      "train loss:0.0299287899439\n",
      "train loss:0.0408184695523\n",
      "train loss:0.0359851413437\n",
      "train loss:0.000901007034802\n",
      "train loss:0.00855313604205\n",
      "train loss:0.0384543248789\n",
      "train loss:0.00101188877149\n",
      "train loss:0.0061350978318\n",
      "train loss:0.0108202230263\n",
      "train loss:0.0011522953795\n",
      "train loss:0.0116700009169\n",
      "train loss:0.00840864558151\n",
      "train loss:0.00604163347695\n",
      "train loss:0.00222728562517\n",
      "train loss:0.0130551443813\n",
      "train loss:0.00351814177546\n",
      "train loss:0.00431978581742\n",
      "train loss:0.00623405823301\n",
      "train loss:0.00569434259968\n",
      "train loss:0.0108030692218\n",
      "train loss:0.00195431274302\n",
      "train loss:0.00256343684908\n",
      "train loss:0.00328259306835\n",
      "train loss:0.00728196936315\n",
      "train loss:0.00193940109715\n",
      "train loss:0.00285236898606\n",
      "train loss:0.0307663665093\n",
      "train loss:0.00952105058713\n",
      "train loss:0.00177958056686\n",
      "train loss:0.0204419967556\n",
      "train loss:0.00569226087398\n",
      "train loss:0.00829762802373\n",
      "train loss:0.00416881459681\n",
      "train loss:0.00694730926811\n",
      "train loss:0.00622813690922\n",
      "train loss:0.00434269410263\n",
      "train loss:0.00482973555555\n",
      "train loss:0.00499630264416\n",
      "train loss:0.00802131379152\n",
      "train loss:0.00125650519147\n",
      "train loss:0.011901680447\n",
      "train loss:0.001591226739\n",
      "train loss:0.00938750622312\n",
      "train loss:0.00330308013999\n",
      "train loss:0.00840148099021\n",
      "train loss:0.0240830152389\n",
      "train loss:0.0164581963526\n",
      "train loss:0.0133361275866\n",
      "train loss:0.00112503750946\n",
      "train loss:0.00298383967425\n",
      "train loss:0.0273735055194\n",
      "train loss:0.00682495411351\n",
      "train loss:0.0454290510644\n",
      "train loss:0.00231215580423\n",
      "train loss:0.0018079473098\n",
      "train loss:0.0453318123314\n",
      "train loss:0.0019081320496\n",
      "train loss:0.00510543922097\n",
      "train loss:0.00496869063128\n",
      "train loss:0.00946768088811\n",
      "train loss:0.0028915930134\n",
      "train loss:0.00179014246984\n",
      "train loss:0.00263904626641\n",
      "train loss:0.0214883588636\n",
      "train loss:0.00827454839519\n",
      "train loss:0.00683492611372\n",
      "train loss:0.000570913550019\n",
      "train loss:0.0341948564278\n",
      "train loss:0.0125169274362\n",
      "train loss:0.0022240495066\n",
      "train loss:0.00547785051073\n",
      "train loss:0.00247184726101\n",
      "train loss:0.0103040350031\n",
      "train loss:0.00348885007344\n",
      "train loss:0.00415448154677\n",
      "train loss:0.0253944256362\n",
      "train loss:0.00652604729349\n",
      "train loss:0.00995746960836\n",
      "train loss:0.0035638356801\n",
      "train loss:0.0833010447071\n",
      "train loss:0.0102212376515\n",
      "train loss:0.00668986470484\n",
      "train loss:0.0041799537565\n",
      "train loss:0.00118594488436\n",
      "train loss:0.0168363386287\n",
      "train loss:0.0119226605212\n",
      "train loss:0.00470242005076\n",
      "train loss:0.002166025421\n",
      "train loss:0.00381696314075\n",
      "train loss:0.00375146212584\n",
      "train loss:0.0121774394535\n",
      "train loss:0.0195395014405\n",
      "train loss:0.00641535617618\n",
      "train loss:0.00256603142189\n",
      "train loss:0.000960521732617\n",
      "train loss:0.0051423116059\n",
      "train loss:0.00843168895351\n",
      "train loss:0.00522940075489\n",
      "train loss:0.00627414893632\n",
      "train loss:0.00708425341004\n",
      "train loss:0.00349359599731\n",
      "train loss:0.00108188970418\n",
      "train loss:0.00450758373853\n",
      "train loss:0.0333311451319\n",
      "train loss:0.00125282846047\n",
      "train loss:0.00168153690826\n",
      "train loss:0.0110967825154\n",
      "train loss:0.000631370175168\n",
      "train loss:0.0109659769685\n",
      "train loss:0.00989322541351\n",
      "train loss:0.00200602876928\n",
      "train loss:0.0148565567132\n",
      "train loss:0.00545252072248\n",
      "train loss:0.0052645372654\n",
      "train loss:0.00033246677491\n",
      "train loss:0.00322814479373\n",
      "train loss:0.0238631734787\n",
      "train loss:0.00131688627898\n",
      "train loss:0.00205373301957\n",
      "train loss:0.00306452461458\n",
      "train loss:0.00276519504625\n",
      "train loss:0.00423405093315\n",
      "train loss:0.00791317331376\n",
      "train loss:0.00314285826763\n",
      "train loss:0.00307967412674\n",
      "train loss:0.00735422909197\n",
      "train loss:0.00204767375362\n",
      "train loss:0.00577607028337\n",
      "train loss:0.00074074133021\n",
      "train loss:0.0602117236164\n",
      "train loss:0.0378238577284\n",
      "train loss:0.0122242949713\n",
      "train loss:0.00601044361302\n",
      "train loss:0.00240824788627\n",
      "train loss:0.0006283275012\n",
      "train loss:0.00244861347043\n",
      "train loss:0.000962127397365\n",
      "train loss:0.00377688458284\n",
      "train loss:0.00338873862347\n",
      "train loss:0.0171821201395\n",
      "train loss:0.00390624817623\n",
      "train loss:0.0155738518032\n",
      "train loss:0.00887785791881\n",
      "train loss:0.00439825514493\n",
      "train loss:0.0466545928488\n",
      "train loss:0.00131282352761\n",
      "train loss:0.00381617496809\n",
      "train loss:0.00468543982121\n",
      "train loss:0.00142097219058\n",
      "train loss:0.015772535525\n",
      "train loss:0.00378247562936\n",
      "train loss:0.0274773852356\n",
      "train loss:0.00178932644526\n",
      "train loss:0.00579845696155\n",
      "train loss:0.00382746947683\n",
      "=== epoch:11, train acc:0.993, test acc:0.985 ===\n",
      "train loss:0.0054028167241\n",
      "train loss:0.00486167044334\n",
      "train loss:0.0212017900096\n",
      "train loss:0.00754085965149\n",
      "train loss:0.00786308495272\n",
      "train loss:0.00197598203066\n",
      "train loss:0.00276236970252\n",
      "train loss:0.00539139724696\n",
      "train loss:0.0280988561272\n",
      "train loss:0.000689630519003\n",
      "train loss:0.0129765056918\n",
      "train loss:0.00292965147433\n",
      "train loss:0.0161717588261\n",
      "train loss:0.00910369827984\n",
      "train loss:0.0499114602078\n",
      "train loss:0.00897757108464\n",
      "train loss:0.0069120271705\n",
      "train loss:0.00190885774725\n",
      "train loss:0.00142506910444\n",
      "train loss:0.0108822456909\n",
      "train loss:0.00223617061909\n",
      "train loss:0.00243289686071\n",
      "train loss:0.00803398971461\n",
      "train loss:0.016115331542\n",
      "train loss:0.00730808058685\n",
      "train loss:0.00551997361586\n",
      "train loss:0.00434262548874\n",
      "train loss:0.01347058808\n",
      "train loss:0.00690489953566\n",
      "train loss:0.00950191851831\n",
      "train loss:0.00324470549643\n",
      "train loss:0.00825421895973\n",
      "train loss:0.0143421804024\n",
      "train loss:0.00105049756129\n",
      "train loss:0.00371152364843\n",
      "train loss:0.00638407238364\n",
      "train loss:0.00194908776329\n",
      "train loss:0.00819785125549\n",
      "train loss:0.00147153211736\n",
      "train loss:0.00232026307769\n",
      "train loss:0.00576803893161\n",
      "train loss:0.0297824217171\n",
      "train loss:0.00482779349103\n",
      "train loss:0.019145927328\n",
      "train loss:0.00840687190932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00565802361654\n",
      "train loss:0.00480165559518\n",
      "train loss:0.00561217283114\n",
      "train loss:0.0031056170452\n",
      "train loss:0.00173592895876\n",
      "train loss:0.00354325126883\n",
      "train loss:0.00496662586196\n",
      "train loss:0.00275316982024\n",
      "train loss:0.0106411247077\n",
      "train loss:0.00493940701969\n",
      "train loss:0.0115116793444\n",
      "train loss:0.0054100943956\n",
      "train loss:0.0100963236404\n",
      "train loss:0.00968242852673\n",
      "train loss:0.00564846463216\n",
      "train loss:0.00852190000572\n",
      "train loss:0.000973001856058\n",
      "train loss:0.00145115672008\n",
      "train loss:0.0058571038034\n",
      "train loss:0.00109071150506\n",
      "train loss:0.00266559826513\n",
      "train loss:0.00210829012052\n",
      "train loss:0.00129499083754\n",
      "train loss:0.0109318193464\n",
      "train loss:0.00502198194529\n",
      "train loss:0.000835910705183\n",
      "train loss:0.00279463066752\n",
      "train loss:0.00666278086227\n",
      "train loss:0.00310561085824\n",
      "train loss:0.00551343162678\n",
      "train loss:0.00236828861228\n",
      "train loss:0.0085106438188\n",
      "train loss:0.00371818579708\n",
      "train loss:0.000745313368215\n",
      "train loss:0.0116967737466\n",
      "train loss:0.000559421240522\n",
      "train loss:0.00632419311777\n",
      "train loss:0.00448800429523\n",
      "train loss:0.00611964876319\n",
      "train loss:0.00862428341519\n",
      "train loss:0.00654665153567\n",
      "train loss:0.00523229459503\n",
      "train loss:0.000767201110328\n",
      "train loss:0.00533181816068\n",
      "train loss:0.0194364274865\n",
      "train loss:0.000369695188297\n",
      "train loss:0.0273726977255\n",
      "train loss:0.00617260668986\n",
      "train loss:0.00437580790919\n",
      "train loss:0.00366701226069\n",
      "train loss:0.00555346097184\n",
      "train loss:0.00475141598667\n",
      "train loss:0.00223549653773\n",
      "train loss:0.00376866745166\n",
      "train loss:0.00145913033972\n",
      "train loss:0.00687803702804\n",
      "train loss:0.00262050502609\n",
      "train loss:0.000327899139469\n",
      "train loss:0.00194082669724\n",
      "train loss:0.000460281066523\n",
      "train loss:0.0144970236736\n",
      "train loss:0.00429062013524\n",
      "train loss:0.00327784091437\n",
      "train loss:0.0028465441434\n",
      "train loss:0.00289970323305\n",
      "train loss:0.00456481336886\n",
      "train loss:0.00144462052572\n",
      "train loss:0.000584554937143\n",
      "train loss:0.00517973090588\n",
      "train loss:0.00526973605308\n",
      "train loss:0.00325387013056\n",
      "train loss:0.0305637257687\n",
      "train loss:0.00127284710387\n",
      "train loss:0.00212564157914\n",
      "train loss:0.00774898920423\n",
      "train loss:0.00651175247013\n",
      "train loss:0.000318224520888\n",
      "train loss:0.00045082854616\n",
      "train loss:0.00161603023993\n",
      "train loss:0.00135394857468\n",
      "train loss:0.00314809504319\n",
      "train loss:0.00376190570117\n",
      "train loss:0.0591491022421\n",
      "train loss:0.0100467438832\n",
      "train loss:0.00812436032874\n",
      "train loss:0.00345185109248\n",
      "train loss:0.00359390343798\n",
      "train loss:0.00620160687616\n",
      "train loss:0.000730771349329\n",
      "train loss:0.00399888628616\n",
      "train loss:0.00282454229885\n",
      "train loss:0.00673762108537\n",
      "train loss:0.00627989520233\n",
      "train loss:0.00628958195783\n",
      "train loss:0.000935685275918\n",
      "train loss:0.0137363211364\n",
      "train loss:0.00119884719272\n",
      "train loss:0.00206270617587\n",
      "train loss:0.00516186624956\n",
      "train loss:0.0129322562767\n",
      "train loss:0.00213298588108\n",
      "train loss:0.00298837251104\n",
      "train loss:0.0014290749811\n",
      "train loss:0.00324728327243\n",
      "train loss:0.00190471572359\n",
      "train loss:0.00543405993285\n",
      "train loss:0.00251931757056\n",
      "train loss:0.00458208502568\n",
      "train loss:0.00125451496773\n",
      "train loss:0.00185052931967\n",
      "train loss:0.00289480919794\n",
      "train loss:0.000579699824625\n",
      "train loss:0.00312545071183\n",
      "train loss:0.00175003429156\n",
      "train loss:0.00148400495739\n",
      "train loss:0.00232810658881\n",
      "train loss:0.0110641470503\n",
      "train loss:0.00394271921596\n",
      "train loss:0.00227674118355\n",
      "train loss:0.00601639924305\n",
      "train loss:0.00141984966269\n",
      "train loss:0.00468718865766\n",
      "train loss:0.000529424035541\n",
      "train loss:0.00926886483523\n",
      "train loss:0.00702840077645\n",
      "train loss:0.000838919567382\n",
      "train loss:0.00511472312834\n",
      "train loss:0.00228674942744\n",
      "train loss:0.00594172861194\n",
      "train loss:0.00217133776411\n",
      "train loss:0.000769504260443\n",
      "train loss:0.00601104470285\n",
      "train loss:0.00150580774497\n",
      "train loss:0.00978993838028\n",
      "train loss:0.00222767571385\n",
      "train loss:0.00091656643008\n",
      "train loss:0.000779007920052\n",
      "train loss:0.00459815764575\n",
      "train loss:0.000548091171235\n",
      "train loss:0.00142451804909\n",
      "train loss:0.000834435198881\n",
      "train loss:0.000687332881319\n",
      "train loss:0.0262820328692\n",
      "train loss:0.0478937674752\n",
      "train loss:0.00493755245055\n",
      "train loss:0.000364665433184\n",
      "train loss:0.000711146549397\n",
      "train loss:0.000709817676946\n",
      "train loss:0.00144237048703\n",
      "train loss:0.00475783480139\n",
      "train loss:0.000861530685267\n",
      "train loss:0.0125296284503\n",
      "train loss:0.00535348604228\n",
      "train loss:0.00687738105584\n",
      "train loss:0.00167576608782\n",
      "train loss:0.00336436613314\n",
      "train loss:0.00184144840116\n",
      "train loss:0.000186248965476\n",
      "train loss:0.00294421208532\n",
      "train loss:0.00175345405765\n",
      "train loss:0.026519239198\n",
      "train loss:0.00966420899138\n",
      "train loss:0.00939896653486\n",
      "train loss:0.00179896762504\n",
      "train loss:0.00171564450145\n",
      "train loss:0.00196699613266\n",
      "train loss:0.00116129393082\n",
      "train loss:0.00105028526419\n",
      "train loss:0.000383797687645\n",
      "train loss:0.0016042233025\n",
      "train loss:0.0019691338785\n",
      "train loss:0.00188495758285\n",
      "train loss:0.00143508649441\n",
      "train loss:0.00124934998239\n",
      "train loss:0.0109284501097\n",
      "train loss:0.0132578883845\n",
      "train loss:0.0150425647785\n",
      "train loss:0.0234496364111\n",
      "train loss:0.0035917094916\n",
      "train loss:0.00369268255737\n",
      "train loss:0.00122441827205\n",
      "train loss:0.00365408871276\n",
      "train loss:0.00846752640597\n",
      "train loss:0.0219690104631\n",
      "train loss:0.00637249120184\n",
      "train loss:0.00281174300118\n",
      "train loss:0.00473554338397\n",
      "train loss:0.00351069753005\n",
      "train loss:0.00525664732029\n",
      "train loss:0.00383113332976\n",
      "train loss:0.0251341195658\n",
      "train loss:0.00458846389073\n",
      "train loss:0.00158000359509\n",
      "train loss:0.00301260332059\n",
      "train loss:0.00362890774733\n",
      "train loss:0.0157276750756\n",
      "train loss:0.00120303121736\n",
      "train loss:0.00409433875629\n",
      "train loss:0.0230684390091\n",
      "train loss:0.0118385228903\n",
      "train loss:0.00990878937205\n",
      "train loss:0.0054753646819\n",
      "train loss:0.00566768819905\n",
      "train loss:0.00280222583628\n",
      "train loss:0.0105290590026\n",
      "train loss:0.00370195381343\n",
      "train loss:0.00146694677007\n",
      "train loss:0.0107392907793\n",
      "train loss:0.00639192377054\n",
      "train loss:0.00248722265274\n",
      "train loss:0.00213544478218\n",
      "train loss:0.0127622339325\n",
      "train loss:0.00483281320891\n",
      "train loss:0.00353849434193\n",
      "train loss:0.00362106720333\n",
      "train loss:0.00144452439561\n",
      "train loss:0.00132379922231\n",
      "train loss:0.0014731754062\n",
      "train loss:0.0180162765312\n",
      "train loss:0.0254121069515\n",
      "train loss:0.00960704625219\n",
      "train loss:0.0134687428538\n",
      "train loss:0.0129293998954\n",
      "train loss:0.0135896317459\n",
      "train loss:0.00192174319137\n",
      "train loss:0.00129591657144\n",
      "train loss:0.00245795464758\n",
      "train loss:0.00083913593923\n",
      "train loss:0.00287281119003\n",
      "train loss:0.00187989357726\n",
      "train loss:0.0025697822262\n",
      "train loss:0.00280101976879\n",
      "train loss:0.0035300404974\n",
      "train loss:0.0022887768055\n",
      "train loss:0.00871407048359\n",
      "train loss:0.00360548088291\n",
      "train loss:0.00673416818919\n",
      "train loss:0.00479128607384\n",
      "train loss:0.00576226464449\n",
      "train loss:0.000500483855056\n",
      "train loss:0.0090837371454\n",
      "train loss:0.035847915258\n",
      "train loss:0.0160284315064\n",
      "train loss:0.000513250508172\n",
      "train loss:0.00184410709092\n",
      "train loss:0.00533418218196\n",
      "train loss:0.023364711191\n",
      "train loss:0.00334855272203\n",
      "train loss:0.00169353684803\n",
      "train loss:0.00499453090129\n",
      "train loss:0.00273354580438\n",
      "train loss:0.00342401387224\n",
      "train loss:0.00728268831729\n",
      "train loss:0.0209155411391\n",
      "train loss:0.0119149487959\n",
      "train loss:0.000461406203956\n",
      "train loss:0.00731056097077\n",
      "train loss:0.00338007570721\n",
      "train loss:0.00407464896806\n",
      "train loss:0.00735086844493\n",
      "train loss:0.00638106757452\n",
      "train loss:0.00150901610579\n",
      "train loss:0.00420158452152\n",
      "train loss:0.0384469763814\n",
      "train loss:0.00337048111515\n",
      "train loss:0.0543548391293\n",
      "train loss:0.00129978751253\n",
      "train loss:0.000748248383166\n",
      "train loss:0.00613562514991\n",
      "train loss:0.00902398400445\n",
      "train loss:0.00100425766235\n",
      "train loss:0.0032918989568\n",
      "train loss:0.0228424815413\n",
      "train loss:0.00920431409213\n",
      "train loss:0.00590445497537\n",
      "train loss:0.00245307588326\n",
      "train loss:0.0209741904348\n",
      "train loss:0.00269615551031\n",
      "train loss:0.0137919963554\n",
      "train loss:0.00430160733648\n",
      "train loss:0.0387932344871\n",
      "train loss:0.00288501677343\n",
      "train loss:0.00832699423845\n",
      "train loss:0.00624405250014\n",
      "train loss:0.00195035847264\n",
      "train loss:0.0185740986914\n",
      "train loss:0.02708473064\n",
      "train loss:0.00732773822209\n",
      "train loss:0.00281003679847\n",
      "train loss:0.00471427215144\n",
      "train loss:0.00159338885449\n",
      "train loss:0.0530590754909\n",
      "train loss:0.0111330102698\n",
      "train loss:0.00778571208526\n",
      "train loss:0.00621863034971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00830121477094\n",
      "train loss:0.00192870346748\n",
      "train loss:0.00163605927568\n",
      "train loss:0.00958249625598\n",
      "train loss:0.027995300291\n",
      "train loss:0.00438949523563\n",
      "train loss:0.00452653691974\n",
      "train loss:0.00345441500521\n",
      "train loss:0.00587826190398\n",
      "train loss:0.0023950561928\n",
      "train loss:0.00202884994021\n",
      "train loss:0.00170554428312\n",
      "train loss:0.00107019126781\n",
      "train loss:0.00601081049426\n",
      "train loss:0.00372514731873\n",
      "train loss:0.00747035420939\n",
      "train loss:0.00214050996081\n",
      "train loss:0.00252577929752\n",
      "train loss:0.00320229945837\n",
      "train loss:0.00354627439699\n",
      "train loss:0.00338309631461\n",
      "train loss:0.0788688831763\n",
      "train loss:0.0335872156189\n",
      "train loss:0.00579377075365\n",
      "train loss:0.0124367425971\n",
      "train loss:0.00134474747558\n",
      "train loss:0.00605790134348\n",
      "train loss:0.0103985295605\n",
      "train loss:0.00605705828774\n",
      "train loss:0.00225713106747\n",
      "train loss:0.00353964947575\n",
      "train loss:0.00277136749912\n",
      "train loss:0.00572847388672\n",
      "train loss:0.00274327665278\n",
      "train loss:0.0332808814061\n",
      "train loss:0.00798802156582\n",
      "train loss:0.00420278865298\n",
      "train loss:0.048623365806\n",
      "train loss:0.00105125933356\n",
      "train loss:0.0375158739533\n",
      "train loss:0.0213769816085\n",
      "train loss:0.00841087245537\n",
      "train loss:0.0197091602434\n",
      "train loss:0.0100186810273\n",
      "train loss:0.00203930698074\n",
      "train loss:0.00233901668337\n",
      "train loss:0.0157169636774\n",
      "train loss:0.0125257279593\n",
      "train loss:0.00128899868492\n",
      "train loss:0.0023032010221\n",
      "train loss:0.00269374329962\n",
      "train loss:0.00425709710809\n",
      "train loss:0.00166136113325\n",
      "train loss:0.0107342273438\n",
      "train loss:0.0181758312912\n",
      "train loss:0.0175909634461\n",
      "train loss:0.000808739295598\n",
      "train loss:0.00473319026079\n",
      "train loss:0.00471311191748\n",
      "train loss:0.00650186049747\n",
      "train loss:0.00837842715263\n",
      "train loss:0.0145465918847\n",
      "train loss:0.00158430417401\n",
      "train loss:0.00211713557206\n",
      "train loss:0.00158327906262\n",
      "train loss:0.0127500484381\n",
      "train loss:0.00447460709515\n",
      "train loss:0.00515785290143\n",
      "train loss:0.00218137174969\n",
      "train loss:0.00134931261091\n",
      "train loss:0.00414157526926\n",
      "train loss:0.00226029400266\n",
      "train loss:0.0114823646457\n",
      "train loss:0.00255102713803\n",
      "train loss:0.0104042651993\n",
      "train loss:0.00262442099136\n",
      "train loss:0.00270605279496\n",
      "train loss:0.00215548565661\n",
      "train loss:0.00242816396163\n",
      "train loss:0.00111731966017\n",
      "train loss:0.083267919398\n",
      "train loss:0.00842256155022\n",
      "train loss:0.00659450228367\n",
      "train loss:0.0027164214229\n",
      "train loss:0.00642817619126\n",
      "train loss:0.00926443134653\n",
      "train loss:0.00564950221221\n",
      "train loss:0.00180445046812\n",
      "train loss:0.0496546982217\n",
      "train loss:0.00336576791321\n",
      "train loss:0.00294445067755\n",
      "train loss:0.00944453900261\n",
      "train loss:0.000743228125258\n",
      "train loss:0.00420098420493\n",
      "train loss:0.00619297553026\n",
      "train loss:0.00983863396306\n",
      "train loss:0.000878030249267\n",
      "train loss:0.00377768283685\n",
      "train loss:0.00196449218479\n",
      "train loss:0.00484316272515\n",
      "train loss:0.0138952214988\n",
      "train loss:0.00321749968512\n",
      "train loss:0.00753781979587\n",
      "train loss:0.0031486909711\n",
      "train loss:0.0121855852646\n",
      "train loss:0.0034532745473\n",
      "train loss:0.000772313113316\n",
      "train loss:0.0130771878833\n",
      "train loss:0.0107916036818\n",
      "train loss:0.00223668747851\n",
      "train loss:0.0376018521296\n",
      "train loss:0.00795210373827\n",
      "train loss:0.00173302519127\n",
      "train loss:0.0082068550178\n",
      "train loss:0.00114517905571\n",
      "train loss:0.00442678271893\n",
      "train loss:0.00458926464728\n",
      "train loss:0.00965410189078\n",
      "train loss:0.00132451309418\n",
      "train loss:0.00203172555096\n",
      "train loss:0.0157186302552\n",
      "train loss:0.000953961053926\n",
      "train loss:0.00132372329748\n",
      "train loss:0.00581742142158\n",
      "train loss:0.00579052947378\n",
      "train loss:0.00934896969124\n",
      "train loss:0.00866682097169\n",
      "train loss:0.00266168923086\n",
      "train loss:0.00231560957832\n",
      "train loss:0.00223957368658\n",
      "train loss:0.00478386709136\n",
      "train loss:0.000842815797047\n",
      "train loss:0.025425781782\n",
      "train loss:0.0011560486562\n",
      "train loss:0.00516460191397\n",
      "train loss:0.0080197179924\n",
      "train loss:0.000619296696691\n",
      "train loss:0.00164459956114\n",
      "train loss:0.000219395975055\n",
      "train loss:0.00116627537367\n",
      "train loss:0.00872265192833\n",
      "train loss:0.00514155358106\n",
      "train loss:0.00122240605017\n",
      "train loss:0.00171060106942\n",
      "train loss:7.64586237992e-05\n",
      "train loss:0.00399609600959\n",
      "train loss:0.00485232872948\n",
      "train loss:0.00340232314576\n",
      "train loss:0.00203609156934\n",
      "train loss:0.0135102904188\n",
      "train loss:0.00259339056171\n",
      "train loss:0.0149822188679\n",
      "train loss:0.00110212063162\n",
      "train loss:0.000807278555075\n",
      "train loss:0.00264623008315\n",
      "train loss:0.00633802130271\n",
      "train loss:0.00408104581139\n",
      "train loss:0.000929931089042\n",
      "train loss:0.00358428647104\n",
      "train loss:0.00158163975861\n",
      "train loss:0.00297473869036\n",
      "train loss:0.00553631286146\n",
      "train loss:0.00154721794039\n",
      "train loss:0.00439872953244\n",
      "train loss:0.0100709603642\n",
      "train loss:0.00402640055857\n",
      "train loss:0.00459257444415\n",
      "train loss:0.0529305524922\n",
      "train loss:0.00231266586623\n",
      "train loss:0.0138847136406\n",
      "train loss:0.00131905817506\n",
      "train loss:0.000664947689611\n",
      "train loss:0.00146815704294\n",
      "train loss:0.00482813162955\n",
      "train loss:0.0172601002718\n",
      "train loss:0.00203391088246\n",
      "train loss:0.00110960304159\n",
      "train loss:0.00365503747974\n",
      "train loss:0.00456401335529\n",
      "train loss:0.0411960780235\n",
      "train loss:0.00389203923919\n",
      "train loss:0.000869956665051\n",
      "train loss:0.00264533641817\n",
      "train loss:0.00748754452767\n",
      "train loss:0.0102114030275\n",
      "train loss:0.000688354199024\n",
      "train loss:0.00111082950371\n",
      "train loss:0.00061615694409\n",
      "train loss:0.00197733192043\n",
      "train loss:0.001516383282\n",
      "train loss:0.00196052000961\n",
      "train loss:0.00510910400446\n",
      "train loss:0.0267967131087\n",
      "train loss:0.00360366450557\n",
      "train loss:0.00699887033936\n",
      "train loss:0.00948074759317\n",
      "train loss:0.00555637333267\n",
      "train loss:0.00598799285794\n",
      "train loss:0.0155908018548\n",
      "train loss:0.00142534802542\n",
      "train loss:0.00590014840023\n",
      "train loss:0.0011156545406\n",
      "train loss:0.00486827451435\n",
      "train loss:0.0170875953897\n",
      "train loss:0.00379715367081\n",
      "train loss:0.0022717497774\n",
      "train loss:0.00141563504796\n",
      "train loss:0.00168297243391\n",
      "train loss:0.0135109349376\n",
      "train loss:0.00146277819886\n",
      "train loss:0.00112636577831\n",
      "train loss:0.0044961109021\n",
      "train loss:0.000505064603609\n",
      "train loss:0.00313064477046\n",
      "train loss:0.00660491240404\n",
      "train loss:0.00196632636327\n",
      "train loss:0.00525475464358\n",
      "train loss:0.00439031622516\n",
      "train loss:0.00212158898475\n",
      "train loss:0.00266949642967\n",
      "train loss:0.00416371075\n",
      "train loss:0.00149240637801\n",
      "train loss:0.0342111995227\n",
      "train loss:0.00285753257062\n",
      "train loss:0.00159677387738\n",
      "train loss:0.0107841027771\n",
      "train loss:0.0182189050831\n",
      "train loss:0.00616090154534\n",
      "train loss:0.00224925068628\n",
      "train loss:0.0139154944259\n",
      "train loss:0.00172037309708\n",
      "train loss:0.0031761387456\n",
      "train loss:0.00235871520996\n",
      "train loss:0.00291814726492\n",
      "train loss:0.00453417059224\n",
      "train loss:0.0117275117417\n",
      "train loss:0.0128807465431\n",
      "train loss:0.00157459531756\n",
      "train loss:0.00243714563309\n",
      "train loss:0.00712461850968\n",
      "train loss:0.00200558940461\n",
      "train loss:0.00577147709423\n",
      "train loss:0.000734745359873\n",
      "train loss:0.0028317243597\n",
      "train loss:0.00452653681976\n",
      "train loss:0.00868036927392\n",
      "train loss:0.0116714676944\n",
      "train loss:0.016761809378\n",
      "train loss:0.0278651979838\n",
      "train loss:0.00825021897831\n",
      "train loss:0.0118526763577\n",
      "train loss:0.00102899032966\n",
      "train loss:0.00372136323165\n",
      "train loss:0.0203024339556\n",
      "train loss:0.00265240084675\n",
      "train loss:0.0232811261941\n",
      "train loss:0.00524112231887\n",
      "train loss:0.00239420888124\n",
      "train loss:0.0103551631046\n",
      "train loss:0.00135205578994\n",
      "=== epoch:12, train acc:0.994, test acc:0.99 ===\n",
      "train loss:0.00390502124788\n",
      "train loss:0.00578373087997\n",
      "train loss:0.0163098716518\n",
      "train loss:0.00365062437392\n",
      "train loss:0.0201754738812\n",
      "train loss:0.0102957313002\n",
      "train loss:0.00140662292311\n",
      "train loss:0.0136313748455\n",
      "train loss:0.00797108745485\n",
      "train loss:0.00676931858337\n",
      "train loss:0.00293262993773\n",
      "train loss:0.00433320917059\n",
      "train loss:0.0138476577652\n",
      "train loss:0.00295792981926\n",
      "train loss:0.00689294026067\n",
      "train loss:0.00703362904611\n",
      "train loss:0.00375437072924\n",
      "train loss:0.00647864030091\n",
      "train loss:0.00229458686083\n",
      "train loss:0.00183978804055\n",
      "train loss:0.00203641780659\n",
      "train loss:0.00108359061946\n",
      "train loss:0.00323991355974\n",
      "train loss:0.00218182690859\n",
      "train loss:0.00322061584814\n",
      "train loss:0.00430552450958\n",
      "train loss:0.00602470997721\n",
      "train loss:0.00860269023229\n",
      "train loss:0.00666076305443\n",
      "train loss:0.0113179416511\n",
      "train loss:0.00302211474445\n",
      "train loss:0.00174269381075\n",
      "train loss:0.000484569316361\n",
      "train loss:0.00112276747636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00770744904563\n",
      "train loss:0.00199695832779\n",
      "train loss:0.00757403625011\n",
      "train loss:0.00227526372337\n",
      "train loss:0.00273063262613\n",
      "train loss:0.000558568107109\n",
      "train loss:0.00339520492522\n",
      "train loss:0.0033725452548\n",
      "train loss:0.0210272467233\n",
      "train loss:0.00427296157659\n",
      "train loss:0.00736226301868\n",
      "train loss:0.00083204615924\n",
      "train loss:0.000891752450736\n",
      "train loss:0.000413085182932\n",
      "train loss:0.00404341728456\n",
      "train loss:0.018969484841\n",
      "train loss:0.00542501118367\n",
      "train loss:0.00197189684246\n",
      "train loss:0.00216956186518\n",
      "train loss:0.00833732478816\n",
      "train loss:0.00405257008879\n",
      "train loss:0.00181821587329\n",
      "train loss:0.0243710119819\n",
      "train loss:0.0014944769381\n",
      "train loss:0.0023488756047\n",
      "train loss:0.00149464914713\n",
      "train loss:0.000847859026549\n",
      "train loss:0.00771256456777\n",
      "train loss:0.00196369611129\n",
      "train loss:0.00986468481855\n",
      "train loss:0.00167726882798\n",
      "train loss:0.102261266067\n",
      "train loss:0.0163236065982\n",
      "train loss:0.00127065217779\n",
      "train loss:0.000150139747294\n",
      "train loss:0.00801624779486\n",
      "train loss:0.00203828576385\n",
      "train loss:0.00128878201443\n",
      "train loss:0.00242429615688\n",
      "train loss:0.00305501704472\n",
      "train loss:0.000563991464581\n",
      "train loss:0.00118769545247\n",
      "train loss:0.00281598106039\n",
      "train loss:0.00161266796983\n",
      "train loss:0.00384165272203\n",
      "train loss:0.0030548906015\n",
      "train loss:0.00634966846723\n",
      "train loss:0.00101253772629\n",
      "train loss:0.00119885200969\n",
      "train loss:0.00144128534331\n",
      "train loss:0.00398506291706\n",
      "train loss:0.00468150251768\n",
      "train loss:0.00144592689505\n",
      "train loss:0.00251709568456\n",
      "train loss:0.000689475525439\n",
      "train loss:0.00644336557236\n",
      "train loss:0.00880308110849\n",
      "train loss:0.00348313480527\n",
      "train loss:0.00409435225548\n",
      "train loss:0.00482485950683\n",
      "train loss:0.00125792930153\n",
      "train loss:0.00497985415828\n",
      "train loss:0.0262691680626\n",
      "train loss:0.00278888741949\n",
      "train loss:0.00108608019976\n",
      "train loss:0.00293221912021\n",
      "train loss:0.000892779935752\n",
      "train loss:0.00398169172884\n",
      "train loss:0.00741730981911\n",
      "train loss:0.00851603132608\n",
      "train loss:0.00733281467339\n",
      "train loss:0.00717104958177\n",
      "train loss:0.00278918765467\n",
      "train loss:0.0113673217287\n",
      "train loss:0.00412789720553\n",
      "train loss:0.0106122489065\n",
      "train loss:0.00667549792994\n",
      "train loss:0.00430534635138\n",
      "train loss:0.00687393357856\n",
      "train loss:0.00086153761397\n",
      "train loss:0.00178508021256\n",
      "train loss:0.0128455521098\n",
      "train loss:0.0160280887409\n",
      "train loss:0.00450014187665\n",
      "train loss:0.00244643079451\n",
      "train loss:0.0116356505886\n",
      "train loss:0.00322112521127\n",
      "train loss:0.00144018119215\n",
      "train loss:0.00353917099729\n",
      "train loss:0.00397277977472\n",
      "train loss:0.00500740280261\n",
      "train loss:0.00201084291616\n",
      "train loss:0.0127083398269\n",
      "train loss:0.00230630798564\n",
      "train loss:0.00289932615212\n",
      "train loss:0.00298588123325\n",
      "train loss:0.00430119046114\n",
      "train loss:0.0107957515027\n",
      "train loss:0.0115681399329\n",
      "train loss:0.00500067896744\n",
      "train loss:0.0223926958333\n",
      "train loss:0.000473609245142\n",
      "train loss:0.00655151750218\n",
      "train loss:0.000746893552221\n",
      "train loss:0.00891223142712\n",
      "train loss:0.00540014865886\n",
      "train loss:0.00218009567809\n",
      "train loss:0.00497013119069\n",
      "train loss:0.00944826778263\n",
      "train loss:0.000732147290444\n",
      "train loss:0.0108843251089\n",
      "train loss:0.0203975715343\n",
      "train loss:0.000806000006132\n",
      "train loss:0.00509680859213\n",
      "train loss:0.00366629416777\n",
      "train loss:0.000469290113667\n",
      "train loss:0.000800689618065\n",
      "train loss:0.000732864175799\n",
      "train loss:0.0105629640472\n",
      "train loss:0.0228955032711\n",
      "train loss:0.0268686681713\n",
      "train loss:0.021896729812\n",
      "train loss:0.00153264416857\n",
      "train loss:0.0176490539322\n",
      "train loss:0.00397692296527\n",
      "train loss:0.00771191269047\n",
      "train loss:0.000212362997287\n",
      "train loss:0.00410276488383\n",
      "train loss:0.0302943277296\n",
      "train loss:0.00306492718285\n",
      "train loss:0.00243479262504\n",
      "train loss:0.00666086975506\n",
      "train loss:0.00419798291914\n",
      "train loss:0.00359269823512\n",
      "train loss:0.00264301979025\n",
      "train loss:0.0216614836191\n",
      "train loss:0.00137931888833\n",
      "train loss:0.00176968231231\n",
      "train loss:0.0249636313092\n",
      "train loss:0.00419909938588\n",
      "train loss:0.00793004540764\n",
      "train loss:0.000734050613254\n",
      "train loss:0.00104610312159\n",
      "train loss:0.00626054796724\n",
      "train loss:0.0167858782796\n",
      "train loss:0.00156398010331\n",
      "train loss:0.022208657268\n",
      "train loss:0.00185469334995\n",
      "train loss:0.0141863067149\n",
      "train loss:0.00249653604205\n",
      "train loss:0.0160396822823\n",
      "train loss:0.00871382061058\n",
      "train loss:0.00257774251485\n",
      "train loss:0.000626326004558\n",
      "train loss:0.0216825972955\n",
      "train loss:0.00526475378475\n",
      "train loss:0.00563622785057\n",
      "train loss:0.0189972830795\n",
      "train loss:0.00544104569403\n",
      "train loss:0.00389581626214\n",
      "train loss:0.0599546156051\n",
      "train loss:0.00916558716885\n",
      "train loss:0.0100773292244\n",
      "train loss:0.00863117235253\n",
      "train loss:0.00168134537999\n",
      "train loss:0.00456882134216\n",
      "train loss:0.00788522591545\n",
      "train loss:0.00486569231599\n",
      "train loss:0.00471839453027\n",
      "train loss:0.000381346877186\n",
      "train loss:0.00416357677286\n",
      "train loss:0.00645917318023\n",
      "train loss:0.00332523437545\n",
      "train loss:0.00264293326974\n",
      "train loss:0.00385048722109\n",
      "train loss:0.00631822471772\n",
      "train loss:0.0449351036058\n",
      "train loss:0.00634359609491\n",
      "train loss:0.00244174647624\n",
      "train loss:0.00537152975611\n",
      "train loss:0.00150152529669\n",
      "train loss:0.0122681581705\n",
      "train loss:0.00397530671643\n",
      "train loss:0.00095608561688\n",
      "train loss:0.00632605668852\n",
      "train loss:0.00722841922517\n",
      "train loss:0.00754276425048\n",
      "train loss:0.0172313763596\n",
      "train loss:0.00182879901059\n",
      "train loss:0.0156138155663\n",
      "train loss:0.00668262763272\n",
      "train loss:0.00260944344516\n",
      "train loss:0.00502037863962\n",
      "train loss:0.0010443862947\n",
      "train loss:0.0047155631883\n",
      "train loss:0.00103898126138\n",
      "train loss:0.00736041945675\n",
      "train loss:0.00836511952868\n",
      "train loss:0.00335437935848\n",
      "train loss:0.0112767685748\n",
      "train loss:0.0132141937987\n",
      "train loss:0.000468812498923\n",
      "train loss:0.00233007127722\n",
      "train loss:0.000169439792586\n",
      "train loss:0.00675336426252\n",
      "train loss:0.00839262666192\n",
      "train loss:0.00226811728735\n",
      "train loss:0.00559141705462\n",
      "train loss:0.00121972329356\n",
      "train loss:0.00216645652504\n",
      "train loss:0.00593080979375\n",
      "train loss:0.00254835342629\n",
      "train loss:0.000887082646804\n",
      "train loss:0.0082606212144\n",
      "train loss:0.00270898795391\n",
      "train loss:0.000735333196518\n",
      "train loss:0.000715813943894\n",
      "train loss:0.00112140798126\n",
      "train loss:0.00123647538488\n",
      "train loss:0.00924920702008\n",
      "train loss:0.00407546039809\n",
      "train loss:0.00327086769285\n",
      "train loss:0.00284123834061\n",
      "train loss:0.000594634583798\n",
      "train loss:0.00152946628829\n",
      "train loss:0.0248623401871\n",
      "train loss:0.00637834187444\n",
      "train loss:0.00381078180426\n",
      "train loss:0.000784875103553\n",
      "train loss:0.00209364394598\n",
      "train loss:0.00173089261204\n",
      "train loss:0.00661748170498\n",
      "train loss:0.00253040868575\n",
      "train loss:0.0092113420719\n",
      "train loss:0.00056070822605\n",
      "train loss:0.00175976520167\n",
      "train loss:0.00906841286439\n",
      "train loss:0.00714585177224\n",
      "train loss:0.00116482064795\n",
      "train loss:0.0127354489478\n",
      "train loss:0.00205739668351\n",
      "train loss:0.000923974550784\n",
      "train loss:0.00690310222359\n",
      "train loss:0.00153995004419\n",
      "train loss:0.0021866700716\n",
      "train loss:0.00140894282867\n",
      "train loss:0.00179781049213\n",
      "train loss:0.00116094679504\n",
      "train loss:0.00387547561023\n",
      "train loss:0.00463502052321\n",
      "train loss:0.0046404414966\n",
      "train loss:0.00123928263859\n",
      "train loss:0.000662104978002\n",
      "train loss:0.0020253315857\n",
      "train loss:0.00591143837222\n",
      "train loss:0.000161536715509\n",
      "train loss:0.00159692908827\n",
      "train loss:0.00132065823548\n",
      "train loss:0.00377239314844\n",
      "train loss:0.00115868255545\n",
      "train loss:0.00078909722033\n",
      "train loss:0.00233332617791\n",
      "train loss:0.00357244484713\n",
      "train loss:0.00215794654715\n",
      "train loss:0.00370850824343\n",
      "train loss:0.00373069111901\n",
      "train loss:0.0149323654123\n",
      "train loss:0.00461598397477\n",
      "train loss:0.00310681778954\n",
      "train loss:8.67993592112e-05\n",
      "train loss:0.0024958888631\n",
      "train loss:0.00617755025576\n",
      "train loss:0.00742111788169\n",
      "train loss:0.00259934615266\n",
      "train loss:0.0037968075935\n",
      "train loss:0.00240499327991\n",
      "train loss:0.0260676467974\n",
      "train loss:0.0192368902682\n",
      "train loss:0.00285066405405\n",
      "train loss:0.00235928880538\n",
      "train loss:0.00252355726353\n",
      "train loss:0.0025800992868\n",
      "train loss:0.060398416475\n",
      "train loss:0.00487151946229\n",
      "train loss:0.00105538330436\n",
      "train loss:0.00154976587432\n",
      "train loss:0.00484459951542\n",
      "train loss:0.0019290095577\n",
      "train loss:0.0186443195689\n",
      "train loss:0.00931686251098\n",
      "train loss:0.0166677570157\n",
      "train loss:0.000609928651844\n",
      "train loss:0.0211933414759\n",
      "train loss:0.00391316648859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000842020960029\n",
      "train loss:0.0191563689945\n",
      "train loss:0.0101011669873\n",
      "train loss:0.00082419795288\n",
      "train loss:0.000724839432722\n",
      "train loss:0.00270221794306\n",
      "train loss:0.0035183152227\n",
      "train loss:0.00709490392574\n",
      "train loss:0.00109003841167\n",
      "train loss:0.00536040064665\n",
      "train loss:0.000763920260604\n",
      "train loss:0.00500860444546\n",
      "train loss:0.0132457039038\n",
      "train loss:0.0108341899397\n",
      "train loss:0.00342338455712\n",
      "train loss:0.00344439517359\n",
      "train loss:0.00337470098992\n",
      "train loss:0.0150159882391\n",
      "train loss:0.002698968957\n",
      "train loss:0.0168917650571\n",
      "train loss:0.000750105332324\n",
      "train loss:0.00287154407095\n",
      "train loss:0.00555240040694\n",
      "train loss:0.0136560105505\n",
      "train loss:0.00385726902262\n",
      "train loss:0.00980625811834\n",
      "train loss:0.00959244241645\n",
      "train loss:0.0207020292287\n",
      "train loss:0.012859226316\n",
      "train loss:0.00102994805899\n",
      "train loss:0.000224769654157\n",
      "train loss:0.000972912697933\n",
      "train loss:0.000951225149733\n",
      "train loss:0.00234817301768\n",
      "train loss:0.0009621099651\n",
      "train loss:0.00355546995447\n",
      "train loss:0.00169060247283\n",
      "train loss:0.00408189457002\n",
      "train loss:0.00270792092812\n",
      "train loss:0.00255544720469\n",
      "train loss:0.00138736791707\n",
      "train loss:0.0129371082283\n",
      "train loss:0.0821561989833\n",
      "train loss:0.00455750614812\n",
      "train loss:0.00266004031401\n",
      "train loss:0.00284011123388\n",
      "train loss:0.00192193990179\n",
      "train loss:0.0164184717067\n",
      "train loss:0.00121237315886\n",
      "train loss:0.00384872966021\n",
      "train loss:0.0029306509048\n",
      "train loss:0.0437434036091\n",
      "train loss:0.00636649875427\n",
      "train loss:0.00357712676645\n",
      "train loss:0.0120634102182\n",
      "train loss:0.0229198435332\n",
      "train loss:0.00820325324435\n",
      "train loss:0.00799501688974\n",
      "train loss:0.00516585401051\n",
      "train loss:0.00483671640693\n",
      "train loss:0.00963099656679\n",
      "train loss:0.0285779809859\n",
      "train loss:0.000459371597354\n",
      "train loss:0.00591445759724\n",
      "train loss:0.00277556321976\n",
      "train loss:0.0268629600658\n",
      "train loss:0.00123705575873\n",
      "train loss:0.00116305291648\n",
      "train loss:0.00507440398327\n",
      "train loss:0.00191711411991\n",
      "train loss:0.000967787309346\n",
      "train loss:0.00434167237665\n",
      "train loss:0.00339051239634\n",
      "train loss:0.00973531087562\n",
      "train loss:0.000878361115701\n",
      "train loss:0.0105071081247\n",
      "train loss:0.00161506751735\n",
      "train loss:0.00251529777528\n",
      "train loss:0.0166109411212\n",
      "train loss:0.00683430712049\n",
      "train loss:0.00191271018716\n",
      "train loss:0.0124185968883\n",
      "train loss:0.000274313843011\n",
      "train loss:0.0103549000435\n",
      "train loss:0.00640410768512\n",
      "train loss:0.00220619967012\n",
      "train loss:0.02634852617\n",
      "train loss:0.0228799882892\n",
      "train loss:0.00100121788647\n",
      "train loss:0.00121851736463\n",
      "train loss:0.00204882229786\n",
      "train loss:0.00209760559109\n",
      "train loss:0.00122718347186\n",
      "train loss:0.00182944259569\n",
      "train loss:0.000138743025479\n",
      "train loss:0.0126936617511\n",
      "train loss:0.0049491484375\n",
      "train loss:0.0138863435538\n",
      "train loss:0.000491293374145\n",
      "train loss:0.00134552036612\n",
      "train loss:0.00308626249822\n",
      "train loss:0.000619709804272\n",
      "train loss:0.00285391811326\n",
      "train loss:0.00202562816257\n",
      "train loss:0.0019096562575\n",
      "train loss:0.00591851089829\n",
      "train loss:0.00461534846513\n",
      "train loss:0.00959266174381\n",
      "train loss:0.00579425834742\n",
      "train loss:0.0129729962604\n",
      "train loss:0.000764196835815\n",
      "train loss:0.000788866016426\n",
      "train loss:0.0227006632236\n",
      "train loss:0.000284061405435\n",
      "train loss:0.0177364561459\n",
      "train loss:0.00150727740352\n",
      "train loss:0.00125865023768\n",
      "train loss:0.0011040462513\n",
      "train loss:0.000413440781951\n",
      "train loss:0.0034792942157\n",
      "train loss:0.00430024912185\n",
      "train loss:0.00199968006844\n",
      "train loss:0.00224528648535\n",
      "train loss:0.0138981723573\n",
      "train loss:0.00456535581687\n",
      "train loss:0.00165400758323\n",
      "train loss:0.00151335274036\n",
      "train loss:0.00478835531425\n",
      "train loss:0.00514511268245\n",
      "train loss:0.000658049981446\n",
      "train loss:0.00273712080201\n",
      "train loss:0.0048929513745\n",
      "train loss:0.00715070583977\n",
      "train loss:0.00149345712939\n",
      "train loss:0.00514073585632\n",
      "train loss:0.00102348085072\n",
      "train loss:0.00697260397805\n",
      "train loss:0.000780137987417\n",
      "train loss:0.097223530297\n",
      "train loss:0.00387638961177\n",
      "train loss:0.00236221976938\n",
      "train loss:0.00244560235388\n",
      "train loss:0.0107103302708\n",
      "train loss:0.00482988448895\n",
      "train loss:0.015493785292\n",
      "train loss:0.00257491116119\n",
      "train loss:0.00135497108417\n",
      "train loss:0.0049672563837\n",
      "train loss:0.00915015709937\n",
      "train loss:0.00748986648954\n",
      "train loss:0.00122691191508\n",
      "train loss:0.00117007370456\n",
      "train loss:0.00186632684248\n",
      "train loss:0.000533072071976\n",
      "train loss:0.00239173204047\n",
      "train loss:0.00270258305869\n",
      "train loss:0.00352384148921\n",
      "train loss:0.00522134662374\n",
      "train loss:0.00147652244958\n",
      "train loss:0.00558995355083\n",
      "train loss:0.00187855616984\n",
      "train loss:0.0108184663503\n",
      "train loss:0.00207890564413\n",
      "train loss:0.0045816486487\n",
      "train loss:0.0204999192322\n",
      "train loss:0.00209297646167\n",
      "train loss:0.00627964778743\n",
      "train loss:0.0163502468547\n",
      "train loss:0.0038992113762\n",
      "train loss:0.000559913101101\n",
      "train loss:0.00212309100142\n",
      "train loss:0.0072534836998\n",
      "train loss:0.000562415664101\n",
      "train loss:0.00302125232041\n",
      "train loss:0.00346581577205\n",
      "train loss:0.0033028141066\n",
      "train loss:0.00176651702327\n",
      "train loss:0.00255289137542\n",
      "train loss:0.00471305855727\n",
      "train loss:0.00280548405368\n",
      "train loss:0.00104396949385\n",
      "train loss:0.000749366050928\n",
      "train loss:0.00261640567528\n",
      "train loss:0.0154535182095\n",
      "train loss:0.00610566084467\n",
      "train loss:0.00022359553579\n",
      "train loss:0.00125309632665\n",
      "train loss:0.00361533029746\n",
      "train loss:0.00699576448\n",
      "train loss:0.00627504963285\n",
      "train loss:0.00153632080733\n",
      "train loss:0.00607457845924\n",
      "train loss:0.0017891852578\n",
      "train loss:0.00740113814953\n",
      "train loss:0.00408176911229\n",
      "train loss:0.000828924317734\n",
      "train loss:0.00157945833278\n",
      "train loss:0.00782051674936\n",
      "train loss:0.00108501716063\n",
      "train loss:0.0354248354191\n",
      "train loss:0.00047546590696\n",
      "train loss:0.00266782459266\n",
      "train loss:0.0148850641966\n",
      "train loss:0.00108767354433\n",
      "train loss:0.00196552355929\n",
      "train loss:0.000433887708487\n",
      "train loss:0.00202925343858\n",
      "train loss:0.00324783426476\n",
      "train loss:0.0488382249108\n",
      "train loss:0.000779100962436\n",
      "train loss:0.00425069157988\n",
      "train loss:0.00157374434602\n",
      "train loss:0.00186238041899\n",
      "train loss:0.00302330276255\n",
      "train loss:0.00549428276712\n",
      "train loss:0.00721271917314\n",
      "train loss:0.00105045182951\n",
      "train loss:0.00330706992836\n",
      "train loss:0.00673246662962\n",
      "train loss:0.0075358529676\n",
      "train loss:0.00116115866949\n",
      "train loss:0.00244245097811\n",
      "train loss:0.00225037534215\n",
      "train loss:0.00258231741501\n",
      "train loss:0.000186025082519\n",
      "train loss:0.000783749684527\n",
      "train loss:0.0051395335432\n",
      "train loss:0.000810344905804\n",
      "train loss:0.00177099060861\n",
      "train loss:0.0154827019385\n",
      "train loss:0.00754992302851\n",
      "train loss:0.000262289969217\n",
      "train loss:0.00423292427643\n",
      "train loss:0.0741976589518\n",
      "train loss:0.000274013607279\n",
      "train loss:0.0287704070075\n",
      "train loss:0.00321871333367\n",
      "train loss:0.011415033266\n",
      "train loss:0.000156475764447\n",
      "train loss:0.00290491955213\n",
      "train loss:0.00128098378984\n",
      "train loss:0.00349197196615\n",
      "train loss:0.00471295162333\n",
      "train loss:0.00157961773795\n",
      "train loss:0.00315979578039\n",
      "train loss:0.000480164295087\n",
      "train loss:0.00151899951028\n",
      "train loss:0.0122386293912\n",
      "train loss:0.0182538509426\n",
      "train loss:0.00663048873021\n",
      "train loss:0.00706711961764\n",
      "train loss:0.00440212278101\n",
      "train loss:0.00316517506422\n",
      "train loss:0.0006698896883\n",
      "train loss:0.00410541116679\n",
      "train loss:0.000804104762378\n",
      "train loss:0.0021741191086\n",
      "train loss:0.00526841125525\n",
      "train loss:0.000958387863257\n",
      "train loss:0.0053551563427\n",
      "train loss:0.0757397032397\n",
      "train loss:0.00426101641513\n",
      "train loss:0.01063993481\n",
      "train loss:0.00357341291267\n",
      "train loss:0.000660465601581\n",
      "train loss:0.0014418077056\n",
      "train loss:0.00492305415924\n",
      "train loss:0.00133835548202\n",
      "train loss:0.00184504720865\n",
      "train loss:0.00365178570601\n",
      "train loss:0.00703013256433\n",
      "train loss:0.00463962278776\n",
      "=== epoch:13, train acc:0.989, test acc:0.986 ===\n",
      "train loss:0.00588074177732\n",
      "train loss:0.00285504806104\n",
      "train loss:0.0102484447819\n",
      "train loss:0.00454221147165\n",
      "train loss:0.00364722698482\n",
      "train loss:0.0314718958108\n",
      "train loss:0.0066538771553\n",
      "train loss:0.00794448252489\n",
      "train loss:0.00514308830649\n",
      "train loss:0.00197264756645\n",
      "train loss:0.00317254635785\n",
      "train loss:0.000930618377826\n",
      "train loss:0.0121370214545\n",
      "train loss:0.000635207795043\n",
      "train loss:0.000793607615363\n",
      "train loss:0.00266205393808\n",
      "train loss:0.000540032733737\n",
      "train loss:0.0102865182695\n",
      "train loss:0.00264065577317\n",
      "train loss:0.0119901965769\n",
      "train loss:0.00100323092223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00226403155558\n",
      "train loss:0.000765750080449\n",
      "train loss:0.000571410812994\n",
      "train loss:0.016644560475\n",
      "train loss:0.00109278960165\n",
      "train loss:0.00722810064002\n",
      "train loss:0.00331325332061\n",
      "train loss:0.00465411633941\n",
      "train loss:0.00282681315865\n",
      "train loss:0.0116606036653\n",
      "train loss:0.00617718672403\n",
      "train loss:0.00774324381833\n",
      "train loss:0.00689958141449\n",
      "train loss:0.00615205109407\n",
      "train loss:0.0100254319532\n",
      "train loss:0.000355593106839\n",
      "train loss:0.0115358559251\n",
      "train loss:0.00381497519275\n",
      "train loss:0.00232403307365\n",
      "train loss:0.000438057015157\n",
      "train loss:0.000419577532351\n",
      "train loss:0.0110958274557\n",
      "train loss:0.00534477717664\n",
      "train loss:0.0042779690955\n",
      "train loss:0.00037959657463\n",
      "train loss:0.000259357560484\n",
      "train loss:0.00114816426946\n",
      "train loss:0.00498981388727\n",
      "train loss:0.00631994581882\n",
      "train loss:0.00875164198356\n",
      "train loss:0.00344271105332\n",
      "train loss:0.000989748097594\n",
      "train loss:0.000415938077981\n",
      "train loss:0.00133227401744\n",
      "train loss:0.00781568899735\n",
      "train loss:0.00327536960577\n",
      "train loss:0.00448038345045\n",
      "train loss:0.00258800955349\n",
      "train loss:0.000114951728569\n",
      "train loss:0.00152862343129\n",
      "train loss:0.0033471832777\n",
      "train loss:0.00265316661233\n",
      "train loss:0.0117657893624\n",
      "train loss:0.010371198127\n",
      "train loss:0.00215040937673\n",
      "train loss:0.00116421129658\n",
      "train loss:0.00403092149564\n",
      "train loss:0.00181712480419\n",
      "train loss:0.000781521130455\n",
      "train loss:0.00118313700082\n",
      "train loss:0.00109761181617\n",
      "train loss:0.00285197493164\n",
      "train loss:0.00802390342468\n",
      "train loss:0.00228215277407\n",
      "train loss:0.000888415097947\n",
      "train loss:0.00201410971279\n",
      "train loss:0.0283906816182\n",
      "train loss:0.00312563814851\n",
      "train loss:0.00272712919016\n",
      "train loss:0.000904950634095\n",
      "train loss:0.000724617995569\n",
      "train loss:0.000883781552757\n",
      "train loss:0.00395945788857\n",
      "train loss:0.00755849351689\n",
      "train loss:0.00218481587433\n",
      "train loss:0.00407502017941\n",
      "train loss:0.00106672515804\n",
      "train loss:0.00480449376507\n",
      "train loss:0.000425352358454\n",
      "train loss:0.0498774986003\n",
      "train loss:0.000361139959116\n",
      "train loss:0.00442531600174\n",
      "train loss:0.0372329745711\n",
      "train loss:0.00100114585255\n",
      "train loss:0.0338401444785\n",
      "train loss:0.00123857459633\n",
      "train loss:0.00312879930109\n",
      "train loss:0.00842713843477\n",
      "train loss:0.00149593152154\n",
      "train loss:0.0237737489996\n",
      "train loss:0.00105410014975\n",
      "train loss:0.00124340290678\n",
      "train loss:0.000624567942147\n",
      "train loss:0.00304537370031\n",
      "train loss:0.00297286534059\n",
      "train loss:0.0142521341855\n",
      "train loss:0.0139854417044\n",
      "train loss:0.00303743325495\n",
      "train loss:0.0010655649613\n",
      "train loss:0.00311433291981\n",
      "train loss:0.0033069020974\n",
      "train loss:0.00287810513903\n",
      "train loss:0.00194993686202\n",
      "train loss:0.0254383190128\n",
      "train loss:0.00654890430186\n",
      "train loss:0.00473633963615\n",
      "train loss:0.0128248311621\n",
      "train loss:0.00213172615558\n",
      "train loss:0.00263832883317\n",
      "train loss:0.000803143748449\n",
      "train loss:0.00176776557256\n",
      "train loss:0.0205743099729\n",
      "train loss:0.00924403165335\n",
      "train loss:0.000702744375647\n",
      "train loss:0.00261349960412\n",
      "train loss:0.000465773023639\n",
      "train loss:0.00451658334142\n",
      "train loss:0.00320045164751\n",
      "train loss:0.00904192646569\n",
      "train loss:0.0007657506031\n",
      "train loss:0.00824569394961\n",
      "train loss:0.000523386282758\n",
      "train loss:0.0100853102743\n",
      "train loss:0.00222277849673\n",
      "train loss:0.00420145720858\n",
      "train loss:0.00402773974735\n",
      "train loss:0.00140055545837\n",
      "train loss:0.00343375943175\n",
      "train loss:0.00139666327114\n",
      "train loss:0.00981877634826\n",
      "train loss:0.00298840040761\n",
      "train loss:0.00739138916554\n",
      "train loss:0.00169851325245\n",
      "train loss:0.000828697282434\n",
      "train loss:0.00431746979324\n",
      "train loss:0.000421731456176\n",
      "train loss:0.00371146680711\n",
      "train loss:0.00162616480406\n",
      "train loss:0.00513069936662\n",
      "train loss:0.00446236840782\n",
      "train loss:0.000154111834646\n",
      "train loss:0.0393789677587\n",
      "train loss:0.00570951116731\n",
      "train loss:0.0239569901301\n",
      "train loss:0.0293824897615\n",
      "train loss:0.0401000447246\n",
      "train loss:0.000231509012618\n",
      "train loss:0.00636528478979\n",
      "train loss:0.00407405665289\n",
      "train loss:0.00733548048902\n",
      "train loss:0.00354575032352\n",
      "train loss:0.00156525725622\n",
      "train loss:0.00353516285403\n",
      "train loss:0.00308264836205\n",
      "train loss:0.0290675140973\n",
      "train loss:0.00134924811514\n",
      "train loss:0.0149266143514\n",
      "train loss:0.00454754104728\n",
      "train loss:0.000361722861201\n",
      "train loss:0.0126898540339\n",
      "train loss:0.0567044437608\n",
      "train loss:0.0068860476715\n",
      "train loss:0.0040999367954\n",
      "train loss:0.0032309131091\n",
      "train loss:0.00158056127133\n",
      "train loss:0.0117255243301\n",
      "train loss:0.00713276395284\n",
      "train loss:0.00145488313609\n",
      "train loss:0.00316297520049\n",
      "train loss:0.00348890814216\n",
      "train loss:0.0101802062139\n",
      "train loss:0.0276893661364\n",
      "train loss:0.0219447028337\n",
      "train loss:0.00065160997512\n",
      "train loss:0.0131172748798\n",
      "train loss:0.0102831532247\n",
      "train loss:0.0190199612727\n",
      "train loss:0.0021795476146\n",
      "train loss:0.0152653086019\n",
      "train loss:0.00130119998244\n",
      "train loss:0.00273193899423\n",
      "train loss:0.0101781060142\n",
      "train loss:0.00446274327756\n",
      "train loss:0.002740584398\n",
      "train loss:0.00876187707956\n",
      "train loss:0.00207014162769\n",
      "train loss:0.00135280910031\n",
      "train loss:0.00887971553547\n",
      "train loss:0.00250124114289\n",
      "train loss:0.00128332221505\n",
      "train loss:0.00133404698988\n",
      "train loss:0.00325493894214\n",
      "train loss:0.00244912625233\n",
      "train loss:0.00794944506658\n",
      "train loss:0.00157268355281\n",
      "train loss:0.00205863614604\n",
      "train loss:0.0160770584878\n",
      "train loss:0.00337345139977\n",
      "train loss:0.00476411277908\n",
      "train loss:0.0031719382652\n",
      "train loss:0.00420717326847\n",
      "train loss:0.00109394834714\n",
      "train loss:0.00481508305221\n",
      "train loss:0.00351518457007\n",
      "train loss:0.00152540886571\n",
      "train loss:0.0039393143718\n",
      "train loss:0.00342894485132\n",
      "train loss:0.00737371350227\n",
      "train loss:0.00669827336096\n",
      "train loss:0.0022021250618\n",
      "train loss:0.00394815528156\n",
      "train loss:0.00199585211382\n",
      "train loss:0.00644902768766\n",
      "train loss:0.0015131590196\n",
      "train loss:0.00756276753768\n",
      "train loss:0.00224956582642\n",
      "train loss:0.00746381660191\n",
      "train loss:0.000160900806697\n",
      "train loss:0.002694653467\n",
      "train loss:0.0155272597643\n",
      "train loss:0.00500616483015\n",
      "train loss:0.00972318097318\n",
      "train loss:0.00498691475187\n",
      "train loss:0.000670597378972\n",
      "train loss:0.00252665254596\n",
      "train loss:0.00118691439069\n",
      "train loss:0.0047919034289\n",
      "train loss:0.00624366540135\n",
      "train loss:0.0855855437274\n",
      "train loss:0.00192115909232\n",
      "train loss:0.00112234523641\n",
      "train loss:0.00238425342333\n",
      "train loss:0.00149020677431\n",
      "train loss:0.00398562775873\n",
      "train loss:0.00739023387078\n",
      "train loss:0.000801398099278\n",
      "train loss:0.000441435819363\n",
      "train loss:0.00441390518313\n",
      "train loss:0.0118130304968\n",
      "train loss:0.00417346484669\n",
      "train loss:0.000998046456373\n",
      "train loss:0.00729019495665\n",
      "train loss:0.000919092775375\n",
      "train loss:0.00315886382677\n",
      "train loss:0.00641396179404\n",
      "train loss:0.00361350183026\n",
      "train loss:0.00349801935039\n",
      "train loss:0.0121136183267\n",
      "train loss:0.00146514976425\n",
      "train loss:0.00866218825672\n",
      "train loss:0.00316744081761\n",
      "train loss:0.00213605809285\n",
      "train loss:0.00271529803383\n",
      "train loss:0.00275927452999\n",
      "train loss:0.00232910795003\n",
      "train loss:0.00367296935825\n",
      "train loss:0.000728549631442\n",
      "train loss:0.00573583598646\n",
      "train loss:0.00157576313706\n",
      "train loss:0.00941747420971\n",
      "train loss:0.00395231683454\n",
      "train loss:0.000234989184628\n",
      "train loss:0.00269912350248\n",
      "train loss:0.00762000367429\n",
      "train loss:0.00109786666408\n",
      "train loss:0.00833698982053\n",
      "train loss:0.00332545246981\n",
      "train loss:0.00329411604448\n",
      "train loss:0.0329678893729\n",
      "train loss:0.000808541673906\n",
      "train loss:0.000528160935209\n",
      "train loss:0.00402638535908\n",
      "train loss:0.00266856684407\n",
      "train loss:0.00326421734999\n",
      "train loss:0.00165516021085\n",
      "train loss:0.000786095173556\n",
      "train loss:0.00228697958956\n",
      "train loss:0.00606204087803\n",
      "train loss:0.0015887977554\n",
      "train loss:0.0115455245962\n",
      "train loss:0.0146868945621\n",
      "train loss:0.000657862992749\n",
      "train loss:0.0120145306186\n",
      "train loss:0.00242415034717\n",
      "train loss:0.00499177684799\n",
      "train loss:0.000887931604319\n",
      "train loss:0.00043733457975\n",
      "train loss:0.000627667190013\n",
      "train loss:0.000102510722209\n",
      "train loss:0.011657522963\n",
      "train loss:0.00169648822324\n",
      "train loss:0.00199026252945\n",
      "train loss:0.0016954066783\n",
      "train loss:0.00405399071648\n",
      "train loss:0.0256299221792\n",
      "train loss:0.00132254598253\n",
      "train loss:0.000210847699871\n",
      "train loss:0.00147220773024\n",
      "train loss:0.000196070665026\n",
      "train loss:0.000395157824329\n",
      "train loss:0.00620937887562\n",
      "train loss:0.00408196800297\n",
      "train loss:0.00103283904471\n",
      "train loss:0.00588690859382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00035904867492\n",
      "train loss:0.000284942025832\n",
      "train loss:0.00165032495544\n",
      "train loss:0.00203649481143\n",
      "train loss:0.00381291097102\n",
      "train loss:0.00859206209563\n",
      "train loss:0.000419138439238\n",
      "train loss:0.000565616095179\n",
      "train loss:0.00447293418757\n",
      "train loss:0.00194061100234\n",
      "train loss:0.00977853896177\n",
      "train loss:0.00243573627278\n",
      "train loss:0.00295837660901\n",
      "train loss:0.00174261786673\n",
      "train loss:0.000690738445908\n",
      "train loss:0.00661291728211\n",
      "train loss:0.00257084893409\n",
      "train loss:9.09518935464e-05\n",
      "train loss:0.000256266819169\n",
      "train loss:0.00175716187892\n",
      "train loss:0.00691512729768\n",
      "train loss:0.00131465333698\n",
      "train loss:0.000605328574144\n",
      "train loss:0.00151795853842\n",
      "train loss:0.00112366595948\n",
      "train loss:0.00151086546079\n",
      "train loss:0.00523709171003\n",
      "train loss:0.00185168800775\n",
      "train loss:0.000218976686181\n",
      "train loss:0.0111145424355\n",
      "train loss:0.000780046971333\n",
      "train loss:0.000935589104533\n",
      "train loss:0.00187790324992\n",
      "train loss:0.0124956682207\n",
      "train loss:0.00107759795847\n",
      "train loss:0.00791102705845\n",
      "train loss:0.000312887060499\n",
      "train loss:0.000789838448413\n",
      "train loss:0.000301646446396\n",
      "train loss:0.00224425019277\n",
      "train loss:0.00377098643123\n",
      "train loss:0.00058649780867\n",
      "train loss:0.00317076185845\n",
      "train loss:0.0080977594501\n",
      "train loss:0.00109810974877\n",
      "train loss:0.00126572175212\n",
      "train loss:0.000525555000774\n",
      "train loss:0.00177101761634\n",
      "train loss:0.00204277441162\n",
      "train loss:0.00236130202957\n",
      "train loss:0.00109185244176\n",
      "train loss:0.00172063342198\n",
      "train loss:0.0057613010689\n",
      "train loss:0.00380641069826\n",
      "train loss:0.00233001172386\n",
      "train loss:0.00122691047726\n",
      "train loss:0.000961328525634\n",
      "train loss:0.00512144310707\n",
      "train loss:0.00273138932372\n",
      "train loss:0.0055379666106\n",
      "train loss:0.00411227943256\n",
      "train loss:0.0143069560712\n",
      "train loss:0.00347074846406\n",
      "train loss:0.000901150181518\n",
      "train loss:0.00609303004379\n",
      "train loss:0.00224169432489\n",
      "train loss:0.000535225204411\n",
      "train loss:0.00159063015906\n",
      "train loss:0.00383958946603\n",
      "train loss:0.000950142012402\n",
      "train loss:0.00175679463904\n",
      "train loss:0.0192077129254\n",
      "train loss:0.00261193522385\n",
      "train loss:0.00107384809276\n",
      "train loss:0.00381184261069\n",
      "train loss:0.000246874714457\n",
      "train loss:0.00210411114567\n",
      "train loss:0.00472163719545\n",
      "train loss:0.00633114716923\n",
      "train loss:0.00582524661742\n",
      "train loss:0.00457384887446\n",
      "train loss:0.00237804567839\n",
      "train loss:0.00286240407971\n",
      "train loss:0.00545732379482\n",
      "train loss:0.00321682537016\n",
      "train loss:0.000219889326171\n",
      "train loss:0.00101985089604\n",
      "train loss:0.00601082344731\n",
      "train loss:0.00130634566064\n",
      "train loss:0.000729415043042\n",
      "train loss:0.000972871791802\n",
      "train loss:0.00589782473062\n",
      "train loss:0.00243748004322\n",
      "train loss:0.00287820590107\n",
      "train loss:0.000327249548185\n",
      "train loss:0.000454405665958\n",
      "train loss:0.000557469416782\n",
      "train loss:0.000496020715586\n",
      "train loss:0.000630066451999\n",
      "train loss:0.00428103036858\n",
      "train loss:0.040444934812\n",
      "train loss:0.000317541951988\n",
      "train loss:0.00208893004832\n",
      "train loss:0.00295576347523\n",
      "train loss:0.000853109881307\n",
      "train loss:0.000913080299352\n",
      "train loss:0.00188219848194\n",
      "train loss:0.000833110065365\n",
      "train loss:0.00094471828373\n",
      "train loss:0.00450696623801\n",
      "train loss:0.00190982579086\n",
      "train loss:0.00559210779418\n",
      "train loss:0.000553890993718\n",
      "train loss:0.00494165478212\n",
      "train loss:0.00793647772844\n",
      "train loss:0.00805019091789\n",
      "train loss:0.000101544381154\n",
      "train loss:0.0032244574865\n",
      "train loss:0.00228093626806\n",
      "train loss:0.00422191285472\n",
      "train loss:0.00156515642514\n",
      "train loss:0.000928353967293\n",
      "train loss:0.000300586146683\n",
      "train loss:0.00145406496333\n",
      "train loss:0.000218330137239\n",
      "train loss:0.00243227857231\n",
      "train loss:7.71902706486e-05\n",
      "train loss:8.20018744038e-05\n",
      "train loss:0.00465669077357\n",
      "train loss:0.00207653235567\n",
      "train loss:0.00520393843769\n",
      "train loss:0.0140110935009\n",
      "train loss:0.00930429076984\n",
      "train loss:0.0016755838598\n",
      "train loss:0.00692641109052\n",
      "train loss:0.00187350887295\n",
      "train loss:0.00185192771223\n",
      "train loss:0.00190063204649\n",
      "train loss:0.00775306914758\n",
      "train loss:0.00302420557237\n",
      "train loss:0.00572776191781\n",
      "train loss:0.000945641474151\n",
      "train loss:0.00580503461323\n",
      "train loss:0.00133404540695\n",
      "train loss:0.00208225218928\n",
      "train loss:0.00603880147672\n",
      "train loss:0.00499664537572\n",
      "train loss:0.00268614397838\n",
      "train loss:0.000528878804459\n",
      "train loss:7.92168749965e-05\n",
      "train loss:0.0029756575169\n",
      "train loss:0.000428812073613\n",
      "train loss:0.00378981024742\n",
      "train loss:0.00170713482729\n",
      "train loss:0.00155913227874\n",
      "train loss:0.00310387868864\n",
      "train loss:0.00282655515398\n",
      "train loss:0.00216966197458\n",
      "train loss:0.0018402516563\n",
      "train loss:0.00190249343792\n",
      "train loss:0.0065409852504\n",
      "train loss:0.00581744796693\n",
      "train loss:0.00623446458194\n",
      "train loss:0.00757175859844\n",
      "train loss:0.02159211392\n",
      "train loss:0.00329284611142\n",
      "train loss:0.00827777904453\n",
      "train loss:0.00746959628002\n",
      "train loss:0.00131440060224\n",
      "train loss:0.000735962828422\n",
      "train loss:0.00145580619975\n",
      "train loss:0.00423869628583\n",
      "train loss:0.00251186642093\n",
      "train loss:0.000433573335167\n",
      "train loss:0.00284760119491\n",
      "train loss:0.0072658857602\n",
      "train loss:0.00245320054743\n",
      "train loss:0.0041081395589\n",
      "train loss:0.0396622542454\n",
      "train loss:0.00682355668009\n",
      "train loss:0.00421551722425\n",
      "train loss:0.00299071824894\n",
      "train loss:0.00105065385127\n",
      "train loss:0.0281490893109\n",
      "train loss:0.00367580196339\n",
      "train loss:0.00312698598166\n",
      "train loss:0.00511099233471\n",
      "train loss:0.000814398801679\n",
      "train loss:0.00229821542237\n",
      "train loss:0.00241084466072\n",
      "train loss:0.00708855799319\n",
      "train loss:0.0130457615178\n",
      "train loss:0.00113645247412\n",
      "train loss:0.00070767955663\n",
      "train loss:0.0215117043157\n",
      "train loss:0.00237980317423\n",
      "train loss:0.00241754259077\n",
      "train loss:0.00367603934983\n",
      "train loss:0.0063371790353\n",
      "train loss:0.000682333527666\n",
      "train loss:0.0045513765453\n",
      "train loss:0.00803963943877\n",
      "train loss:0.00158932929398\n",
      "train loss:0.00253713009676\n",
      "train loss:0.0012961656632\n",
      "train loss:0.00398665962582\n",
      "train loss:0.00111191469431\n",
      "train loss:0.00187135037082\n",
      "train loss:0.00374212039545\n",
      "train loss:0.00108730393009\n",
      "train loss:0.00051940855491\n",
      "train loss:0.00889654418588\n",
      "train loss:0.00110436921918\n",
      "train loss:0.00128362157087\n",
      "train loss:0.000539752367071\n",
      "train loss:0.00505486810008\n",
      "train loss:0.00785757708986\n",
      "train loss:0.000292585739016\n",
      "train loss:0.00830801625703\n",
      "train loss:0.00354825468456\n",
      "train loss:0.00204346516077\n",
      "train loss:0.0024667239739\n",
      "train loss:0.00178762799427\n",
      "train loss:0.0184144660499\n",
      "train loss:0.000646639652586\n",
      "train loss:0.0107540354657\n",
      "train loss:0.00846262233008\n",
      "train loss:0.000685285897785\n",
      "train loss:0.00300833443602\n",
      "train loss:0.000713677853607\n",
      "train loss:0.00128225064572\n",
      "train loss:0.0033958017993\n",
      "train loss:0.000579087806147\n",
      "train loss:0.00345759093628\n",
      "train loss:0.00334787140807\n",
      "train loss:0.00252189456571\n",
      "train loss:0.00562652379251\n",
      "train loss:0.000589208636704\n",
      "train loss:0.00562843620688\n",
      "train loss:0.0106431427864\n",
      "train loss:0.00223286955515\n",
      "train loss:0.00120830928586\n",
      "train loss:0.0102556190031\n",
      "train loss:0.00213651883659\n",
      "train loss:0.00255518891151\n",
      "train loss:0.00219669536641\n",
      "train loss:0.00695153364543\n",
      "train loss:0.0020416789794\n",
      "train loss:0.00680064213614\n",
      "train loss:0.00243193193014\n",
      "train loss:0.00240150055523\n",
      "train loss:0.0776865291446\n",
      "train loss:0.0115400404845\n",
      "train loss:0.00168408713314\n",
      "train loss:0.0054960860136\n",
      "train loss:0.000549474877614\n",
      "train loss:0.00160266954566\n",
      "train loss:0.00260224920434\n",
      "train loss:0.0343422118449\n",
      "train loss:0.00237291769216\n",
      "train loss:0.00216495799318\n",
      "train loss:0.000313270548721\n",
      "train loss:0.00713929856118\n",
      "train loss:0.0112494859846\n",
      "train loss:0.0304191523706\n",
      "train loss:0.0180729077573\n",
      "train loss:0.00677667070755\n",
      "train loss:0.000855491128687\n",
      "train loss:0.00906921303988\n",
      "train loss:0.00122163388329\n",
      "train loss:0.000340863652273\n",
      "train loss:0.00198957977459\n",
      "train loss:0.00442169128839\n",
      "train loss:0.00345375784235\n",
      "train loss:0.00220498196711\n",
      "train loss:0.0130056285349\n",
      "train loss:0.00265887465638\n",
      "train loss:0.000258735287246\n",
      "train loss:0.0387246089746\n",
      "train loss:0.000140533710536\n",
      "train loss:0.000903888078942\n",
      "train loss:0.00350496467637\n",
      "train loss:0.0023050205232\n",
      "train loss:0.00361478508407\n",
      "train loss:0.0443915706059\n",
      "=== epoch:14, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.0111960390888\n",
      "train loss:0.000680922656407\n",
      "train loss:0.0225235616176\n",
      "train loss:0.00149926578622\n",
      "train loss:0.00236830813129\n",
      "train loss:0.00802609017333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000934939386806\n",
      "train loss:0.000142930755195\n",
      "train loss:0.000477706647145\n",
      "train loss:0.000684224028426\n",
      "train loss:0.000561744640581\n",
      "train loss:0.0224326813187\n",
      "train loss:0.00408142295906\n",
      "train loss:0.00188341651141\n",
      "train loss:0.00560763117906\n",
      "train loss:0.0091123361889\n",
      "train loss:0.00138836652643\n",
      "train loss:0.0226290676059\n",
      "train loss:0.00088786487413\n",
      "train loss:0.00129578406077\n",
      "train loss:0.00195588336007\n",
      "train loss:0.0107010509917\n",
      "train loss:0.00185928419839\n",
      "train loss:0.0022747514654\n",
      "train loss:0.00789012124513\n",
      "train loss:0.00633283262375\n",
      "train loss:0.00226968359382\n",
      "train loss:0.017002918613\n",
      "train loss:0.00376240819464\n",
      "train loss:0.00452485749616\n",
      "train loss:0.00187058915678\n",
      "train loss:0.00461323558362\n",
      "train loss:0.00662370486657\n",
      "train loss:0.00270147336966\n",
      "train loss:0.00779516647458\n",
      "train loss:0.0111886997895\n",
      "train loss:0.0109605128482\n",
      "train loss:0.000852003631915\n",
      "train loss:0.0159634035211\n",
      "train loss:0.00134137311014\n",
      "train loss:0.0038688110931\n",
      "train loss:0.00252429667977\n",
      "train loss:0.000623411859649\n",
      "train loss:0.00109379454181\n",
      "train loss:0.00446898292154\n",
      "train loss:0.00721487891004\n",
      "train loss:0.000233865980633\n",
      "train loss:0.00852854803022\n",
      "train loss:0.000515654403076\n",
      "train loss:0.00251152939853\n",
      "train loss:0.00293089226254\n",
      "train loss:0.0160946988117\n",
      "train loss:0.00102488188767\n",
      "train loss:0.0308831272711\n",
      "train loss:9.32900449644e-05\n",
      "train loss:0.00124421547949\n",
      "train loss:0.00261253415298\n",
      "train loss:0.000429136938282\n",
      "train loss:0.00077461152385\n",
      "train loss:0.00912278726253\n",
      "train loss:0.000348845060777\n",
      "train loss:0.00455530888691\n",
      "train loss:0.000194586103552\n",
      "train loss:0.00511748221376\n",
      "train loss:0.00145332020073\n",
      "train loss:0.00568242595476\n",
      "train loss:0.000301152456369\n",
      "train loss:0.00382773964455\n",
      "train loss:0.0001659765248\n",
      "train loss:0.000286830285037\n",
      "train loss:0.00634594522598\n",
      "train loss:0.000354533152206\n",
      "train loss:0.00173754840237\n",
      "train loss:0.000161018182376\n",
      "train loss:0.00163615901539\n",
      "train loss:0.00277915223765\n",
      "train loss:0.00717543579769\n",
      "train loss:0.00353134923765\n",
      "train loss:0.00120633900759\n",
      "train loss:0.00085105624515\n",
      "train loss:0.00228554989906\n",
      "train loss:0.00273066464465\n",
      "train loss:0.00225065904188\n",
      "train loss:0.00212677189234\n",
      "train loss:0.00127183251377\n",
      "train loss:0.000270246106611\n",
      "train loss:0.00163558654009\n",
      "train loss:0.00466577584352\n",
      "train loss:0.000928850916701\n",
      "train loss:0.000297933631109\n",
      "train loss:0.00287917543894\n",
      "train loss:0.0109146887171\n",
      "train loss:0.00289025932831\n",
      "train loss:0.000137245423596\n",
      "train loss:0.00114267124096\n",
      "train loss:0.00498096024535\n",
      "train loss:0.00201779697489\n",
      "train loss:0.00126870814122\n",
      "train loss:0.00395609623295\n",
      "train loss:0.00715369042174\n",
      "train loss:0.000897047205196\n",
      "train loss:0.00925245147163\n",
      "train loss:0.0047706442469\n",
      "train loss:0.000237048591878\n",
      "train loss:0.00181126408103\n",
      "train loss:0.00809287958853\n",
      "train loss:0.014973983369\n",
      "train loss:0.00483874979783\n",
      "train loss:0.00222448561368\n",
      "train loss:0.00302128627074\n",
      "train loss:0.00282349344274\n",
      "train loss:0.000634811376735\n",
      "train loss:0.00180437776154\n",
      "train loss:0.0298888939599\n",
      "train loss:0.00135868270459\n",
      "train loss:0.0116484234514\n",
      "train loss:2.55382310259e-05\n",
      "train loss:0.0145284783571\n",
      "train loss:0.000487647160291\n",
      "train loss:0.0173438764468\n",
      "train loss:0.0123867089889\n",
      "train loss:0.00794317965995\n",
      "train loss:0.0166194244301\n",
      "train loss:0.00725085435547\n",
      "train loss:0.107372934451\n",
      "train loss:0.0011199619943\n",
      "train loss:0.00889855813731\n",
      "train loss:0.000418680963104\n",
      "train loss:0.00392499177045\n",
      "train loss:0.0188588118934\n",
      "train loss:0.000914965821234\n",
      "train loss:0.00108577489346\n",
      "train loss:0.0236227948085\n",
      "train loss:0.00530289939001\n",
      "train loss:0.00662644446657\n",
      "train loss:0.00694867062664\n",
      "train loss:0.0258183440236\n",
      "train loss:0.0246831610621\n",
      "train loss:0.0083204848329\n",
      "train loss:0.00879614416756\n",
      "train loss:0.0017689911411\n",
      "train loss:0.000869069886705\n",
      "train loss:0.00620406113044\n",
      "train loss:0.0598955573031\n",
      "train loss:0.000629054831909\n",
      "train loss:0.000673998645788\n",
      "train loss:0.000487546895535\n",
      "train loss:0.000631810965621\n",
      "train loss:0.000553090455118\n",
      "train loss:0.00282622101838\n",
      "train loss:0.00179366951974\n",
      "train loss:0.00307131733755\n",
      "train loss:0.00503512277849\n",
      "train loss:0.00512686296447\n",
      "train loss:0.00811656131128\n",
      "train loss:0.00563969499819\n",
      "train loss:0.00142648732153\n",
      "train loss:0.0011681551754\n",
      "train loss:0.00522555273572\n",
      "train loss:0.00542035898044\n",
      "train loss:0.000856361702772\n",
      "train loss:0.00339550686241\n",
      "train loss:0.0020015682271\n",
      "train loss:0.0122731423255\n",
      "train loss:0.00189375161986\n",
      "train loss:0.00186506463369\n",
      "train loss:0.00273707497431\n",
      "train loss:0.001590610981\n",
      "train loss:0.0131653306319\n",
      "train loss:0.0297427871689\n",
      "train loss:0.00101846751797\n",
      "train loss:0.0183988756073\n",
      "train loss:0.00183961904338\n",
      "train loss:0.00241919338568\n",
      "train loss:0.000334491864254\n",
      "train loss:0.000320941696649\n",
      "train loss:0.000528392632786\n",
      "train loss:0.00179362970656\n",
      "train loss:0.00401665636684\n",
      "train loss:0.0217140461287\n",
      "train loss:0.000652124881115\n",
      "train loss:0.00117891708523\n",
      "train loss:0.000135689688846\n",
      "train loss:0.001819646088\n",
      "train loss:0.00234374939027\n",
      "train loss:0.00494871993803\n",
      "train loss:0.00161879111348\n",
      "train loss:0.00060967034422\n",
      "train loss:0.000508151914381\n",
      "train loss:0.0274920759333\n",
      "train loss:0.000961083607048\n",
      "train loss:0.00310508074644\n",
      "train loss:0.0187117131423\n",
      "train loss:0.00252506737695\n",
      "train loss:0.0237632002826\n",
      "train loss:0.0136618072185\n",
      "train loss:0.00757678849394\n",
      "train loss:0.00329134578856\n",
      "train loss:0.00305095961212\n",
      "train loss:0.00724919653432\n",
      "train loss:0.00235307124864\n",
      "train loss:0.00347870775264\n",
      "train loss:0.0110254990285\n",
      "train loss:0.00318795458632\n",
      "train loss:0.00892666731625\n",
      "train loss:0.00493731679644\n",
      "train loss:0.00453545373691\n",
      "train loss:0.016735058119\n",
      "train loss:0.00202976309764\n",
      "train loss:0.00134656544196\n",
      "train loss:0.00259821272567\n",
      "train loss:0.00269015824647\n",
      "train loss:0.000775918305553\n",
      "train loss:0.00033120818947\n",
      "train loss:0.00245221134561\n",
      "train loss:0.0166321236281\n",
      "train loss:0.00505359698956\n",
      "train loss:0.0023350635498\n",
      "train loss:0.00088032007979\n",
      "train loss:0.00591690510065\n",
      "train loss:0.00237613941485\n",
      "train loss:0.00517319089738\n",
      "train loss:0.00109136408582\n",
      "train loss:0.00042670093726\n",
      "train loss:0.000957914497173\n",
      "train loss:0.00165306648026\n",
      "train loss:0.00113564981802\n",
      "train loss:0.00482147443732\n",
      "train loss:0.000769481644862\n",
      "train loss:0.000414409989185\n",
      "train loss:0.00377961197711\n",
      "train loss:0.00235339571636\n",
      "train loss:0.00260551333837\n",
      "train loss:0.000335187388547\n",
      "train loss:0.00216583719219\n",
      "train loss:0.00238517775102\n",
      "train loss:0.00630372201789\n",
      "train loss:0.000263145099921\n",
      "train loss:0.000122212086408\n",
      "train loss:0.00472764058256\n",
      "train loss:0.00187032837452\n",
      "train loss:0.00989706184245\n",
      "train loss:0.00116451025088\n",
      "train loss:0.0193448669587\n",
      "train loss:0.00107009711842\n",
      "train loss:0.00129487680701\n",
      "train loss:0.00218374206198\n",
      "train loss:0.00157020625377\n",
      "train loss:0.00234799950961\n",
      "train loss:0.00152649790586\n",
      "train loss:0.0116662737427\n",
      "train loss:0.00302476084233\n",
      "train loss:0.00465213353221\n",
      "train loss:0.00111334624706\n",
      "train loss:0.00413106840981\n",
      "train loss:0.00107425208988\n",
      "train loss:0.0342925692097\n",
      "train loss:0.00836287369914\n",
      "train loss:0.000347314950062\n",
      "train loss:0.000123134060398\n",
      "train loss:0.00781511488428\n",
      "train loss:0.00376639289164\n",
      "train loss:0.00562963625981\n",
      "train loss:0.00395068023295\n",
      "train loss:0.00104297362664\n",
      "train loss:0.000814270794747\n",
      "train loss:0.00247403971568\n",
      "train loss:0.00112056648296\n",
      "train loss:0.0026859498602\n",
      "train loss:0.00209574021736\n",
      "train loss:0.00347899995419\n",
      "train loss:0.00151453417194\n",
      "train loss:0.00168391637572\n",
      "train loss:0.00147464361053\n",
      "train loss:0.0016735499205\n",
      "train loss:0.000264713291356\n",
      "train loss:0.00124521830586\n",
      "train loss:0.00220335066112\n",
      "train loss:0.00437291424976\n",
      "train loss:0.000225584767041\n",
      "train loss:0.0021603960948\n",
      "train loss:0.0160358728642\n",
      "train loss:0.00590204869106\n",
      "train loss:0.00270770051932\n",
      "train loss:0.00617922346859\n",
      "train loss:0.00277378655106\n",
      "train loss:0.0038474562656\n",
      "train loss:0.00359949589966\n",
      "train loss:0.0307700932691\n",
      "train loss:0.00407114497469\n",
      "train loss:0.00233865457065\n",
      "train loss:0.000939338275181\n",
      "train loss:0.00565132406274\n",
      "train loss:0.00484632378717\n",
      "train loss:0.00162293929649\n",
      "train loss:0.00618862093245\n",
      "train loss:0.00385449125797\n",
      "train loss:0.00287897750635\n",
      "train loss:0.00142875692338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00110621894356\n",
      "train loss:0.00748291554373\n",
      "train loss:0.00234786603626\n",
      "train loss:0.0111323193201\n",
      "train loss:0.00492488169346\n",
      "train loss:0.00302574903114\n",
      "train loss:0.00312606784212\n",
      "train loss:0.00160149526016\n",
      "train loss:0.00261238454102\n",
      "train loss:0.000233290822072\n",
      "train loss:0.00382584295586\n",
      "train loss:0.00236598259571\n",
      "train loss:0.00081318351838\n",
      "train loss:0.00381649496528\n",
      "train loss:0.00483789760571\n",
      "train loss:0.00232167292047\n",
      "train loss:0.024713959008\n",
      "train loss:0.00823000604175\n",
      "train loss:0.00115917328895\n",
      "train loss:0.000559193021658\n",
      "train loss:0.00723631120796\n",
      "train loss:0.00190834099165\n",
      "train loss:0.00246382004609\n",
      "train loss:0.0023251950587\n",
      "train loss:0.000840479910468\n",
      "train loss:0.00354147114174\n",
      "train loss:0.00111871854924\n",
      "train loss:0.00479562645123\n",
      "train loss:0.000618752263209\n",
      "train loss:0.00345903496262\n",
      "train loss:0.0100871416796\n",
      "train loss:0.00129697448986\n",
      "train loss:0.00601165829987\n",
      "train loss:0.00204863497803\n",
      "train loss:0.00500086079892\n",
      "train loss:0.00391160267134\n",
      "train loss:0.00487102386783\n",
      "train loss:0.00163287724197\n",
      "train loss:0.00776154535895\n",
      "train loss:0.00032147982909\n",
      "train loss:0.00600781182702\n",
      "train loss:0.00360887618482\n",
      "train loss:0.00609110717517\n",
      "train loss:0.00250187480392\n",
      "train loss:0.00141343293171\n",
      "train loss:0.00118289948349\n",
      "train loss:0.00120705503801\n",
      "train loss:0.00217096648866\n",
      "train loss:0.000912353457506\n",
      "train loss:0.000192599058409\n",
      "train loss:0.00203223677801\n",
      "train loss:0.00268544132129\n",
      "train loss:0.000811718039414\n",
      "train loss:0.00454553009274\n",
      "train loss:0.000672813421873\n",
      "train loss:0.00314016678037\n",
      "train loss:0.00231144131703\n",
      "train loss:0.000978701018573\n",
      "train loss:0.00473239269181\n",
      "train loss:0.00203834710027\n",
      "train loss:0.000335946500271\n",
      "train loss:0.00259317315724\n",
      "train loss:7.83865440384e-05\n",
      "train loss:0.00394990693518\n",
      "train loss:0.00204791946661\n",
      "train loss:0.0234217718244\n",
      "train loss:0.00134048488603\n",
      "train loss:0.00114233628151\n",
      "train loss:0.0015500864682\n",
      "train loss:0.0341401088173\n",
      "train loss:0.000680141328741\n",
      "train loss:0.00301522865551\n",
      "train loss:0.000240766125296\n",
      "train loss:0.0112227853445\n",
      "train loss:0.00105589173813\n",
      "train loss:0.00409948393834\n",
      "train loss:0.00823427327335\n",
      "train loss:0.00242140630852\n",
      "train loss:0.000159263563942\n",
      "train loss:0.00055478844618\n",
      "train loss:0.00264544119904\n",
      "train loss:0.00207079170154\n",
      "train loss:0.00201546557647\n",
      "train loss:0.0110887579353\n",
      "train loss:0.00592044321149\n",
      "train loss:0.000214657075282\n",
      "train loss:0.0027494461941\n",
      "train loss:0.000772465667131\n",
      "train loss:0.0066780984608\n",
      "train loss:0.00373934634681\n",
      "train loss:0.00104079784357\n",
      "train loss:0.00126088921687\n",
      "train loss:0.00252674457987\n",
      "train loss:0.00211258064182\n",
      "train loss:0.000947520417511\n",
      "train loss:0.0018325218068\n",
      "train loss:0.000126963357894\n",
      "train loss:0.00244086736144\n",
      "train loss:0.000726440522786\n",
      "train loss:0.00473064480596\n",
      "train loss:0.00945030970589\n",
      "train loss:0.00280984602061\n",
      "train loss:0.00366944962275\n",
      "train loss:0.00264048974148\n",
      "train loss:0.000769576710809\n",
      "train loss:0.000216855730778\n",
      "train loss:0.000581590269821\n",
      "train loss:0.00904154457495\n",
      "train loss:0.000167151604053\n",
      "train loss:0.0029230756329\n",
      "train loss:0.00196266384219\n",
      "train loss:0.00541333016746\n",
      "train loss:0.0168600832941\n",
      "train loss:0.00181775125306\n",
      "train loss:0.000589947424559\n",
      "train loss:0.000695163878734\n",
      "train loss:0.0151578909108\n",
      "train loss:0.00500965796753\n",
      "train loss:0.0353698192627\n",
      "train loss:0.00151508852673\n",
      "train loss:0.00393120604274\n",
      "train loss:0.00383636607766\n",
      "train loss:0.000334038954855\n",
      "train loss:0.00123025608106\n",
      "train loss:0.000486687385396\n",
      "train loss:0.00148997244141\n",
      "train loss:0.000220376373566\n",
      "train loss:0.00108476194301\n",
      "train loss:0.00793703564806\n",
      "train loss:0.00496843240124\n",
      "train loss:0.00109907338042\n",
      "train loss:0.00451988429494\n",
      "train loss:0.000741776839431\n",
      "train loss:0.00188541581777\n",
      "train loss:0.00270381316258\n",
      "train loss:0.00253714122845\n",
      "train loss:0.00220111493448\n",
      "train loss:0.000581361300606\n",
      "train loss:0.0022914950676\n",
      "train loss:0.0288662324588\n",
      "train loss:8.62778727997e-05\n",
      "train loss:0.00346209293249\n",
      "train loss:0.00372578944573\n",
      "train loss:0.00134785161441\n",
      "train loss:0.00116810062202\n",
      "train loss:0.0483604805524\n",
      "train loss:0.00217990920746\n",
      "train loss:0.000721900706603\n",
      "train loss:0.0225917359937\n",
      "train loss:0.00633972458273\n",
      "train loss:0.00140301877657\n",
      "train loss:0.0409762525175\n",
      "train loss:0.000181074072614\n",
      "train loss:0.00339428132661\n",
      "train loss:0.00193281061644\n",
      "train loss:0.0154129781036\n",
      "train loss:0.00826984822193\n",
      "train loss:0.00759234279578\n",
      "train loss:0.00160793285672\n",
      "train loss:0.0141705871715\n",
      "train loss:0.010514916795\n",
      "train loss:0.00663554846971\n",
      "train loss:0.000960416011552\n",
      "train loss:0.00230273127866\n",
      "train loss:0.000666642267607\n",
      "train loss:0.000459871295506\n",
      "train loss:0.000594847005027\n",
      "train loss:0.00691577420022\n",
      "train loss:0.00209468140062\n",
      "train loss:0.000867776992266\n",
      "train loss:0.00218827878759\n",
      "train loss:0.000254604937855\n",
      "train loss:0.00548042605189\n",
      "train loss:0.00271436315146\n",
      "train loss:0.00327335469568\n",
      "train loss:0.00568263523021\n",
      "train loss:0.00123853979535\n",
      "train loss:0.00462640887225\n",
      "train loss:0.00208354564399\n",
      "train loss:0.00335239229959\n",
      "train loss:0.00357217862817\n",
      "train loss:0.0238491500664\n",
      "train loss:0.0123319085701\n",
      "train loss:0.000204484350885\n",
      "train loss:0.00386885190162\n",
      "train loss:0.00285849504582\n",
      "train loss:0.00149136351623\n",
      "train loss:0.00423468607706\n",
      "train loss:0.00332082242487\n",
      "train loss:0.00032224758653\n",
      "train loss:0.00429813891373\n",
      "train loss:0.000757570454285\n",
      "train loss:0.00166882195636\n",
      "train loss:0.00811533173819\n",
      "train loss:0.00356829844656\n",
      "train loss:0.000235037941299\n",
      "train loss:0.000317380633102\n",
      "train loss:0.00061090561513\n",
      "train loss:0.00637777926418\n",
      "train loss:0.000704956607705\n",
      "train loss:0.00140490064766\n",
      "train loss:0.00309671803948\n",
      "train loss:0.00210031457905\n",
      "train loss:0.00141371614597\n",
      "train loss:0.000436983803872\n",
      "train loss:0.000498094305703\n",
      "train loss:0.00100106297819\n",
      "train loss:0.00114776547381\n",
      "train loss:0.00709926869284\n",
      "train loss:0.00473288959056\n",
      "train loss:0.000525553394206\n",
      "train loss:0.0012443586536\n",
      "train loss:0.000578109995378\n",
      "train loss:0.00997987985253\n",
      "train loss:0.00368772971736\n",
      "train loss:0.000681692528233\n",
      "train loss:0.000801762564103\n",
      "train loss:0.00711950947561\n",
      "train loss:0.000838804385899\n",
      "train loss:0.00486512236858\n",
      "train loss:0.0014389255979\n",
      "train loss:0.00199039323909\n",
      "train loss:0.00366101421869\n",
      "train loss:0.0278265296016\n",
      "train loss:0.00135481718416\n",
      "train loss:0.00106755171841\n",
      "train loss:0.000549732385446\n",
      "train loss:0.00370266651582\n",
      "train loss:0.000338143877807\n",
      "train loss:0.0127103715788\n",
      "train loss:0.00454252478869\n",
      "train loss:0.00232517918817\n",
      "train loss:0.00317761755387\n",
      "train loss:0.00101044395973\n",
      "train loss:0.0041546948921\n",
      "train loss:0.00502131591696\n",
      "train loss:0.00172178183967\n",
      "train loss:0.00255583457723\n",
      "train loss:0.0043142718894\n",
      "train loss:0.00147265995577\n",
      "train loss:0.00199377771158\n",
      "train loss:0.00040052798561\n",
      "train loss:0.000573788585894\n",
      "train loss:0.00553732306331\n",
      "train loss:0.00056592082902\n",
      "train loss:0.00181593059043\n",
      "train loss:0.00182082014742\n",
      "train loss:0.000663194158266\n",
      "train loss:0.000506954110062\n",
      "train loss:0.000179324264714\n",
      "train loss:0.000272336407499\n",
      "train loss:0.00199384663426\n",
      "train loss:0.000421296550398\n",
      "train loss:0.00242023197965\n",
      "train loss:0.00117685182563\n",
      "train loss:0.0030556789652\n",
      "train loss:0.00079223346741\n",
      "train loss:0.000464992984511\n",
      "train loss:0.000785331495593\n",
      "train loss:0.000960182254717\n",
      "train loss:0.00374286968302\n",
      "train loss:0.00412631056402\n",
      "train loss:0.00093573798078\n",
      "train loss:0.00296667681084\n",
      "train loss:0.000398521480396\n",
      "train loss:0.00132701851675\n",
      "train loss:0.000668725875874\n",
      "train loss:0.00247656689959\n",
      "train loss:0.000850021026488\n",
      "train loss:0.000358325319514\n",
      "train loss:0.000887918522923\n",
      "train loss:0.00660429889798\n",
      "train loss:0.000975210315777\n",
      "train loss:0.000360799155478\n",
      "train loss:0.000234871209233\n",
      "train loss:0.000431292192967\n",
      "train loss:0.00253037947857\n",
      "train loss:0.00234689991282\n",
      "train loss:0.00231620415083\n",
      "train loss:0.000355396249509\n",
      "train loss:0.00469947286081\n",
      "train loss:0.00121493176622\n",
      "train loss:0.000283201632034\n",
      "train loss:0.000229643560413\n",
      "train loss:0.0683785023313\n",
      "train loss:0.002361870992\n",
      "train loss:0.00188443850978\n",
      "train loss:0.0015987455006\n",
      "train loss:0.00414428589864\n",
      "train loss:0.031874007742\n",
      "train loss:0.0398106524942\n",
      "train loss:0.000392944271604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00911641865128\n",
      "train loss:0.00188402070662\n",
      "train loss:0.00321398618515\n",
      "train loss:0.0012463337166\n",
      "train loss:0.00619007988006\n",
      "train loss:0.0061503376011\n",
      "train loss:0.00278806327294\n",
      "train loss:0.00327466965518\n",
      "train loss:0.0032036824793\n",
      "=== epoch:15, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.00312691166344\n",
      "train loss:0.00156165526814\n",
      "train loss:0.00304461333292\n",
      "train loss:0.00747790062106\n",
      "train loss:0.00811053433069\n",
      "train loss:0.00233024319713\n",
      "train loss:0.000542410165994\n",
      "train loss:0.00984798036207\n",
      "train loss:0.000576400610232\n",
      "train loss:0.00102167003619\n",
      "train loss:0.000946036025841\n",
      "train loss:0.00886840480994\n",
      "train loss:0.000582227725173\n",
      "train loss:0.00908491537093\n",
      "train loss:0.00358933757528\n",
      "train loss:0.00243208168679\n",
      "train loss:0.00547259253578\n",
      "train loss:0.00338902353828\n",
      "train loss:0.0133204294062\n",
      "train loss:0.000159848609565\n",
      "train loss:0.00679256891044\n",
      "train loss:0.00348946999111\n",
      "train loss:0.00313295335682\n",
      "train loss:0.000872760052383\n",
      "train loss:0.000406833330679\n",
      "train loss:0.001715323192\n",
      "train loss:0.0038317150582\n",
      "train loss:0.00464454214393\n",
      "train loss:0.00623357146726\n",
      "train loss:0.00025979200299\n",
      "train loss:0.000320382225392\n",
      "train loss:0.00408409998538\n",
      "train loss:0.00683261367928\n",
      "train loss:0.00158082096316\n",
      "train loss:0.00830086000673\n",
      "train loss:0.000347982169055\n",
      "train loss:0.00168381341067\n",
      "train loss:0.00211942964305\n",
      "train loss:0.00488418808767\n",
      "train loss:0.00883496710104\n",
      "train loss:0.00167496376203\n",
      "train loss:0.00413532387082\n",
      "train loss:0.00061668975064\n",
      "train loss:0.000797247754046\n",
      "train loss:0.000870755343919\n",
      "train loss:0.00901202426754\n",
      "train loss:0.0046018031003\n",
      "train loss:0.01057773882\n",
      "train loss:0.00123977840972\n",
      "train loss:0.0105798015624\n",
      "train loss:0.0166135385432\n",
      "train loss:0.00432907834808\n",
      "train loss:0.00248054347108\n",
      "train loss:0.00507033935979\n",
      "train loss:0.0125425588209\n",
      "train loss:0.0026899411342\n",
      "train loss:0.00384978900229\n",
      "train loss:0.000237359337525\n",
      "train loss:0.00045391350316\n",
      "train loss:0.00487531846182\n",
      "train loss:0.00286881634834\n",
      "train loss:0.00172464219942\n",
      "train loss:0.000139912089816\n",
      "train loss:0.00138696428981\n",
      "train loss:0.00351217210433\n",
      "train loss:0.00122764603062\n",
      "train loss:0.00462770003247\n",
      "train loss:0.00785377432577\n",
      "train loss:0.000790869531267\n",
      "train loss:0.00229159288295\n",
      "train loss:0.00178737403905\n",
      "train loss:0.00300246708593\n",
      "train loss:0.000495228444605\n",
      "train loss:0.0022888991427\n",
      "train loss:0.00014038438772\n",
      "train loss:0.00133613295914\n",
      "train loss:0.00494985403943\n",
      "train loss:0.00138429385316\n",
      "train loss:0.00522557089167\n",
      "train loss:0.00839963482581\n",
      "train loss:0.000372116885907\n",
      "train loss:0.00016908148895\n",
      "train loss:0.00203728027034\n",
      "train loss:0.000537393989524\n",
      "train loss:0.000887641517459\n",
      "train loss:0.00504058352883\n",
      "train loss:0.00266215740128\n",
      "train loss:0.00375939208444\n",
      "train loss:0.00234480045512\n",
      "train loss:0.00271806005414\n",
      "train loss:0.00413773146222\n",
      "train loss:0.00261486727211\n",
      "train loss:0.00582258982726\n",
      "train loss:0.0166195926637\n",
      "train loss:0.00562303423432\n",
      "train loss:0.0283166776537\n",
      "train loss:0.0029055160238\n",
      "train loss:0.00441324264709\n",
      "train loss:0.00377442498567\n",
      "train loss:0.0233701501091\n",
      "train loss:0.00175976464174\n",
      "train loss:0.00108061998252\n",
      "train loss:4.86256597682e-05\n",
      "train loss:0.00351693557687\n",
      "train loss:0.00428414615707\n",
      "train loss:0.00492671833429\n",
      "train loss:0.00624509477898\n",
      "train loss:0.00266075698273\n",
      "train loss:0.00776021640283\n",
      "train loss:0.00974994023044\n",
      "train loss:0.0032217566938\n",
      "train loss:0.000309229997503\n",
      "train loss:0.00309217896866\n",
      "train loss:0.000602651460094\n",
      "train loss:0.00197200691385\n",
      "train loss:0.00197927049957\n",
      "train loss:0.000173776249618\n",
      "train loss:0.0132552425673\n",
      "train loss:0.000397223794403\n",
      "train loss:0.00715783015939\n",
      "train loss:0.00602528253532\n",
      "train loss:0.000635111252669\n",
      "train loss:0.00105244496915\n",
      "train loss:0.00108702506366\n",
      "train loss:0.00117751963537\n",
      "train loss:0.00229591689839\n",
      "train loss:0.00734356885892\n",
      "train loss:0.0092028071093\n",
      "train loss:0.000920521105821\n",
      "train loss:0.000825903965076\n",
      "train loss:0.00516447583541\n",
      "train loss:0.00998792283311\n",
      "train loss:0.00598983724448\n",
      "train loss:0.000880894348859\n",
      "train loss:0.00345103944936\n",
      "train loss:0.000402731047306\n",
      "train loss:0.000559816077148\n",
      "train loss:0.0143879343622\n",
      "train loss:0.00391514201556\n",
      "train loss:0.00302767302092\n",
      "train loss:0.0165752534631\n",
      "train loss:0.00493454145136\n",
      "train loss:0.00347966870651\n",
      "train loss:0.00116748184294\n",
      "train loss:0.00273883858649\n",
      "train loss:0.0002095920092\n",
      "train loss:0.00214092161069\n",
      "train loss:0.00167075310169\n",
      "train loss:0.0024856396013\n",
      "train loss:0.013372437359\n",
      "train loss:0.00372152018735\n",
      "train loss:0.00933935014559\n",
      "train loss:0.00539452563266\n",
      "train loss:6.10075064212e-05\n",
      "train loss:0.0157745345745\n",
      "train loss:0.000286082976926\n",
      "train loss:0.0019599721221\n",
      "train loss:0.000883575303152\n",
      "train loss:0.00384112074017\n",
      "train loss:0.00340491312867\n",
      "train loss:0.00176037205364\n",
      "train loss:0.00106387632087\n",
      "train loss:0.00323103057781\n",
      "train loss:0.00714433393876\n",
      "train loss:0.00599131159374\n",
      "train loss:0.000132509373286\n",
      "train loss:0.00443521743168\n",
      "train loss:0.00391951229716\n",
      "train loss:0.00190305122523\n",
      "train loss:0.000498896198987\n",
      "train loss:0.00228116500763\n",
      "train loss:0.000729599571328\n",
      "train loss:0.00975621732424\n",
      "train loss:0.00364307036118\n",
      "train loss:0.00221681778752\n",
      "train loss:0.00657163898039\n",
      "train loss:0.00133428275962\n",
      "train loss:0.000280875878842\n",
      "train loss:0.00253872140384\n",
      "train loss:0.00178231615769\n",
      "train loss:0.000725445293349\n",
      "train loss:0.000450540794203\n",
      "train loss:0.00403091461705\n",
      "train loss:0.00220454605802\n",
      "train loss:0.00431672010119\n",
      "train loss:0.000344084527361\n",
      "train loss:0.0591661026684\n",
      "train loss:0.00514510230416\n",
      "train loss:0.00120038242978\n",
      "train loss:0.0223775850791\n",
      "train loss:0.00307369434894\n",
      "train loss:0.00179396299322\n",
      "train loss:0.00432808196859\n",
      "train loss:0.0129381871638\n",
      "train loss:0.000406977729264\n",
      "train loss:0.000421608342236\n",
      "train loss:0.00162596538711\n",
      "train loss:0.0147632325416\n",
      "train loss:0.00212322401662\n",
      "train loss:0.0129633002982\n",
      "train loss:0.0123336774985\n",
      "train loss:0.00101037392648\n",
      "train loss:0.00354985628238\n",
      "train loss:0.00130791968329\n",
      "train loss:0.00863410078782\n",
      "train loss:0.00030929250925\n",
      "train loss:0.00141313550332\n",
      "train loss:0.00186590413095\n",
      "train loss:0.00101355546368\n",
      "train loss:0.00047906370024\n",
      "train loss:0.000636062476284\n",
      "train loss:0.000831982878567\n",
      "train loss:0.0177915408082\n",
      "train loss:0.000990275268571\n",
      "train loss:0.00233957404523\n",
      "train loss:0.000460532421975\n",
      "train loss:0.00714396837879\n",
      "train loss:0.00546031982301\n",
      "train loss:0.00215257042746\n",
      "train loss:0.000507766788595\n",
      "train loss:0.00140166987289\n",
      "train loss:0.00141565045807\n",
      "train loss:0.0019517895361\n",
      "train loss:0.00210445890712\n",
      "train loss:0.00596950657673\n",
      "train loss:0.00142928339935\n",
      "train loss:0.00033909773496\n",
      "train loss:0.019586814157\n",
      "train loss:0.00131828415324\n",
      "train loss:0.000823717140153\n",
      "train loss:0.0090714049414\n",
      "train loss:0.00269959519841\n",
      "train loss:0.00114471622155\n",
      "train loss:0.000675891160256\n",
      "train loss:0.00418872878915\n",
      "train loss:0.000404553209365\n",
      "train loss:0.000736806450519\n",
      "train loss:0.00260110049873\n",
      "train loss:0.00489583972465\n",
      "train loss:0.00593601607424\n",
      "train loss:0.0103974473143\n",
      "train loss:0.00499633101924\n",
      "train loss:0.000626308661095\n",
      "train loss:0.000426897182876\n",
      "train loss:0.00469512706042\n",
      "train loss:0.000243649466566\n",
      "train loss:0.000398024726901\n",
      "train loss:0.000832633434788\n",
      "train loss:0.0142028622504\n",
      "train loss:0.00803441774977\n",
      "train loss:0.00609588579449\n",
      "train loss:0.00228519816468\n",
      "train loss:0.00373604467564\n",
      "train loss:0.00477434817049\n",
      "train loss:0.000354161846202\n",
      "train loss:0.00203687750486\n",
      "train loss:0.00431284618143\n",
      "train loss:0.00827369343083\n",
      "train loss:0.0073959164245\n",
      "train loss:0.00975418206377\n",
      "train loss:0.00263277639582\n",
      "train loss:0.000621938094217\n",
      "train loss:0.00137523724069\n",
      "train loss:0.00380582311623\n",
      "train loss:0.00449842187129\n",
      "train loss:0.000899089583577\n",
      "train loss:0.00465243448405\n",
      "train loss:0.00424110573593\n",
      "train loss:0.000603456091969\n",
      "train loss:0.00848335912057\n",
      "train loss:0.00458690829773\n",
      "train loss:0.00317812932853\n",
      "train loss:0.000610614925286\n",
      "train loss:0.0039663669025\n",
      "train loss:0.0101116149513\n",
      "train loss:0.00915909036254\n",
      "train loss:0.000981171026223\n",
      "train loss:8.29369973344e-05\n",
      "train loss:0.00280869353305\n",
      "train loss:0.00605760309906\n",
      "train loss:0.000423412561226\n",
      "train loss:0.00106961749917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00439769855482\n",
      "train loss:0.00124314244317\n",
      "train loss:0.00207647017593\n",
      "train loss:0.000764091797855\n",
      "train loss:0.00178912480652\n",
      "train loss:0.00132593143494\n",
      "train loss:0.00352254491864\n",
      "train loss:0.00857587760185\n",
      "train loss:0.000255363740966\n",
      "train loss:0.0038884176105\n",
      "train loss:0.000822815530903\n",
      "train loss:0.0040904062471\n",
      "train loss:0.00306784773991\n",
      "train loss:0.000926760807159\n",
      "train loss:0.00330624816542\n",
      "train loss:0.00220477987749\n",
      "train loss:0.00229100698447\n",
      "train loss:0.00419198032897\n",
      "train loss:0.00143573046198\n",
      "train loss:0.00680930851402\n",
      "train loss:0.00440915044068\n",
      "train loss:0.00210993868362\n",
      "train loss:0.00295799004529\n",
      "train loss:0.00208841881306\n",
      "train loss:0.000533232565287\n",
      "train loss:0.000909071789139\n",
      "train loss:0.00141546133287\n",
      "train loss:0.00141746146773\n",
      "train loss:0.000280491620623\n",
      "train loss:0.0269756189728\n",
      "train loss:0.00245684759\n",
      "train loss:0.000635982337184\n",
      "train loss:0.00109307810198\n",
      "train loss:0.00308804252443\n",
      "train loss:0.00798304288446\n",
      "train loss:0.000799924099649\n",
      "train loss:0.000267029469187\n",
      "train loss:0.00440665932635\n",
      "train loss:0.00177542097745\n",
      "train loss:7.96586392542e-05\n",
      "train loss:0.00660255963782\n",
      "train loss:0.00745079766848\n",
      "train loss:0.00380989640348\n",
      "train loss:0.00169437713837\n",
      "train loss:0.00222833623224\n",
      "train loss:0.0336128786441\n",
      "train loss:0.00342794310069\n",
      "train loss:0.00220341704725\n",
      "train loss:0.00264758945463\n",
      "train loss:0.000123977850989\n",
      "train loss:0.00190592382216\n",
      "train loss:0.000703798787766\n",
      "train loss:0.00555091336516\n",
      "train loss:0.00143242821449\n",
      "train loss:0.00125971143225\n",
      "train loss:0.00105150467259\n",
      "train loss:0.0200504589756\n",
      "train loss:0.00272907339085\n",
      "train loss:0.00141815053429\n",
      "train loss:0.00251059542998\n",
      "train loss:0.00341950056239\n",
      "train loss:0.0555043400544\n",
      "train loss:0.00080036734398\n",
      "train loss:0.000234083317272\n",
      "train loss:0.00149363374713\n",
      "train loss:0.00484981164254\n",
      "train loss:0.00879186708179\n",
      "train loss:0.00268408487466\n",
      "train loss:0.00290060338033\n",
      "train loss:0.0111421618563\n",
      "train loss:0.000372982574946\n",
      "train loss:0.000805655082602\n",
      "train loss:0.0227676717917\n",
      "train loss:0.00451862857056\n",
      "train loss:0.00238773308695\n",
      "train loss:0.00174830896842\n",
      "train loss:0.0116829633402\n",
      "train loss:0.00606598229903\n",
      "train loss:0.00311689966973\n",
      "train loss:0.00155979890231\n",
      "train loss:0.00211856083175\n",
      "train loss:0.00342559927077\n",
      "train loss:0.00439079533844\n",
      "train loss:0.00165212496138\n",
      "train loss:0.000259664536895\n",
      "train loss:0.00233776478616\n",
      "train loss:0.00119936828564\n",
      "train loss:0.00363811225799\n",
      "train loss:0.00148752820219\n",
      "train loss:0.00217860261087\n",
      "train loss:0.00374964654211\n",
      "train loss:0.00222516246703\n",
      "train loss:0.00187978821231\n",
      "train loss:0.00389340410744\n",
      "train loss:0.000400849542135\n",
      "train loss:0.00183754313395\n",
      "train loss:0.000155125638288\n",
      "train loss:0.00239695836165\n",
      "train loss:0.00104617252718\n",
      "train loss:0.0022003390105\n",
      "train loss:0.000970575608645\n",
      "train loss:0.000141964241015\n",
      "train loss:0.00524218705463\n",
      "train loss:0.0010506002731\n",
      "train loss:0.000516630486557\n",
      "train loss:0.00408708232997\n",
      "train loss:0.00103287153055\n",
      "train loss:0.00235578077552\n",
      "train loss:0.0042268388296\n",
      "train loss:0.000850993750232\n",
      "train loss:0.000694591642904\n",
      "train loss:0.00697424308291\n",
      "train loss:0.00222923928374\n",
      "train loss:0.000330984560441\n",
      "train loss:0.00469032032409\n",
      "train loss:0.0198863128961\n",
      "train loss:0.0117387047283\n",
      "train loss:0.00101809136636\n",
      "train loss:0.00101571832178\n",
      "train loss:0.00195459022038\n",
      "train loss:0.00126409989775\n",
      "train loss:0.00859212399035\n",
      "train loss:0.00191707821216\n",
      "train loss:0.00144425999416\n",
      "train loss:0.000162619198647\n",
      "train loss:0.000719113363619\n",
      "train loss:0.0010043823752\n",
      "train loss:0.00322876890765\n",
      "train loss:0.00664677033478\n",
      "train loss:0.00348518283023\n",
      "train loss:0.00404911166702\n",
      "train loss:0.00102991693836\n",
      "train loss:0.00599849981311\n",
      "train loss:0.00288404733644\n",
      "train loss:0.00164374706023\n",
      "train loss:0.00152200265309\n",
      "train loss:0.000733428910833\n",
      "train loss:0.00870329716488\n",
      "train loss:0.00111076086008\n",
      "train loss:0.000546116421125\n",
      "train loss:0.00183011925753\n",
      "train loss:0.000541383965507\n",
      "train loss:0.000317219357282\n",
      "train loss:0.00175464655845\n",
      "train loss:0.000167574263689\n",
      "train loss:0.0025962000265\n",
      "train loss:0.000253120816906\n",
      "train loss:0.00172214287325\n",
      "train loss:0.00453659077084\n",
      "train loss:0.00139847831933\n",
      "train loss:0.00557675937655\n",
      "train loss:0.000355570008236\n",
      "train loss:0.000654788041851\n",
      "train loss:0.000529864799519\n",
      "train loss:0.00373628026018\n",
      "train loss:0.00290398744653\n",
      "train loss:0.0213840004465\n",
      "train loss:0.000587942054181\n",
      "train loss:0.00221694638408\n",
      "train loss:0.00108860931302\n",
      "train loss:0.00291860702628\n",
      "train loss:0.000372785224963\n",
      "train loss:0.00293949858158\n",
      "train loss:0.000179574733843\n",
      "train loss:0.00125343190076\n",
      "train loss:0.00191986503547\n",
      "train loss:0.00836623506662\n",
      "train loss:0.00189400044646\n",
      "train loss:5.66953819931e-05\n",
      "train loss:0.00185450062036\n",
      "train loss:0.000425539672837\n",
      "train loss:0.000347675424697\n",
      "train loss:0.000535406894139\n",
      "train loss:0.00309720839871\n",
      "train loss:0.00349758735298\n",
      "train loss:0.00146599088874\n",
      "train loss:0.00019182604392\n",
      "train loss:0.000148673422998\n",
      "train loss:0.0116160761572\n",
      "train loss:4.94388271987e-05\n",
      "train loss:0.000888170503722\n",
      "train loss:0.00252213860757\n",
      "train loss:0.00112517523899\n",
      "train loss:6.80338736448e-05\n",
      "train loss:0.00230815013296\n",
      "train loss:0.00598834558564\n",
      "train loss:0.00410331866157\n",
      "train loss:0.0560516159511\n",
      "train loss:0.00425567053379\n",
      "train loss:0.00106842970644\n",
      "train loss:0.000663977200999\n",
      "train loss:0.00133806869148\n",
      "train loss:0.00174627311923\n",
      "train loss:0.00146320921542\n",
      "train loss:0.00792511247935\n",
      "train loss:0.000585980733306\n",
      "train loss:0.0183682173333\n",
      "train loss:0.00900114561862\n",
      "train loss:0.00124214159962\n",
      "train loss:0.00397727615847\n",
      "train loss:0.00180363425117\n",
      "train loss:0.000216042074347\n",
      "train loss:0.00281510126078\n",
      "train loss:0.00106470454918\n",
      "train loss:0.00449218510271\n",
      "train loss:0.00246684161417\n",
      "train loss:0.000993637241071\n",
      "train loss:0.00866850199007\n",
      "train loss:0.00188822273491\n",
      "train loss:0.00217363612954\n",
      "train loss:0.000125156461564\n",
      "train loss:0.00139257132988\n",
      "train loss:0.0018538546513\n",
      "train loss:0.00393691260515\n",
      "train loss:0.00684749374251\n",
      "train loss:0.000208279620984\n",
      "train loss:0.00244226641583\n",
      "train loss:0.00107727467902\n",
      "train loss:0.00361707539275\n",
      "train loss:0.00171746776407\n",
      "train loss:0.00260180402484\n",
      "train loss:0.00381212695295\n",
      "train loss:0.000560224006665\n",
      "train loss:0.00063694881212\n",
      "train loss:0.00170776464819\n",
      "train loss:0.00891751090139\n",
      "train loss:0.000842531396221\n",
      "train loss:0.000677343393237\n",
      "train loss:0.00244512685069\n",
      "train loss:0.00228984698062\n",
      "train loss:0.0234543395527\n",
      "train loss:0.00215844519622\n",
      "train loss:0.00184754189864\n",
      "train loss:0.00139238263692\n",
      "train loss:0.00628096543652\n",
      "train loss:0.00103245546247\n",
      "train loss:0.002046113681\n",
      "train loss:0.00134160447049\n",
      "train loss:0.00700933161948\n",
      "train loss:0.000759330583581\n",
      "train loss:0.000369115769533\n",
      "train loss:0.000734676432421\n",
      "train loss:0.00126190416258\n",
      "train loss:0.00326773343545\n",
      "train loss:0.00103280622715\n",
      "train loss:0.00494645415376\n",
      "train loss:0.004626707217\n",
      "train loss:0.00498786018185\n",
      "train loss:0.00739112498652\n",
      "train loss:0.00268658747218\n",
      "train loss:0.00176996150707\n",
      "train loss:0.0042291656034\n",
      "train loss:0.00110273145594\n",
      "train loss:0.00123482567311\n",
      "train loss:0.000310291380387\n",
      "train loss:0.00601663909768\n",
      "train loss:0.000285468442061\n",
      "train loss:0.00177689717366\n",
      "train loss:0.00593537065744\n",
      "train loss:0.00205906298128\n",
      "train loss:0.000703154677953\n",
      "train loss:0.000967121501052\n",
      "train loss:0.00153180512307\n",
      "train loss:0.000615795915648\n",
      "train loss:0.00272885061348\n",
      "train loss:0.00185234243747\n",
      "train loss:0.00126455994224\n",
      "train loss:0.00800827764274\n",
      "train loss:0.00126651203108\n",
      "train loss:0.000751139112928\n",
      "train loss:0.000410333432193\n",
      "train loss:0.00285242532152\n",
      "train loss:0.000278890794153\n",
      "train loss:0.000409329356053\n",
      "train loss:0.00526116769466\n",
      "train loss:0.000916563059878\n",
      "train loss:0.00168413313427\n",
      "train loss:0.0333912598403\n",
      "train loss:0.000805689644664\n",
      "train loss:0.00227627895061\n",
      "train loss:0.000140554170905\n",
      "train loss:0.00462089060098\n",
      "train loss:0.000307919762956\n",
      "train loss:0.00146062194042\n",
      "train loss:0.00136066453171\n",
      "train loss:0.00346819874749\n",
      "train loss:0.00286721695745\n",
      "train loss:0.00301498767016\n",
      "train loss:0.0014320227945\n",
      "train loss:0.00577890544243\n",
      "train loss:0.00283935114589\n",
      "train loss:0.00265926136196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00243176400479\n",
      "train loss:0.00113534932697\n",
      "train loss:0.00680833126752\n",
      "train loss:0.00121128052253\n",
      "train loss:0.000329309223978\n",
      "train loss:0.000158303097435\n",
      "train loss:0.00119457196289\n",
      "train loss:0.00256333652179\n",
      "train loss:0.000206779432115\n",
      "train loss:0.000274039274224\n",
      "train loss:0.000114494592696\n",
      "train loss:0.00029286202424\n",
      "train loss:0.00234728175055\n",
      "train loss:0.00088895363329\n",
      "train loss:0.00875227345652\n",
      "train loss:0.00311193061476\n",
      "train loss:0.00522068972487\n",
      "train loss:0.022940069544\n",
      "train loss:0.00186920433324\n",
      "train loss:0.00873314462418\n",
      "train loss:0.00917487156949\n",
      "train loss:0.000454873292957\n",
      "train loss:0.0139187765709\n",
      "train loss:0.0085502893519\n",
      "train loss:0.0140301117186\n",
      "train loss:0.00530604014138\n",
      "=== epoch:16, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.00967264213789\n",
      "train loss:0.00298642158216\n",
      "train loss:0.000793866007833\n",
      "train loss:0.00209844066258\n",
      "train loss:0.00472963026977\n",
      "train loss:0.00586199787178\n",
      "train loss:0.00340246520942\n",
      "train loss:0.00983719294709\n",
      "train loss:0.00318180753507\n",
      "train loss:0.00307521058037\n",
      "train loss:0.00140085892232\n",
      "train loss:0.0017340546351\n",
      "train loss:0.00385000123634\n",
      "train loss:0.000223095638795\n",
      "train loss:0.00021158322623\n",
      "train loss:0.00624695035463\n",
      "train loss:0.00945938668109\n",
      "train loss:0.00120251833388\n",
      "train loss:0.0042037402447\n",
      "train loss:0.0181273820571\n",
      "train loss:0.0060809566079\n",
      "train loss:0.00924063430862\n",
      "train loss:0.000842885469166\n",
      "train loss:0.00114416500933\n",
      "train loss:0.000146559975229\n",
      "train loss:0.00147418993914\n",
      "train loss:0.00109550138836\n",
      "train loss:0.00818190238682\n",
      "train loss:0.00384857749299\n",
      "train loss:0.000399450320103\n",
      "train loss:0.00895741005167\n",
      "train loss:0.00638067826707\n",
      "train loss:0.000425415828731\n",
      "train loss:0.00100735766825\n",
      "train loss:0.0055536254638\n",
      "train loss:0.00341054026577\n",
      "train loss:0.00062523161349\n",
      "train loss:0.0129284581108\n",
      "train loss:0.000255620319131\n",
      "train loss:0.0014491134353\n",
      "train loss:0.00115045609691\n",
      "train loss:9.12709039198e-05\n",
      "train loss:0.000255263181871\n",
      "train loss:0.000390948617657\n",
      "train loss:0.0027666058719\n",
      "train loss:0.00487138129723\n",
      "train loss:0.00418879084017\n",
      "train loss:0.000214767132848\n",
      "train loss:0.00317138591443\n",
      "train loss:0.00091763611835\n",
      "train loss:0.000753387461429\n",
      "train loss:0.000822293226043\n",
      "train loss:0.0601745345977\n",
      "train loss:0.00217981784232\n",
      "train loss:0.00432258559984\n",
      "train loss:0.00972917801854\n",
      "train loss:0.00230489680789\n",
      "train loss:0.00366459655143\n",
      "train loss:0.00538286680705\n",
      "train loss:0.0278342420647\n",
      "train loss:0.000211408668382\n",
      "train loss:0.000199726170936\n",
      "train loss:0.00363733897383\n",
      "train loss:0.00321639340206\n",
      "train loss:0.000979069338665\n",
      "train loss:0.00131898073052\n",
      "train loss:0.0161109373815\n",
      "train loss:0.0026316948585\n",
      "train loss:0.0067089024455\n",
      "train loss:0.00038289663427\n",
      "train loss:0.000299657231874\n",
      "train loss:0.00143480592983\n",
      "train loss:0.0014801032747\n",
      "train loss:0.00788693589179\n",
      "train loss:0.000666693022028\n",
      "train loss:0.000992750284697\n",
      "train loss:0.00296501709656\n",
      "train loss:0.00189858824323\n",
      "train loss:0.00116187079939\n",
      "train loss:0.000488149297905\n",
      "train loss:0.00214142073695\n",
      "train loss:0.000963823081168\n",
      "train loss:0.00177325414297\n",
      "train loss:0.000601300390172\n",
      "train loss:0.0047047490174\n",
      "train loss:0.00240582093339\n",
      "train loss:0.000783752420468\n",
      "train loss:0.00145429827384\n",
      "train loss:0.00502861884236\n",
      "train loss:0.0108952990458\n",
      "train loss:0.0023490460518\n",
      "train loss:0.00166821826689\n",
      "train loss:0.00413053890465\n",
      "train loss:0.000294169466712\n",
      "train loss:6.60093818744e-05\n",
      "train loss:0.000669579777952\n",
      "train loss:0.000539944999051\n",
      "train loss:0.00159549049792\n",
      "train loss:0.000717127036735\n",
      "train loss:0.000923450339322\n",
      "train loss:8.65128732081e-05\n",
      "train loss:0.00211681350195\n",
      "train loss:0.00286971254584\n",
      "train loss:0.00152056673584\n",
      "train loss:0.00217934364915\n",
      "train loss:0.00142257979863\n",
      "train loss:0.00145798007722\n",
      "train loss:0.000508760839887\n",
      "train loss:6.49143899051e-05\n",
      "train loss:0.00122779917028\n",
      "train loss:0.00461532151042\n",
      "train loss:0.00553902873853\n",
      "train loss:0.00188085821993\n",
      "train loss:0.0010206295\n",
      "train loss:0.00128625351871\n",
      "train loss:0.00231629986355\n",
      "train loss:5.11223007312e-05\n",
      "train loss:0.00207863607948\n",
      "train loss:0.00137460618425\n",
      "train loss:0.00860483465345\n",
      "train loss:0.00108459216831\n",
      "train loss:0.000754453203524\n",
      "train loss:0.00411734358\n",
      "train loss:0.00751569986539\n",
      "train loss:0.0015515801338\n",
      "train loss:0.00377173571109\n",
      "train loss:0.00514741001269\n",
      "train loss:0.000122196127738\n",
      "train loss:0.00131041029436\n",
      "train loss:0.00435650184363\n",
      "train loss:0.000260076777255\n",
      "train loss:0.00258845821541\n",
      "train loss:0.00312870936232\n",
      "train loss:0.00322653275689\n",
      "train loss:0.0036429564069\n",
      "train loss:0.00126914892656\n",
      "train loss:0.000568710344557\n",
      "train loss:0.000724073056962\n",
      "train loss:0.00337437367844\n",
      "train loss:0.000759762772618\n",
      "train loss:0.00194993532551\n",
      "train loss:0.00550773513887\n",
      "train loss:0.00358680451462\n",
      "train loss:0.00528803076162\n",
      "train loss:0.0023537787908\n",
      "train loss:0.000562162568138\n",
      "train loss:0.000515257906828\n",
      "train loss:0.00301693427749\n",
      "train loss:0.000178543931742\n",
      "train loss:0.0015867002592\n",
      "train loss:0.00335533663497\n",
      "train loss:0.000171454152688\n",
      "train loss:0.00430116288579\n",
      "train loss:0.000457136177722\n",
      "train loss:0.00502902838361\n",
      "train loss:0.000126475026522\n",
      "train loss:0.00537893642113\n",
      "train loss:0.000637851710477\n",
      "train loss:0.000763544291928\n",
      "train loss:0.000244842224817\n",
      "train loss:0.00306554765212\n",
      "train loss:0.00182053629024\n",
      "train loss:0.00190001924539\n",
      "train loss:0.00308758289447\n",
      "train loss:0.0020061421572\n",
      "train loss:0.00121877359908\n",
      "train loss:0.000152616184237\n",
      "train loss:0.000235799173192\n",
      "train loss:0.00787184721115\n",
      "train loss:0.000150409034023\n",
      "train loss:0.00639795822533\n",
      "train loss:0.00282966766954\n",
      "train loss:0.000636363595202\n",
      "train loss:0.00146671096256\n",
      "train loss:0.00015344478829\n",
      "train loss:0.00631499823759\n",
      "train loss:0.000223336504021\n",
      "train loss:0.00247002452067\n",
      "train loss:0.000472750987336\n",
      "train loss:0.0017798465503\n",
      "train loss:0.00194969732975\n",
      "train loss:0.00103485554217\n",
      "train loss:0.00413146210581\n",
      "train loss:0.000447346885766\n",
      "train loss:0.00915598159047\n",
      "train loss:0.000654702206578\n",
      "train loss:0.00541112257828\n",
      "train loss:0.000134012798062\n",
      "train loss:0.00398836318812\n",
      "train loss:0.00109913033957\n",
      "train loss:0.00285949567043\n",
      "train loss:0.000345485861338\n",
      "train loss:0.00245719807044\n",
      "train loss:0.000559130842859\n",
      "train loss:0.000403994845505\n",
      "train loss:0.000259808202668\n",
      "train loss:0.000944351258297\n",
      "train loss:0.000912863241786\n",
      "train loss:0.00276651911982\n",
      "train loss:0.00393212555061\n",
      "train loss:0.000134599395417\n",
      "train loss:0.000546422471403\n",
      "train loss:0.000199891104106\n",
      "train loss:5.22963603678e-05\n",
      "train loss:0.00341221111472\n",
      "train loss:0.000780061975451\n",
      "train loss:0.0591580266862\n",
      "train loss:0.000668117103773\n",
      "train loss:0.00207411940236\n",
      "train loss:0.000106820361794\n",
      "train loss:0.000641439312869\n",
      "train loss:0.00128639828893\n",
      "train loss:0.000815755908966\n",
      "train loss:0.0026287243748\n",
      "train loss:0.0014046972229\n",
      "train loss:0.00132540966921\n",
      "train loss:0.000736948359076\n",
      "train loss:0.00719860332327\n",
      "train loss:0.000359264863343\n",
      "train loss:0.00133441478323\n",
      "train loss:0.00258275208575\n",
      "train loss:0.0113899725648\n",
      "train loss:0.00210131780455\n",
      "train loss:0.00409460548266\n",
      "train loss:0.000137210374169\n",
      "train loss:0.000228810125621\n",
      "train loss:0.00275553535531\n",
      "train loss:0.00602133580674\n",
      "train loss:0.00107313920575\n",
      "train loss:0.000265402938469\n",
      "train loss:0.00110224058562\n",
      "train loss:0.00751267965291\n",
      "train loss:0.000277514604963\n",
      "train loss:0.00061686971048\n",
      "train loss:0.000601850245759\n",
      "train loss:0.000163653364408\n",
      "train loss:0.00039808593519\n",
      "train loss:0.00371937678324\n",
      "train loss:0.000675677651144\n",
      "train loss:0.00266582016881\n",
      "train loss:0.00135790835231\n",
      "train loss:0.000208262946039\n",
      "train loss:0.00126740303929\n",
      "train loss:0.00109525377323\n",
      "train loss:0.00148404218554\n",
      "train loss:0.000827449935167\n",
      "train loss:0.000809412817327\n",
      "train loss:0.00135759454834\n",
      "train loss:0.00187974720047\n",
      "train loss:0.0028436144971\n",
      "train loss:0.00165461639636\n",
      "train loss:0.000394595118596\n",
      "train loss:0.000282784703821\n",
      "train loss:0.00112369517459\n",
      "train loss:0.00162159790414\n",
      "train loss:0.0070341455606\n",
      "train loss:0.00106828328881\n",
      "train loss:0.00127113407627\n",
      "train loss:0.000846015894865\n",
      "train loss:0.000957774799924\n",
      "train loss:0.000721869958995\n",
      "train loss:0.00306553108712\n",
      "train loss:0.000246598605279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000206805119497\n",
      "train loss:0.00699273316196\n",
      "train loss:0.000148325549303\n",
      "train loss:0.0168985385016\n",
      "train loss:0.00136067112465\n",
      "train loss:0.00383426547813\n",
      "train loss:0.00126652123055\n",
      "train loss:0.00100537487503\n",
      "train loss:0.000973726106432\n",
      "train loss:0.00284246078726\n",
      "train loss:0.00252286266623\n",
      "train loss:0.00106603944358\n",
      "train loss:0.00227730590676\n",
      "train loss:0.003783292575\n",
      "train loss:0.000568071428166\n",
      "train loss:0.00167301130908\n",
      "train loss:0.000520807620297\n",
      "train loss:0.0024879954285\n",
      "train loss:0.00193565529408\n",
      "train loss:0.00019949851286\n",
      "train loss:0.000798796699663\n",
      "train loss:0.000485890203228\n",
      "train loss:0.0019375699623\n",
      "train loss:0.0018067604337\n",
      "train loss:0.00127604334478\n",
      "train loss:0.00407997842499\n",
      "train loss:0.000713848411534\n",
      "train loss:0.000516586098723\n",
      "train loss:0.00202319309732\n",
      "train loss:0.000202678861089\n",
      "train loss:0.000694072089679\n",
      "train loss:0.00424139166151\n",
      "train loss:0.00221520415489\n",
      "train loss:0.00296013518226\n",
      "train loss:0.00355237871164\n",
      "train loss:0.00419638052351\n",
      "train loss:0.0019027922343\n",
      "train loss:0.000247247164758\n",
      "train loss:0.0011283497262\n",
      "train loss:0.000918274441339\n",
      "train loss:0.00244345695066\n",
      "train loss:0.00551137852751\n",
      "train loss:0.00729602838279\n",
      "train loss:0.000162738017803\n",
      "train loss:0.0002282217257\n",
      "train loss:0.00140506438993\n",
      "train loss:4.06256242933e-05\n",
      "train loss:0.00111292539765\n",
      "train loss:0.000243115823212\n",
      "train loss:0.000134249750426\n",
      "train loss:0.00326374273401\n",
      "train loss:0.00319038830801\n",
      "train loss:0.00571678305561\n",
      "train loss:0.00903871055668\n",
      "train loss:0.000669040365983\n",
      "train loss:0.000241258496857\n",
      "train loss:0.000443994605433\n",
      "train loss:0.000878060760194\n",
      "train loss:0.00521024024592\n",
      "train loss:0.00100901603838\n",
      "train loss:0.00462943596327\n",
      "train loss:0.00243929769399\n",
      "train loss:0.0129892721874\n",
      "train loss:0.0332002468036\n",
      "train loss:0.00890267372819\n",
      "train loss:0.00452209775306\n",
      "train loss:0.000520405647477\n",
      "train loss:0.00286064021652\n",
      "train loss:0.000723207825067\n",
      "train loss:0.000340097539998\n",
      "train loss:0.00443796116583\n",
      "train loss:0.000474218999553\n",
      "train loss:0.00222137911614\n",
      "train loss:0.0014860301178\n",
      "train loss:0.0034513140242\n",
      "train loss:0.00246133080862\n",
      "train loss:0.0171061812941\n",
      "train loss:0.0218705481266\n",
      "train loss:0.0100463927844\n",
      "train loss:0.00711497040646\n",
      "train loss:0.0399377938798\n",
      "train loss:5.96978688063e-05\n",
      "train loss:0.00223157588769\n",
      "train loss:0.0139174411348\n",
      "train loss:0.0021017222593\n",
      "train loss:0.00106254449932\n",
      "train loss:0.00369789799363\n",
      "train loss:0.00078906283543\n",
      "train loss:0.00139903995379\n",
      "train loss:0.000775979580488\n",
      "train loss:0.00505202196112\n",
      "train loss:0.000213974999115\n",
      "train loss:0.0057956069846\n",
      "train loss:0.00237415042298\n",
      "train loss:0.00421737651999\n",
      "train loss:0.0533811703121\n",
      "train loss:0.00436496599053\n",
      "train loss:0.00255153997995\n",
      "train loss:0.000183706769311\n",
      "train loss:0.00393494349561\n",
      "train loss:0.00390369813787\n",
      "train loss:0.00983913913516\n",
      "train loss:0.00321372079344\n",
      "train loss:0.00106474625414\n",
      "train loss:0.00501467853673\n",
      "train loss:0.000357344413599\n",
      "train loss:0.00257076496441\n",
      "train loss:0.00154450434089\n",
      "train loss:0.000403686317566\n",
      "train loss:0.000137691847242\n",
      "train loss:0.000985469134066\n",
      "train loss:0.0019237545502\n",
      "train loss:0.00102131744809\n",
      "train loss:0.001430795615\n",
      "train loss:0.0122745073099\n",
      "train loss:0.00238432304896\n",
      "train loss:0.000711561185296\n",
      "train loss:0.0147534775114\n",
      "train loss:0.000437478892949\n",
      "train loss:0.00216179628209\n",
      "train loss:0.00212805573746\n",
      "train loss:0.00120070957667\n",
      "train loss:0.00277386529272\n",
      "train loss:0.00688474447684\n",
      "train loss:0.00620616126057\n",
      "train loss:0.0092918925537\n",
      "train loss:0.00055326769975\n",
      "train loss:0.00378522612965\n",
      "train loss:0.000326550549438\n",
      "train loss:0.00201720207257\n",
      "train loss:0.00597026272136\n",
      "train loss:0.00149711109314\n",
      "train loss:0.00445293921065\n",
      "train loss:0.000636182890324\n",
      "train loss:0.00120595593368\n",
      "train loss:0.000694044964286\n",
      "train loss:0.00113117184814\n",
      "train loss:0.00171784435348\n",
      "train loss:0.000955467937124\n",
      "train loss:0.00148871797981\n",
      "train loss:0.00161604142542\n",
      "train loss:0.000114330971252\n",
      "train loss:0.000195660068245\n",
      "train loss:0.00770822641056\n",
      "train loss:0.00187813613658\n",
      "train loss:0.0050547249031\n",
      "train loss:0.000173004462525\n",
      "train loss:0.000481131925155\n",
      "train loss:0.00696001168539\n",
      "train loss:0.000360699907169\n",
      "train loss:0.00095750598313\n",
      "train loss:0.000529347973157\n",
      "train loss:0.00188928398585\n",
      "train loss:0.00706982194104\n",
      "train loss:0.00147059819523\n",
      "train loss:0.0015306502606\n",
      "train loss:0.00149812139727\n",
      "train loss:0.00450322242932\n",
      "train loss:0.00249206518212\n",
      "train loss:0.00676043871823\n",
      "train loss:0.00239832234299\n",
      "train loss:0.00213286629791\n",
      "train loss:0.000591458433258\n",
      "train loss:0.0142096194421\n",
      "train loss:0.0047986837367\n",
      "train loss:0.0180711467604\n",
      "train loss:0.0026639903745\n",
      "train loss:4.95832020873e-05\n",
      "train loss:0.00366035893795\n",
      "train loss:0.0135593409882\n",
      "train loss:6.7085999259e-05\n",
      "train loss:0.0005158459981\n",
      "train loss:0.000716601301073\n",
      "train loss:0.00413652962476\n",
      "train loss:0.000197554670996\n",
      "train loss:0.00655579357346\n",
      "train loss:0.00131679587906\n",
      "train loss:0.000745455169686\n",
      "train loss:0.000250086491391\n",
      "train loss:0.000446248322254\n",
      "train loss:0.00277472505864\n",
      "train loss:0.00500032817554\n",
      "train loss:0.00368269342282\n",
      "train loss:0.0176378676864\n",
      "train loss:0.000251671018855\n",
      "train loss:0.00171444125154\n",
      "train loss:0.00372459618033\n",
      "train loss:0.00110691227237\n",
      "train loss:0.00280018874549\n",
      "train loss:0.00468982722146\n",
      "train loss:0.0349253643392\n",
      "train loss:0.00291319904795\n",
      "train loss:0.0218338864671\n",
      "train loss:0.000634819782566\n",
      "train loss:0.00420490413623\n",
      "train loss:0.00104082542337\n",
      "train loss:0.000763316795322\n",
      "train loss:0.014761199299\n",
      "train loss:0.00743796502504\n",
      "train loss:0.0189522442284\n",
      "train loss:0.0325810287407\n",
      "train loss:0.00322166457412\n",
      "train loss:0.000813216010325\n",
      "train loss:0.00251860524804\n",
      "train loss:0.00400693362765\n",
      "train loss:0.00469842868478\n",
      "train loss:0.000594371258124\n",
      "train loss:0.00115395194567\n",
      "train loss:0.0100247464733\n",
      "train loss:0.00547972708633\n",
      "train loss:0.00371701586768\n",
      "train loss:0.0020994548385\n",
      "train loss:0.00148523143152\n",
      "train loss:0.0032308727413\n",
      "train loss:0.0115406615785\n",
      "train loss:0.00142623239339\n",
      "train loss:0.00288138872041\n",
      "train loss:0.00142345495743\n",
      "train loss:0.00726536691677\n",
      "train loss:0.00540651826426\n",
      "train loss:0.00627365414287\n",
      "train loss:0.00160675969716\n",
      "train loss:0.000373881424313\n",
      "train loss:0.00204919786898\n",
      "train loss:0.00269064933584\n",
      "train loss:0.00546658811181\n",
      "train loss:0.0938732422139\n",
      "train loss:0.000857861228932\n",
      "train loss:0.00274939989735\n",
      "train loss:0.00786529291328\n",
      "train loss:0.00153291552982\n",
      "train loss:0.000862551313894\n",
      "train loss:0.000659434272471\n",
      "train loss:0.00157340410374\n",
      "train loss:0.00081104878828\n",
      "train loss:0.00283112540422\n",
      "train loss:0.000677349505927\n",
      "train loss:0.00722558821757\n",
      "train loss:0.00366355230745\n",
      "train loss:0.00378604184988\n",
      "train loss:0.0206051443557\n",
      "train loss:0.000887249748298\n",
      "train loss:0.00182893040158\n",
      "train loss:0.000615791770427\n",
      "train loss:0.00261331780338\n",
      "train loss:0.00398714909016\n",
      "train loss:0.00110472793958\n",
      "train loss:0.00219937844328\n",
      "train loss:0.0108074272699\n",
      "train loss:0.00767572714585\n",
      "train loss:0.00412832171381\n",
      "train loss:0.00440193073449\n",
      "train loss:0.00102535757175\n",
      "train loss:0.00650496209437\n",
      "train loss:0.00232351784652\n",
      "train loss:0.00148210849442\n",
      "train loss:0.00692072984419\n",
      "train loss:0.00029364443497\n",
      "train loss:0.00218020479612\n",
      "train loss:0.000697399358351\n",
      "train loss:0.00364935346527\n",
      "train loss:0.0545808657718\n",
      "train loss:0.0014555584016\n",
      "train loss:0.00078306824608\n",
      "train loss:0.000841951349227\n",
      "train loss:0.000426401254325\n",
      "train loss:0.00371587920507\n",
      "train loss:0.000227061648663\n",
      "train loss:0.00218187003019\n",
      "train loss:0.00113038619472\n",
      "train loss:0.000784394215457\n",
      "train loss:0.000167753283342\n",
      "train loss:0.000327621852649\n",
      "train loss:0.00366121467664\n",
      "train loss:0.0046622293463\n",
      "train loss:0.01162237376\n",
      "train loss:0.00134192159243\n",
      "train loss:0.00539773216718\n",
      "train loss:0.0133294644195\n",
      "train loss:0.000243209010942\n",
      "train loss:0.00198792925465\n",
      "train loss:0.000758764206602\n",
      "train loss:0.00152915307386\n",
      "train loss:0.00330277879095\n",
      "train loss:0.00459815803272\n",
      "train loss:0.000311858302962\n",
      "train loss:0.00324928274581\n",
      "train loss:0.00374533803802\n",
      "train loss:0.00490019007574\n",
      "train loss:0.00698099918503\n",
      "train loss:0.0134976193056\n",
      "train loss:0.00180468677878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0124712938651\n",
      "train loss:0.0021007318023\n",
      "train loss:0.000500595199986\n",
      "train loss:0.000160141237618\n",
      "train loss:0.00104697734666\n",
      "train loss:0.00154244989602\n",
      "train loss:0.00090967305932\n",
      "train loss:0.000743221838088\n",
      "train loss:0.00257489695964\n",
      "train loss:0.000734229415478\n",
      "train loss:0.000387505365829\n",
      "train loss:0.000121880355716\n",
      "train loss:0.00097398085135\n",
      "train loss:0.00418422703995\n",
      "train loss:0.0143429347038\n",
      "train loss:0.000604783841605\n",
      "train loss:0.00204387427125\n",
      "train loss:0.00266598173402\n",
      "train loss:0.000334212020339\n",
      "train loss:0.000415174579689\n",
      "train loss:0.00186023434816\n",
      "train loss:0.00155555747621\n",
      "train loss:0.00270803481247\n",
      "train loss:0.000452598430822\n",
      "train loss:0.000497284816196\n",
      "train loss:0.0174888609094\n",
      "train loss:0.00107509752144\n",
      "train loss:0.000684394999823\n",
      "train loss:0.00136108943215\n",
      "train loss:0.00044029531569\n",
      "train loss:0.000410934328208\n",
      "train loss:0.00366390699563\n",
      "train loss:0.0117208591555\n",
      "train loss:0.00464839842524\n",
      "train loss:0.000626937620692\n",
      "train loss:0.00281148711395\n",
      "train loss:0.023744061566\n",
      "train loss:0.00135024100012\n",
      "train loss:0.00328670528315\n",
      "train loss:0.00179143283206\n",
      "train loss:0.00311683927504\n",
      "train loss:0.00912490780867\n",
      "train loss:0.000936671347078\n",
      "train loss:0.00739796000261\n",
      "train loss:0.00136618938376\n",
      "=== epoch:17, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.00344763730548\n",
      "train loss:0.00287046759789\n",
      "train loss:0.00359854255593\n",
      "train loss:0.000873259089834\n",
      "train loss:0.02602823588\n",
      "train loss:0.0345122540036\n",
      "train loss:0.00343637148593\n",
      "train loss:0.00839373592817\n",
      "train loss:0.00644753202241\n",
      "train loss:0.000820712004313\n",
      "train loss:0.000447612921228\n",
      "train loss:0.000259324867167\n",
      "train loss:0.000376878766973\n",
      "train loss:0.0274326599524\n",
      "train loss:0.00135690136063\n",
      "train loss:0.000747966660702\n",
      "train loss:0.00305468706274\n",
      "train loss:0.0019878659872\n",
      "train loss:0.00959799982424\n",
      "train loss:0.00958541314005\n",
      "train loss:0.00127724240439\n",
      "train loss:0.00228876621244\n",
      "train loss:0.0021438380166\n",
      "train loss:0.00922871969961\n",
      "train loss:0.000776696969723\n",
      "train loss:0.0016508504917\n",
      "train loss:0.00252383419285\n",
      "train loss:0.00816168765782\n",
      "train loss:0.00182830318617\n",
      "train loss:0.00152833663691\n",
      "train loss:0.00260845242773\n",
      "train loss:0.00298190287261\n",
      "train loss:0.0168130561167\n",
      "train loss:0.000386639228335\n",
      "train loss:0.0052957775752\n",
      "train loss:0.00798057854527\n",
      "train loss:0.000333918251531\n",
      "train loss:0.00271294658287\n",
      "train loss:0.000634122032343\n",
      "train loss:0.000468801403404\n",
      "train loss:0.000123416927051\n",
      "train loss:0.00136233116375\n",
      "train loss:0.00108168641961\n",
      "train loss:0.000520986890408\n",
      "train loss:0.00426934916893\n",
      "train loss:0.00293026522881\n",
      "train loss:0.0024816801261\n",
      "train loss:0.0026749408115\n",
      "train loss:0.000584958973397\n",
      "train loss:0.000959680541147\n",
      "train loss:0.00292847317838\n",
      "train loss:4.07638214642e-05\n",
      "train loss:0.00283339784814\n",
      "train loss:0.00258774894605\n",
      "train loss:0.00563735843333\n",
      "train loss:0.00840055228439\n",
      "train loss:0.00369608355232\n",
      "train loss:0.000828216363188\n",
      "train loss:0.000738726074086\n",
      "train loss:0.00014438027777\n",
      "train loss:0.00166545874518\n",
      "train loss:0.00303769965615\n",
      "train loss:0.000593013216211\n",
      "train loss:0.00546770191487\n",
      "train loss:0.00717230971849\n",
      "train loss:8.63299277325e-05\n",
      "train loss:0.000335020008482\n",
      "train loss:0.00111947264863\n",
      "train loss:0.00175124549039\n",
      "train loss:0.00141693982537\n",
      "train loss:0.000616756595441\n",
      "train loss:0.0095406735217\n",
      "train loss:0.0034267968531\n",
      "train loss:0.00242014897048\n",
      "train loss:0.00145824236502\n",
      "train loss:0.00293812897895\n",
      "train loss:0.00206765200837\n",
      "train loss:0.00503121768464\n",
      "train loss:0.0113046053175\n",
      "train loss:0.000854411799557\n",
      "train loss:0.000525907283451\n",
      "train loss:0.00221393561278\n",
      "train loss:0.0141295000822\n",
      "train loss:0.000575710718269\n",
      "train loss:0.00148141810848\n",
      "train loss:0.00193744874414\n",
      "train loss:0.00701997031372\n",
      "train loss:0.0077532797357\n",
      "train loss:0.00237788757259\n",
      "train loss:0.00168952241775\n",
      "train loss:0.000778256501292\n",
      "train loss:0.00299592950116\n",
      "train loss:0.0121213337853\n",
      "train loss:0.000386508210497\n",
      "train loss:0.00142244577144\n",
      "train loss:0.00172094424412\n",
      "train loss:0.00245666078607\n",
      "train loss:0.000233328623958\n",
      "train loss:0.00373422276805\n",
      "train loss:0.0331578456929\n",
      "train loss:0.00436765478143\n",
      "train loss:0.000290151095618\n",
      "train loss:0.00188597126405\n",
      "train loss:0.000404164994391\n",
      "train loss:0.00216955061729\n",
      "train loss:0.00087802340619\n",
      "train loss:0.00101946881982\n",
      "train loss:0.00649546025138\n",
      "train loss:0.00942285278952\n",
      "train loss:0.000908131027484\n",
      "train loss:0.000603776248742\n",
      "train loss:0.000407657712704\n",
      "train loss:0.00143635486464\n",
      "train loss:0.00740161495849\n",
      "train loss:0.00664692092583\n",
      "train loss:0.0116457457575\n",
      "train loss:0.0528018595867\n",
      "train loss:0.00400232111218\n",
      "train loss:0.00195530893912\n",
      "train loss:0.000962754790226\n",
      "train loss:0.000345539960302\n",
      "train loss:0.00180926285341\n",
      "train loss:0.000987826976168\n",
      "train loss:0.000871342229879\n",
      "train loss:0.00361332258714\n",
      "train loss:0.00594840881802\n",
      "train loss:0.000963649451304\n",
      "train loss:0.00857660006882\n",
      "train loss:0.00206295213336\n",
      "train loss:0.00114262349502\n",
      "train loss:0.0041939363934\n",
      "train loss:0.00218212900817\n",
      "train loss:0.0150122124177\n",
      "train loss:0.000116843194631\n",
      "train loss:0.0300765769233\n",
      "train loss:0.000964043454027\n",
      "train loss:0.000302195387186\n",
      "train loss:0.00150462116081\n",
      "train loss:0.00707677631121\n",
      "train loss:0.00238923107795\n",
      "train loss:0.00267014734417\n",
      "train loss:0.000976356261145\n",
      "train loss:0.000129960406499\n",
      "train loss:0.00231512289774\n",
      "train loss:0.00274663457752\n",
      "train loss:0.000220623468155\n",
      "train loss:0.00137708371943\n",
      "train loss:0.000164853970394\n",
      "train loss:0.0175672717127\n",
      "train loss:0.0122648816016\n",
      "train loss:0.000320470519485\n",
      "train loss:0.00130862892813\n",
      "train loss:0.0038617682988\n",
      "train loss:0.000440791472929\n",
      "train loss:0.000847216397729\n",
      "train loss:0.000949136877614\n",
      "train loss:5.29202357682e-05\n",
      "train loss:0.0022417581374\n",
      "train loss:0.000666138634642\n",
      "train loss:0.00310409711533\n",
      "train loss:0.0221235693006\n",
      "train loss:0.000322222760539\n",
      "train loss:0.00199894372636\n",
      "train loss:0.0336168235397\n",
      "train loss:0.000114244360806\n",
      "train loss:0.0235265396298\n",
      "train loss:0.0033692678749\n",
      "train loss:0.00580523883704\n",
      "train loss:0.000982832762751\n",
      "train loss:0.00241481007232\n",
      "train loss:0.000545237337804\n",
      "train loss:0.000963459345877\n",
      "train loss:0.000512095870384\n",
      "train loss:0.00418058281832\n",
      "train loss:0.00360857343957\n",
      "train loss:0.000462153183307\n",
      "train loss:0.00223583339676\n",
      "train loss:0.000743815088359\n",
      "train loss:0.000409499276495\n",
      "train loss:0.00191808238579\n",
      "train loss:0.000872093955629\n",
      "train loss:0.00194033086852\n",
      "train loss:0.00184983233554\n",
      "train loss:0.00277660709771\n",
      "train loss:0.00219956399789\n",
      "train loss:0.00485906224326\n",
      "train loss:0.00112458017505\n",
      "train loss:0.0030720129863\n",
      "train loss:0.00583815301579\n",
      "train loss:0.00125756629486\n",
      "train loss:0.00357074244892\n",
      "train loss:0.00871648477947\n",
      "train loss:0.000341453442581\n",
      "train loss:0.00103854780251\n",
      "train loss:0.00147307327143\n",
      "train loss:0.000709683485295\n",
      "train loss:0.000415901696793\n",
      "train loss:0.00457751479417\n",
      "train loss:0.00106284409926\n",
      "train loss:0.000267803374281\n",
      "train loss:0.00268774897468\n",
      "train loss:0.00142041307064\n",
      "train loss:0.00546614110372\n",
      "train loss:0.000550940622044\n",
      "train loss:0.00186070038978\n",
      "train loss:8.83858249788e-05\n",
      "train loss:0.000501081456901\n",
      "train loss:0.000574316736856\n",
      "train loss:0.00261451516766\n",
      "train loss:0.00676200136291\n",
      "train loss:0.00023484950991\n",
      "train loss:0.00163567786972\n",
      "train loss:0.00211390769841\n",
      "train loss:0.00411268491842\n",
      "train loss:0.00388909982776\n",
      "train loss:0.00120608515324\n",
      "train loss:0.00212177401917\n",
      "train loss:0.000668802749399\n",
      "train loss:0.0378176538757\n",
      "train loss:0.00277263423667\n",
      "train loss:0.00522157399713\n",
      "train loss:0.000432924199852\n",
      "train loss:0.000452823685835\n",
      "train loss:0.00990876861446\n",
      "train loss:0.0258043558334\n",
      "train loss:0.000101432762274\n",
      "train loss:0.00244036080944\n",
      "train loss:0.00117524757287\n",
      "train loss:0.00143544925929\n",
      "train loss:0.000865200911644\n",
      "train loss:0.00012049138706\n",
      "train loss:0.00491249656696\n",
      "train loss:0.00112121633656\n",
      "train loss:0.000194121865601\n",
      "train loss:0.00254392823638\n",
      "train loss:0.00151114922521\n",
      "train loss:0.00406117714093\n",
      "train loss:0.0135794832966\n",
      "train loss:0.000627441665887\n",
      "train loss:0.00307425377265\n",
      "train loss:0.00440807795411\n",
      "train loss:0.00150019042807\n",
      "train loss:0.00181188840096\n",
      "train loss:0.000109063140999\n",
      "train loss:8.33737812248e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00601466396897\n",
      "train loss:0.00115229794309\n",
      "train loss:0.0025719452577\n",
      "train loss:0.00353206841319\n",
      "train loss:0.000722616235079\n",
      "train loss:0.0276671691621\n",
      "train loss:0.00260730931953\n",
      "train loss:0.00802671832124\n",
      "train loss:0.00743378921534\n",
      "train loss:0.000634981678646\n",
      "train loss:0.00107753505443\n",
      "train loss:0.0102614950928\n",
      "train loss:0.000609821569412\n",
      "train loss:0.000404743651116\n",
      "train loss:0.00407510067969\n",
      "train loss:0.00326828712214\n",
      "train loss:0.000122275974412\n",
      "train loss:0.00278297940603\n",
      "train loss:0.000689650011959\n",
      "train loss:0.00324893606924\n",
      "train loss:0.0106082514406\n",
      "train loss:0.00224853804524\n",
      "train loss:0.00382225337942\n",
      "train loss:0.00136620219607\n",
      "train loss:0.00261485795566\n",
      "train loss:0.00149799980644\n",
      "train loss:0.00098749570692\n",
      "train loss:0.00563716059245\n",
      "train loss:0.00377084043966\n",
      "train loss:0.000682797452777\n",
      "train loss:0.00700288843847\n",
      "train loss:0.00212774725834\n",
      "train loss:0.00497717183377\n",
      "train loss:0.00157761248071\n",
      "train loss:0.000571339825014\n",
      "train loss:0.00108587163828\n",
      "train loss:0.00268387440698\n",
      "train loss:0.000363940568437\n",
      "train loss:0.00195470758063\n",
      "train loss:0.000901338095777\n",
      "train loss:0.0107664770167\n",
      "train loss:0.0012417010967\n",
      "train loss:0.00235997176983\n",
      "train loss:0.0777732462103\n",
      "train loss:0.00161276171638\n",
      "train loss:0.000243830135753\n",
      "train loss:0.00022181574173\n",
      "train loss:0.00406441506803\n",
      "train loss:0.000333242560456\n",
      "train loss:0.000907517452668\n",
      "train loss:0.00170202751169\n",
      "train loss:0.000102228091405\n",
      "train loss:0.00653720235671\n",
      "train loss:0.000413650037412\n",
      "train loss:0.00807014817516\n",
      "train loss:0.00124412862549\n",
      "train loss:0.0113670356732\n",
      "train loss:0.00202405345228\n",
      "train loss:0.000292374904649\n",
      "train loss:0.000633665215465\n",
      "train loss:0.000299555571543\n",
      "train loss:0.00051296492293\n",
      "train loss:0.000579725358347\n",
      "train loss:0.0173536570136\n",
      "train loss:0.00320232043517\n",
      "train loss:0.000722269568051\n",
      "train loss:0.000918022828982\n",
      "train loss:0.00466159841821\n",
      "train loss:0.0145680347685\n",
      "train loss:0.00127927104481\n",
      "train loss:0.000499610881919\n",
      "train loss:0.00164215210094\n",
      "train loss:0.000208770182142\n",
      "train loss:0.000660079974202\n",
      "train loss:0.00104623582701\n",
      "train loss:0.00471407866503\n",
      "train loss:0.0146533873\n",
      "train loss:0.0170868176213\n",
      "train loss:0.000124972599388\n",
      "train loss:0.00615977649087\n",
      "train loss:0.00278138560217\n",
      "train loss:0.00162359277438\n",
      "train loss:0.00243971820989\n",
      "train loss:0.00295008099802\n",
      "train loss:0.000928444495793\n",
      "train loss:0.0266704177419\n",
      "train loss:0.00193764404078\n",
      "train loss:0.000985931505725\n",
      "train loss:0.0477655113833\n",
      "train loss:0.00166847305999\n",
      "train loss:0.00172444726026\n",
      "train loss:0.00256289892073\n",
      "train loss:0.000467586185834\n",
      "train loss:0.00827717761611\n",
      "train loss:0.000287486240293\n",
      "train loss:0.00108537164201\n",
      "train loss:0.00210760380811\n",
      "train loss:0.000588562823962\n",
      "train loss:0.0100574472591\n",
      "train loss:0.00225852155005\n",
      "train loss:0.00101681811913\n",
      "train loss:0.0013376150211\n",
      "train loss:0.0031633482223\n",
      "train loss:0.0047298842629\n",
      "train loss:0.00404572415142\n",
      "train loss:0.000458117318622\n",
      "train loss:0.00013690464081\n",
      "train loss:0.00185398720116\n",
      "train loss:0.00287141447232\n",
      "train loss:0.000871827567836\n",
      "train loss:0.000403206407015\n",
      "train loss:0.00388899813082\n",
      "train loss:0.00794347120324\n",
      "train loss:0.00170816794492\n",
      "train loss:0.000388218437032\n",
      "train loss:0.000796025862646\n",
      "train loss:0.00257298823005\n",
      "train loss:0.004504596748\n",
      "train loss:0.00352133174539\n",
      "train loss:0.00119415268503\n",
      "train loss:0.000132657992027\n",
      "train loss:0.00165886424615\n",
      "train loss:0.00091074555658\n",
      "train loss:0.00217737465858\n",
      "train loss:0.00203017169464\n",
      "train loss:0.00145088754081\n",
      "train loss:0.00155118417952\n",
      "train loss:0.000876663242576\n",
      "train loss:0.000434455753454\n",
      "train loss:9.80607750002e-05\n",
      "train loss:0.000120602685416\n",
      "train loss:0.000425357362407\n",
      "train loss:0.00129192180286\n",
      "train loss:0.000764777047531\n",
      "train loss:0.000719303726428\n",
      "train loss:0.0217922272863\n",
      "train loss:0.00128981166665\n",
      "train loss:0.00254902908733\n",
      "train loss:0.0180096645232\n",
      "train loss:0.000232311824384\n",
      "train loss:0.0033846467554\n",
      "train loss:0.00127346309934\n",
      "train loss:0.00298073126025\n",
      "train loss:0.0125064749716\n",
      "train loss:0.000974074693413\n",
      "train loss:0.0014324124841\n",
      "train loss:0.000219875319506\n",
      "train loss:0.00158083895675\n",
      "train loss:0.00050295323452\n",
      "train loss:0.00528858804771\n",
      "train loss:0.0037081570399\n",
      "train loss:0.00105662854119\n",
      "train loss:0.00290979985113\n",
      "train loss:0.000737135072013\n",
      "train loss:0.0012854343329\n",
      "train loss:0.000493670312207\n",
      "train loss:0.00975794756218\n",
      "train loss:0.0038034993129\n",
      "train loss:0.0015474975256\n",
      "train loss:0.00189517850579\n",
      "train loss:0.00508116054304\n",
      "train loss:0.00304302441427\n",
      "train loss:0.0257604313269\n",
      "train loss:0.000640820211144\n",
      "train loss:0.000950410076635\n",
      "train loss:0.0021803096827\n",
      "train loss:0.00175952636601\n",
      "train loss:0.00184551676254\n",
      "train loss:0.00544098394766\n",
      "train loss:0.0169858275453\n",
      "train loss:0.00510394208505\n",
      "train loss:0.0001300923548\n",
      "train loss:0.000276526169332\n",
      "train loss:0.00102462196451\n",
      "train loss:0.00838463737831\n",
      "train loss:0.000995375515248\n",
      "train loss:0.00331405861032\n",
      "train loss:0.000519110487166\n",
      "train loss:0.00529716890505\n",
      "train loss:0.017721712338\n",
      "train loss:0.003088288456\n",
      "train loss:0.00139463040816\n",
      "train loss:0.00111569393626\n",
      "train loss:0.00442795468414\n",
      "train loss:0.0071650636388\n",
      "train loss:0.000877597646523\n",
      "train loss:0.00036679818465\n",
      "train loss:0.00379355705248\n",
      "train loss:0.00326507568779\n",
      "train loss:0.000442533729242\n",
      "train loss:0.0059358891269\n",
      "train loss:0.00118170543059\n",
      "train loss:0.00827174937481\n",
      "train loss:0.00130034069614\n",
      "train loss:0.000897081959368\n",
      "train loss:0.00283771824492\n",
      "train loss:0.00111933033479\n",
      "train loss:0.000113141513053\n",
      "train loss:0.000712160277914\n",
      "train loss:0.00270024932175\n",
      "train loss:0.00453973981871\n",
      "train loss:0.00436335576613\n",
      "train loss:0.0010354500895\n",
      "train loss:0.00173676754491\n",
      "train loss:0.00169588701858\n",
      "train loss:0.00207310847015\n",
      "train loss:0.00156973088157\n",
      "train loss:0.00104577315524\n",
      "train loss:0.00528297258408\n",
      "train loss:0.000622082778586\n",
      "train loss:0.00121711205574\n",
      "train loss:0.00699715951595\n",
      "train loss:0.015244747858\n",
      "train loss:0.00120613426504\n",
      "train loss:0.00420369685199\n",
      "train loss:0.00022928699413\n",
      "train loss:0.00898597004607\n",
      "train loss:0.000517643252522\n",
      "train loss:0.00287956344936\n",
      "train loss:0.0126457985751\n",
      "train loss:0.00135700243277\n",
      "train loss:0.00576920249183\n",
      "train loss:0.0021552185526\n",
      "train loss:0.00149769042583\n",
      "train loss:0.000268702793849\n",
      "train loss:0.000551663861232\n",
      "train loss:0.000619820754849\n",
      "train loss:0.000217323657287\n",
      "train loss:0.000561351865948\n",
      "train loss:0.000306746823531\n",
      "train loss:0.00532825555921\n",
      "train loss:0.000627304100919\n",
      "train loss:0.00178090246255\n",
      "train loss:0.000337664067745\n",
      "train loss:0.00302243718802\n",
      "train loss:0.000139477666361\n",
      "train loss:0.00104788717939\n",
      "train loss:0.000291083299823\n",
      "train loss:0.0037151103861\n",
      "train loss:0.000128046876902\n",
      "train loss:0.000497608242357\n",
      "train loss:0.00219528619131\n",
      "train loss:0.00189328130554\n",
      "train loss:0.00239594878369\n",
      "train loss:0.000580636348773\n",
      "train loss:0.00212435262578\n",
      "train loss:0.00447809951095\n",
      "train loss:0.00985404772482\n",
      "train loss:0.00470126315798\n",
      "train loss:0.000575714528135\n",
      "train loss:0.00210817126705\n",
      "train loss:0.00409361243511\n",
      "train loss:0.00153080491992\n",
      "train loss:0.00103791049855\n",
      "train loss:0.00289600301978\n",
      "train loss:0.00149468291033\n",
      "train loss:0.00167056668047\n",
      "train loss:0.00208064732533\n",
      "train loss:0.00055735493356\n",
      "train loss:0.000296230765178\n",
      "train loss:0.0015195631126\n",
      "train loss:0.00181414018748\n",
      "train loss:0.000296314561814\n",
      "train loss:0.00114566924804\n",
      "train loss:0.00481397891473\n",
      "train loss:0.0049712387276\n",
      "train loss:0.000421047602696\n",
      "train loss:0.000562963609938\n",
      "train loss:0.00119636101127\n",
      "train loss:0.00246974723803\n",
      "train loss:0.000218705460142\n",
      "train loss:0.00123549661765\n",
      "train loss:7.43593498895e-05\n",
      "train loss:0.0183184682567\n",
      "train loss:0.00214071988438\n",
      "train loss:0.00230830301255\n",
      "train loss:0.00020586771673\n",
      "train loss:0.00831924510729\n",
      "train loss:0.000605583701169\n",
      "train loss:0.00242204991549\n",
      "train loss:2.43816145622e-05\n",
      "train loss:0.000279524913325\n",
      "train loss:0.00163423953409\n",
      "train loss:0.00244179952389\n",
      "train loss:0.00183435504577\n",
      "train loss:0.000393417942991\n",
      "train loss:0.000260966434943\n",
      "train loss:0.00322452048672\n",
      "train loss:0.00174552780634\n",
      "train loss:0.00046079604182\n",
      "train loss:0.00255505602037\n",
      "train loss:3.31706255193e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000822310333758\n",
      "train loss:0.00182839941232\n",
      "train loss:0.000329651573431\n",
      "train loss:0.010780510405\n",
      "train loss:0.00665846458214\n",
      "train loss:0.000154399742217\n",
      "train loss:0.00164243739956\n",
      "train loss:0.00632448788672\n",
      "train loss:0.00230114284916\n",
      "train loss:0.00101366362014\n",
      "train loss:0.00174269851462\n",
      "train loss:0.0026756899399\n",
      "train loss:0.00188740152859\n",
      "train loss:0.000459038132424\n",
      "train loss:0.00407453058577\n",
      "train loss:0.00148857461677\n",
      "train loss:0.0309405822122\n",
      "train loss:0.000353528612461\n",
      "train loss:0.0050729623868\n",
      "train loss:0.00146673114285\n",
      "train loss:0.00318255272378\n",
      "train loss:0.00321667414438\n",
      "train loss:0.00723374270783\n",
      "train loss:0.000429356164892\n",
      "train loss:0.000763986943179\n",
      "train loss:0.000519367709636\n",
      "train loss:0.0116576547449\n",
      "train loss:0.00514165916345\n",
      "train loss:0.00126085737689\n",
      "train loss:0.000442668457096\n",
      "train loss:0.000380438089686\n",
      "train loss:0.00427803559228\n",
      "train loss:0.00185755404966\n",
      "train loss:0.000110649044543\n",
      "train loss:0.00263492346169\n",
      "train loss:0.000376214058486\n",
      "train loss:0.000692770150244\n",
      "train loss:0.000183708558568\n",
      "train loss:0.000929933650359\n",
      "train loss:0.00133650553989\n",
      "train loss:0.000397652894585\n",
      "train loss:0.000195352399416\n",
      "train loss:0.000230243904104\n",
      "train loss:0.00226325314375\n",
      "train loss:0.000494513875105\n",
      "train loss:0.00282773472629\n",
      "train loss:0.0012980515192\n",
      "train loss:0.00290976728733\n",
      "train loss:0.000389688703959\n",
      "train loss:0.00116731288759\n",
      "train loss:0.000828389110246\n",
      "train loss:0.00104477849424\n",
      "train loss:0.00301318100438\n",
      "train loss:0.000661461993311\n",
      "train loss:0.00519939433666\n",
      "train loss:0.000174595077717\n",
      "train loss:0.000360435029553\n",
      "train loss:0.000830961153557\n",
      "train loss:0.00137827951676\n",
      "train loss:0.00132579762122\n",
      "train loss:0.0016316517097\n",
      "train loss:0.00575218192151\n",
      "train loss:0.000634985839035\n",
      "=== epoch:18, train acc:0.996, test acc:0.99 ===\n",
      "train loss:0.00208568585721\n",
      "train loss:0.000394017987168\n",
      "train loss:0.000955680144842\n",
      "train loss:0.00277971855828\n",
      "train loss:0.00236614243862\n",
      "train loss:0.00104479822475\n",
      "train loss:0.000106785157019\n",
      "train loss:0.00252231909704\n",
      "train loss:0.000356811782772\n",
      "train loss:0.000671730120213\n",
      "train loss:0.00160666574431\n",
      "train loss:0.00168911030052\n",
      "train loss:0.00164006182364\n",
      "train loss:0.005983787865\n",
      "train loss:0.00301269304069\n",
      "train loss:0.00172358699041\n",
      "train loss:0.00452706481881\n",
      "train loss:0.00140078244684\n",
      "train loss:4.29938847638e-05\n",
      "train loss:0.000572289184428\n",
      "train loss:0.00207027848593\n",
      "train loss:0.000662679064359\n",
      "train loss:0.000249978944032\n",
      "train loss:0.000302284172764\n",
      "train loss:0.00107369693746\n",
      "train loss:0.00204690787398\n",
      "train loss:0.00335332671319\n",
      "train loss:0.000651533690559\n",
      "train loss:0.000663959497375\n",
      "train loss:0.00354443810446\n",
      "train loss:0.00119797804042\n",
      "train loss:0.000317256703058\n",
      "train loss:0.000681092949971\n",
      "train loss:0.00270249502567\n",
      "train loss:0.000999022537546\n",
      "train loss:0.00531956175997\n",
      "train loss:0.00195767189079\n",
      "train loss:0.00667871110837\n",
      "train loss:0.00392291650112\n",
      "train loss:0.00166578246622\n",
      "train loss:0.000616583066451\n",
      "train loss:0.0005128224888\n",
      "train loss:0.000826469636985\n",
      "train loss:0.00101923466519\n",
      "train loss:0.00122538661381\n",
      "train loss:0.0012045570244\n",
      "train loss:0.000421827795108\n",
      "train loss:5.97749355053e-05\n",
      "train loss:0.00131956818777\n",
      "train loss:0.000202001027443\n",
      "train loss:0.000997012908261\n",
      "train loss:0.000377143570717\n",
      "train loss:0.000693939116046\n",
      "train loss:5.06407098891e-05\n",
      "train loss:0.000256909193888\n",
      "train loss:0.00189414434164\n",
      "train loss:0.000212372477757\n",
      "train loss:0.00560576055674\n",
      "train loss:8.05632623337e-05\n",
      "train loss:0.000499570292649\n",
      "train loss:0.00356645294761\n",
      "train loss:0.000566179241374\n",
      "train loss:0.00334002574456\n",
      "train loss:0.00194938677068\n",
      "train loss:0.000163298454625\n",
      "train loss:0.0025659412624\n",
      "train loss:0.00055270398464\n",
      "train loss:0.00101634200493\n",
      "train loss:0.0162530653617\n",
      "train loss:0.000922563494418\n",
      "train loss:0.0022308510143\n",
      "train loss:0.00041134511499\n",
      "train loss:0.000850491882314\n",
      "train loss:0.000296299438959\n",
      "train loss:0.000219080862299\n",
      "train loss:0.000622456960573\n",
      "train loss:7.10954444339e-05\n",
      "train loss:0.000393337991228\n",
      "train loss:0.00114489262281\n",
      "train loss:0.000658144644981\n",
      "train loss:0.00193869570251\n",
      "train loss:0.000337620970143\n",
      "train loss:0.00812523340815\n",
      "train loss:0.000294777395978\n",
      "train loss:0.000121719596975\n",
      "train loss:0.000630883192733\n",
      "train loss:0.0014540578817\n",
      "train loss:0.00335644000971\n",
      "train loss:6.87369511787e-05\n",
      "train loss:0.000147436192069\n",
      "train loss:0.0111971019328\n",
      "train loss:0.000412258292554\n",
      "train loss:0.00198991568369\n",
      "train loss:0.000117238415306\n",
      "train loss:0.000337662392677\n",
      "train loss:5.47662070696e-05\n",
      "train loss:0.000358201095787\n",
      "train loss:0.0052368976628\n",
      "train loss:0.000613961731442\n",
      "train loss:0.0019811130861\n",
      "train loss:0.00361426533725\n",
      "train loss:0.000209250399073\n",
      "train loss:0.00667021333242\n",
      "train loss:0.000290029889206\n",
      "train loss:0.000445948002884\n",
      "train loss:0.00207977323421\n",
      "train loss:0.00169938036434\n",
      "train loss:0.00212398090461\n",
      "train loss:0.0006495414541\n",
      "train loss:0.00146576396694\n",
      "train loss:0.00238022442412\n",
      "train loss:0.00251217157975\n",
      "train loss:0.000389652653134\n",
      "train loss:0.000185895243068\n",
      "train loss:0.000341927920413\n",
      "train loss:0.00067303255303\n",
      "train loss:0.00010302465406\n",
      "train loss:0.0112692721937\n",
      "train loss:0.00471644140613\n",
      "train loss:0.000736576994246\n",
      "train loss:0.00204880308719\n",
      "train loss:0.00213886172832\n",
      "train loss:0.00177135881408\n",
      "train loss:0.00477413557877\n",
      "train loss:0.000796525593078\n",
      "train loss:0.000152612878789\n",
      "train loss:0.00035765022376\n",
      "train loss:0.00127326017304\n",
      "train loss:0.000123256371907\n",
      "train loss:0.000451474426428\n",
      "train loss:0.000204471672106\n",
      "train loss:0.000770704856869\n",
      "train loss:0.000268145850262\n",
      "train loss:0.000100550560927\n",
      "train loss:0.00394454769047\n",
      "train loss:0.0042311155705\n",
      "train loss:6.65768546037e-05\n",
      "train loss:0.00442048200159\n",
      "train loss:0.0020125597557\n",
      "train loss:0.000202999072018\n",
      "train loss:0.00797402534464\n",
      "train loss:7.65967643221e-05\n",
      "train loss:0.00031794912914\n",
      "train loss:0.000542164128896\n",
      "train loss:0.003097504905\n",
      "train loss:0.00318117584534\n",
      "train loss:0.00120424425012\n",
      "train loss:0.00107201242529\n",
      "train loss:0.000155937479345\n",
      "train loss:0.000788524330358\n",
      "train loss:0.00161086797048\n",
      "train loss:0.00184821022482\n",
      "train loss:0.003062109302\n",
      "train loss:0.000922980047852\n",
      "train loss:0.000863076524897\n",
      "train loss:0.00149265718499\n",
      "train loss:0.00307129768526\n",
      "train loss:4.20123297696e-05\n",
      "train loss:0.00022847968748\n",
      "train loss:0.00521166187533\n",
      "train loss:0.000301273380855\n",
      "train loss:0.000340509721005\n",
      "train loss:0.0171959983912\n",
      "train loss:0.000642563581672\n",
      "train loss:0.00959935598014\n",
      "train loss:0.00126574805479\n",
      "train loss:0.000294304588242\n",
      "train loss:3.71194167488e-05\n",
      "train loss:0.000375339323165\n",
      "train loss:0.00198576976971\n",
      "train loss:0.00338716749079\n",
      "train loss:0.000152685609496\n",
      "train loss:0.000103125961675\n",
      "train loss:0.00334524796268\n",
      "train loss:0.00144226917509\n",
      "train loss:0.00938861176115\n",
      "train loss:0.00178935871518\n",
      "train loss:0.0016199231816\n",
      "train loss:0.000565842875939\n",
      "train loss:0.000646304571608\n",
      "train loss:0.000331827653668\n",
      "train loss:0.00805532554118\n",
      "train loss:0.00594923620046\n",
      "train loss:2.3694689948e-05\n",
      "train loss:0.000189867840579\n",
      "train loss:0.00017698917328\n",
      "train loss:0.00097982777904\n",
      "train loss:0.000261509721971\n",
      "train loss:0.0011729725221\n",
      "train loss:0.000282458094385\n",
      "train loss:0.000221485275038\n",
      "train loss:0.000272245644234\n",
      "train loss:0.000205183135714\n",
      "train loss:0.000451229814792\n",
      "train loss:0.000191287453525\n",
      "train loss:0.000127866916445\n",
      "train loss:0.000167060190188\n",
      "train loss:0.00224638253632\n",
      "train loss:0.000219709555302\n",
      "train loss:0.000793656685224\n",
      "train loss:0.00102631004015\n",
      "train loss:0.00504061263898\n",
      "train loss:0.00276219072002\n",
      "train loss:0.00144778769557\n",
      "train loss:3.83867332253e-05\n",
      "train loss:0.00589201277801\n",
      "train loss:0.00338336992834\n",
      "train loss:0.00357869760672\n",
      "train loss:0.000442514266577\n",
      "train loss:0.00236681223524\n",
      "train loss:0.000201994801556\n",
      "train loss:0.00826500596207\n",
      "train loss:0.000555180517776\n",
      "train loss:0.00251197419434\n",
      "train loss:0.00201447076652\n",
      "train loss:0.00128949918111\n",
      "train loss:0.000300458809211\n",
      "train loss:7.84455251129e-05\n",
      "train loss:0.000241669129658\n",
      "train loss:0.000503780593506\n",
      "train loss:0.00054147089457\n",
      "train loss:0.000200616840017\n",
      "train loss:0.000211643103221\n",
      "train loss:0.000127876920363\n",
      "train loss:0.00012374283487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0017666862537\n",
      "train loss:0.000365555378518\n",
      "train loss:0.000465187714375\n",
      "train loss:0.000265669974512\n",
      "train loss:0.00303029204178\n",
      "train loss:0.000943739233809\n",
      "train loss:0.00023782299974\n",
      "train loss:0.00114581485659\n",
      "train loss:0.00353559818152\n",
      "train loss:0.000165674958285\n",
      "train loss:0.0013359615838\n",
      "train loss:0.00118321827214\n",
      "train loss:0.000138749939026\n",
      "train loss:0.000266357627698\n",
      "train loss:0.00201148782835\n",
      "train loss:0.000414474416773\n",
      "train loss:0.000412761184057\n",
      "train loss:0.000819995464367\n",
      "train loss:0.00693155124537\n",
      "train loss:3.17538701768e-05\n",
      "train loss:0.000652090080721\n",
      "train loss:0.00157880201901\n",
      "train loss:0.00268861012445\n",
      "train loss:0.000681766117014\n",
      "train loss:0.000922914344731\n",
      "train loss:0.0011101899474\n",
      "train loss:0.0244626543338\n",
      "train loss:0.000808954682263\n",
      "train loss:0.00417671295519\n",
      "train loss:0.000840809902415\n",
      "train loss:6.99484108329e-05\n",
      "train loss:0.00318474055787\n",
      "train loss:0.0731627770054\n",
      "train loss:0.000472547054912\n",
      "train loss:0.000184009143639\n",
      "train loss:0.000217290017477\n",
      "train loss:0.00128914229571\n",
      "train loss:0.00123157823568\n",
      "train loss:0.000228962429888\n",
      "train loss:0.000123419608687\n",
      "train loss:0.000361529390957\n",
      "train loss:0.000482789613649\n",
      "train loss:0.00170563197468\n",
      "train loss:0.000868103815708\n",
      "train loss:0.000337836596523\n",
      "train loss:0.00242369411761\n",
      "train loss:0.000225500749471\n",
      "train loss:0.000369466494819\n",
      "train loss:0.00189553527837\n",
      "train loss:0.000408925692038\n",
      "train loss:0.000173387565955\n",
      "train loss:0.000911567653717\n",
      "train loss:0.000607505749222\n",
      "train loss:0.000305032220559\n",
      "train loss:0.000628602881576\n",
      "train loss:0.000841773153401\n",
      "train loss:0.00219298534202\n",
      "train loss:0.000433453853758\n",
      "train loss:0.00787555527425\n",
      "train loss:0.00212417671134\n",
      "train loss:0.00276175260268\n",
      "train loss:0.00131940896158\n",
      "train loss:0.00011290747241\n",
      "train loss:0.000352629522161\n",
      "train loss:0.00013857853536\n",
      "train loss:0.000630123595786\n",
      "train loss:2.12331206761e-05\n",
      "train loss:0.000921296774833\n",
      "train loss:0.00140948720276\n",
      "train loss:0.00041178499844\n",
      "train loss:0.000317518375666\n",
      "train loss:0.0118139495427\n",
      "train loss:0.000140178979639\n",
      "train loss:0.00360330370977\n",
      "train loss:0.000917657910503\n",
      "train loss:0.00785173274094\n",
      "train loss:4.30530791983e-05\n",
      "train loss:0.000407855040092\n",
      "train loss:0.00606679187139\n",
      "train loss:0.000542357360325\n",
      "train loss:0.00111211191489\n",
      "train loss:0.000521316119512\n",
      "train loss:0.00205973560106\n",
      "train loss:0.000787287907785\n",
      "train loss:0.00170995506298\n",
      "train loss:0.00118253307342\n",
      "train loss:0.000521076024125\n",
      "train loss:0.0021993478793\n",
      "train loss:0.000998394225823\n",
      "train loss:0.00365540100556\n",
      "train loss:0.00129550758049\n",
      "train loss:0.000212364982235\n",
      "train loss:0.00259487767157\n",
      "train loss:0.00241138468077\n",
      "train loss:0.000311184846462\n",
      "train loss:0.000605487951935\n",
      "train loss:0.000135457144726\n",
      "train loss:0.000574768696913\n",
      "train loss:0.00324624697671\n",
      "train loss:0.00523457115495\n",
      "train loss:0.00194535902855\n",
      "train loss:0.000393110697836\n",
      "train loss:0.00237908486269\n",
      "train loss:0.00131416118523\n",
      "train loss:0.00118320206804\n",
      "train loss:0.000335147644781\n",
      "train loss:0.00489919866635\n",
      "train loss:0.000732491328183\n",
      "train loss:0.000257906775315\n",
      "train loss:0.000178193581438\n",
      "train loss:0.00012059953761\n",
      "train loss:0.000569987742754\n",
      "train loss:0.000701673319507\n",
      "train loss:0.000801720516513\n",
      "train loss:0.000312226387087\n",
      "train loss:0.0003306453589\n",
      "train loss:0.00332604481948\n",
      "train loss:0.000357529044373\n",
      "train loss:0.00277189285161\n",
      "train loss:0.00156086188833\n",
      "train loss:0.00121980467599\n",
      "train loss:0.0015927807378\n",
      "train loss:0.000500477648786\n",
      "train loss:0.000734562828619\n",
      "train loss:0.00038149831526\n",
      "train loss:3.87461963067e-05\n",
      "train loss:0.00375195768449\n",
      "train loss:0.000706535728566\n",
      "train loss:0.000157322723185\n",
      "train loss:0.0020972992272\n",
      "train loss:0.00310368017577\n",
      "train loss:0.000904857070975\n",
      "train loss:0.000133008837906\n",
      "train loss:0.00180978532657\n",
      "train loss:0.00184017548495\n",
      "train loss:0.00106948866007\n",
      "train loss:0.000897454573513\n",
      "train loss:0.000239381336945\n",
      "train loss:0.000446975519927\n",
      "train loss:0.00231135099778\n",
      "train loss:0.000176749338201\n",
      "train loss:0.00107026972529\n",
      "train loss:0.00405805914212\n",
      "train loss:0.000209226493336\n",
      "train loss:0.00318441103463\n",
      "train loss:0.000775051025811\n",
      "train loss:0.00208286863049\n",
      "train loss:0.00169794154104\n",
      "train loss:0.00148287371227\n",
      "train loss:0.000313635494701\n",
      "train loss:0.00019387371499\n",
      "train loss:0.000465577355878\n",
      "train loss:0.000831399157947\n",
      "train loss:0.000491958911259\n",
      "train loss:0.000114593982986\n",
      "train loss:0.0014569591329\n",
      "train loss:0.000143483926785\n",
      "train loss:0.000504657949853\n",
      "train loss:0.00043069578924\n",
      "train loss:0.00176625567548\n",
      "train loss:0.00121084313872\n",
      "train loss:0.00236048238039\n",
      "train loss:0.000307383168458\n",
      "train loss:0.00344799995063\n",
      "train loss:7.58974800676e-05\n",
      "train loss:0.000267182254507\n",
      "train loss:0.00205250675657\n",
      "train loss:0.00339380628816\n",
      "train loss:0.00110844774268\n",
      "train loss:0.00211513581619\n",
      "train loss:0.000204175376633\n",
      "train loss:0.000157405380408\n",
      "train loss:0.00226906142438\n",
      "train loss:0.00578975267177\n",
      "train loss:0.0133403064912\n",
      "train loss:0.002430296843\n",
      "train loss:0.000610196686755\n",
      "train loss:0.00105023106667\n",
      "train loss:0.00336462784064\n",
      "train loss:0.000150767006765\n",
      "train loss:0.000194070705211\n",
      "train loss:0.000717479778652\n",
      "train loss:0.00391351813339\n",
      "train loss:0.00235194314724\n",
      "train loss:0.000382848728748\n",
      "train loss:0.00129634405757\n",
      "train loss:0.00188094339394\n",
      "train loss:7.45595041965e-05\n",
      "train loss:0.000315005579401\n",
      "train loss:0.000241990510756\n",
      "train loss:0.00178517207411\n",
      "train loss:0.011864980218\n",
      "train loss:0.00171255315497\n",
      "train loss:0.00178266704984\n",
      "train loss:0.000875098203834\n",
      "train loss:0.00190145567866\n",
      "train loss:0.00458592052432\n",
      "train loss:0.00271057863175\n",
      "train loss:0.00130258941003\n",
      "train loss:0.0122207931371\n",
      "train loss:0.000912051585125\n",
      "train loss:0.000167378247849\n",
      "train loss:0.00109359910014\n",
      "train loss:0.000150143055119\n",
      "train loss:0.00169262194448\n",
      "train loss:0.00167256209907\n",
      "train loss:0.00245391941423\n",
      "train loss:0.0015788605528\n",
      "train loss:0.000222756116815\n",
      "train loss:0.00147172293796\n",
      "train loss:0.000297259957723\n",
      "train loss:0.0623049592498\n",
      "train loss:0.00247459922077\n",
      "train loss:0.000433470080169\n",
      "train loss:0.00177336758388\n",
      "train loss:0.00193846710949\n",
      "train loss:0.00168223159054\n",
      "train loss:0.00159219507503\n",
      "train loss:0.000526869354411\n",
      "train loss:0.00389284535154\n",
      "train loss:0.00214097691752\n",
      "train loss:0.000136465565524\n",
      "train loss:0.000183382043042\n",
      "train loss:0.00252935639472\n",
      "train loss:0.00039360286262\n",
      "train loss:0.00158802320626\n",
      "train loss:0.000344838683409\n",
      "train loss:0.00574040846738\n",
      "train loss:0.000277547441593\n",
      "train loss:0.000555099787402\n",
      "train loss:0.00239869677932\n",
      "train loss:0.0010572295004\n",
      "train loss:0.00448266592883\n",
      "train loss:0.000357316284879\n",
      "train loss:9.54358478542e-05\n",
      "train loss:0.00188168461514\n",
      "train loss:0.0019252017487\n",
      "train loss:0.000350990968799\n",
      "train loss:0.000178638406728\n",
      "train loss:0.00117549580797\n",
      "train loss:0.000765386355625\n",
      "train loss:0.000560774437486\n",
      "train loss:0.00585487224916\n",
      "train loss:0.000930456195731\n",
      "train loss:0.00512646716305\n",
      "train loss:0.00118131964761\n",
      "train loss:0.00125750346851\n",
      "train loss:0.00678381664523\n",
      "train loss:0.0096804997021\n",
      "train loss:0.000414848008811\n",
      "train loss:0.000150530257569\n",
      "train loss:0.00314423105054\n",
      "train loss:0.00284442028679\n",
      "train loss:0.00377263261588\n",
      "train loss:0.000562831052327\n",
      "train loss:0.00194821206017\n",
      "train loss:0.000860382366523\n",
      "train loss:0.00158691644215\n",
      "train loss:0.00225672249875\n",
      "train loss:0.0136929902286\n",
      "train loss:0.000292190731359\n",
      "train loss:0.000646541220905\n",
      "train loss:0.00120048616951\n",
      "train loss:0.00169786321214\n",
      "train loss:0.00098396051563\n",
      "train loss:0.000380362331008\n",
      "train loss:0.000762020930558\n",
      "train loss:8.16144688955e-05\n",
      "train loss:0.000640911670904\n",
      "train loss:0.00151357892464\n",
      "train loss:0.000130309842197\n",
      "train loss:0.00200055855379\n",
      "train loss:0.000144162030261\n",
      "train loss:0.000599216700777\n",
      "train loss:0.00018450664203\n",
      "train loss:9.87570065028e-05\n",
      "train loss:0.000186058844818\n",
      "train loss:0.000218366909962\n",
      "train loss:0.00148855759062\n",
      "train loss:0.000992719805622\n",
      "train loss:0.000242183651767\n",
      "train loss:0.000319087297319\n",
      "train loss:0.0127354872614\n",
      "train loss:4.44779046945e-05\n",
      "train loss:0.000299216808687\n",
      "train loss:0.000853818678374\n",
      "train loss:0.000358936397824\n",
      "train loss:9.53130254998e-05\n",
      "train loss:0.000772948165363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000126711764384\n",
      "train loss:0.00310730518634\n",
      "train loss:0.00130181014133\n",
      "train loss:0.000435376611512\n",
      "train loss:0.000497436342086\n",
      "train loss:0.000822458698994\n",
      "train loss:9.05437500043e-05\n",
      "train loss:0.00184816844978\n",
      "train loss:1.88024584922e-05\n",
      "train loss:0.00010433689095\n",
      "train loss:0.000142953995805\n",
      "train loss:0.0130178636599\n",
      "train loss:4.61889563683e-05\n",
      "train loss:0.000722003255153\n",
      "train loss:0.000739820967428\n",
      "train loss:0.000301848379138\n",
      "train loss:0.00216147571054\n",
      "train loss:0.000749704694066\n",
      "train loss:0.000323739580469\n",
      "train loss:0.00409492227773\n",
      "train loss:0.00179280190875\n",
      "train loss:0.000590330925864\n",
      "train loss:0.000207160050488\n",
      "train loss:0.00248826599815\n",
      "train loss:0.000394045583893\n",
      "train loss:0.000107468437925\n",
      "train loss:0.00146980257004\n",
      "train loss:0.000852393492298\n",
      "train loss:0.00311842540861\n",
      "train loss:0.000131188775683\n",
      "train loss:0.00140371291359\n",
      "train loss:0.00126531404658\n",
      "train loss:0.00228084512226\n",
      "train loss:0.00119085048472\n",
      "train loss:0.001946992543\n",
      "train loss:0.00167234324951\n",
      "train loss:0.00904875920384\n",
      "train loss:0.00312309371504\n",
      "train loss:0.00139561197114\n",
      "train loss:0.00301076643322\n",
      "train loss:0.00145104258373\n",
      "train loss:0.00336134964906\n",
      "train loss:0.000511170089738\n",
      "train loss:0.000417537756972\n",
      "train loss:3.1999423105e-05\n",
      "train loss:0.000189610537346\n",
      "train loss:0.000577176040203\n",
      "train loss:0.00177562496852\n",
      "train loss:0.000299926681235\n",
      "train loss:0.00223827137605\n",
      "train loss:0.00340354704274\n",
      "train loss:0.000588027037834\n",
      "train loss:0.00196700893981\n",
      "train loss:0.00364856886662\n",
      "train loss:0.00172292964314\n",
      "train loss:0.00116355209067\n",
      "train loss:0.000325273753237\n",
      "train loss:0.000819751579829\n",
      "train loss:0.000908404650872\n",
      "train loss:0.00102397897711\n",
      "train loss:0.000310277026278\n",
      "train loss:0.000156528796493\n",
      "train loss:4.46270334588e-05\n",
      "train loss:0.000379385085731\n",
      "train loss:1.98092672409e-05\n",
      "train loss:0.000678203542856\n",
      "train loss:0.000210508472203\n",
      "train loss:0.000351756030407\n",
      "train loss:0.00192488051828\n",
      "train loss:0.000417757331369\n",
      "train loss:0.000552645111816\n",
      "train loss:0.000564816229046\n",
      "train loss:2.25240400058e-05\n",
      "train loss:0.00051106532612\n",
      "train loss:0.000170003671218\n",
      "train loss:0.000422608599355\n",
      "train loss:0.000419198041835\n",
      "train loss:0.000194363764463\n",
      "train loss:0.00017818069272\n",
      "train loss:0.000198939985634\n",
      "train loss:0.000515855425854\n",
      "train loss:0.000204422733656\n",
      "train loss:5.41857691498e-05\n",
      "train loss:0.000110517766981\n",
      "train loss:0.000489238500052\n",
      "train loss:0.000471026711718\n",
      "=== epoch:19, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.00144265858835\n",
      "train loss:0.000175834334929\n",
      "train loss:0.000258063736828\n",
      "train loss:0.000450293327124\n",
      "train loss:2.60644802607e-05\n",
      "train loss:0.00135947624317\n",
      "train loss:0.00217574010368\n",
      "train loss:0.00147689656524\n",
      "train loss:0.00104752050114\n",
      "train loss:0.00327209003791\n",
      "train loss:1.49007042178e-05\n",
      "train loss:3.12578282451e-05\n",
      "train loss:2.20940527375e-05\n",
      "train loss:0.00129564563277\n",
      "train loss:3.78262191892e-05\n",
      "train loss:0.000461100004385\n",
      "train loss:0.000292958488472\n",
      "train loss:0.00243526540504\n",
      "train loss:0.00100066691172\n",
      "train loss:0.00154282817886\n",
      "train loss:0.000336104295692\n",
      "train loss:6.86489801874e-05\n",
      "train loss:0.000189883545058\n",
      "train loss:0.000644437917635\n",
      "train loss:0.000114880225802\n",
      "train loss:0.000332770173714\n",
      "train loss:0.000387481855243\n",
      "train loss:0.00176625598075\n",
      "train loss:0.0057180528176\n",
      "train loss:9.06129477573e-05\n",
      "train loss:5.9285210089e-05\n",
      "train loss:0.000205134556586\n",
      "train loss:0.000803692857316\n",
      "train loss:0.000606827777947\n",
      "train loss:0.000377266840294\n",
      "train loss:0.000848852886431\n",
      "train loss:0.00191369162773\n",
      "train loss:6.6717539579e-06\n",
      "train loss:0.000224288536595\n",
      "train loss:0.000875842248897\n",
      "train loss:0.000100485728119\n",
      "train loss:0.00042928179943\n",
      "train loss:0.000261793344937\n",
      "train loss:0.000595143226021\n",
      "train loss:0.000402153181739\n",
      "train loss:0.0137735877213\n",
      "train loss:0.000350962669691\n",
      "train loss:0.000327507207044\n",
      "train loss:0.000769071050301\n",
      "train loss:0.00141328468948\n",
      "train loss:0.000167904837084\n",
      "train loss:0.000376173435883\n",
      "train loss:0.00299645951799\n",
      "train loss:0.00191016593234\n",
      "train loss:0.000857373548905\n",
      "train loss:0.00445458633001\n",
      "train loss:0.00129791655676\n",
      "train loss:0.00240041550072\n",
      "train loss:0.000228780423466\n",
      "train loss:0.000263728232801\n",
      "train loss:0.00176522649073\n",
      "train loss:7.02469684343e-05\n",
      "train loss:0.000823236039789\n",
      "train loss:0.000116280901077\n",
      "train loss:0.00033479055574\n",
      "train loss:0.00142748459672\n",
      "train loss:0.00332409849866\n",
      "train loss:0.00235550515642\n",
      "train loss:0.000456958522383\n",
      "train loss:0.000145221937158\n",
      "train loss:0.000189036784953\n",
      "train loss:0.00421736908287\n",
      "train loss:0.000907143915308\n",
      "train loss:0.000222242938313\n",
      "train loss:0.000598929235342\n",
      "train loss:0.024816562045\n",
      "train loss:0.00103591221114\n",
      "train loss:0.00152145995145\n",
      "train loss:0.00271951573697\n",
      "train loss:0.000616438123713\n",
      "train loss:0.000394917165393\n",
      "train loss:0.00164533853841\n",
      "train loss:0.000620671171628\n",
      "train loss:0.00204202440237\n",
      "train loss:0.00019447254806\n",
      "train loss:0.00235094758311\n",
      "train loss:0.000240051868174\n",
      "train loss:0.00146124694524\n",
      "train loss:0.00017341320046\n",
      "train loss:0.00289570584578\n",
      "train loss:0.00558635019036\n",
      "train loss:0.000284658256124\n",
      "train loss:6.77759372409e-05\n",
      "train loss:0.000521083794456\n",
      "train loss:6.15278439397e-05\n",
      "train loss:0.00233038752236\n",
      "train loss:4.61138675711e-05\n",
      "train loss:0.000186457855075\n",
      "train loss:0.000851917920505\n",
      "train loss:0.000103948158263\n",
      "train loss:0.000111260012861\n",
      "train loss:0.000591426204847\n",
      "train loss:0.000449717466004\n",
      "train loss:0.000146757277881\n",
      "train loss:0.000806280609326\n",
      "train loss:0.00176771728638\n",
      "train loss:0.000796451944852\n",
      "train loss:0.00273794395668\n",
      "train loss:0.0033239219749\n",
      "train loss:0.00100192611487\n",
      "train loss:0.00422149762682\n",
      "train loss:0.00181607667005\n",
      "train loss:0.000301401068689\n",
      "train loss:0.0202666114921\n",
      "train loss:0.00254585643959\n",
      "train loss:0.000183079451275\n",
      "train loss:0.00487912212996\n",
      "train loss:0.000134175432466\n",
      "train loss:0.00337704089279\n",
      "train loss:0.000732674601287\n",
      "train loss:0.00421846257088\n",
      "train loss:3.59350671392e-05\n",
      "train loss:0.000944278509665\n",
      "train loss:0.00163379664229\n",
      "train loss:0.00139268319986\n",
      "train loss:0.000306985800097\n",
      "train loss:0.000606193477914\n",
      "train loss:9.66695558212e-05\n",
      "train loss:0.0119541323607\n",
      "train loss:0.000223501861591\n",
      "train loss:0.00256993467163\n",
      "train loss:0.00132669143977\n",
      "train loss:0.000795437264247\n",
      "train loss:0.000637586930146\n",
      "train loss:0.00184498599615\n",
      "train loss:0.010803148934\n",
      "train loss:0.000733173367737\n",
      "train loss:0.000895784883561\n",
      "train loss:0.00106829013567\n",
      "train loss:0.000140085904772\n",
      "train loss:0.00107001468645\n",
      "train loss:0.00348003712157\n",
      "train loss:0.000343280368643\n",
      "train loss:0.000480102789478\n",
      "train loss:0.000206114973843\n",
      "train loss:0.000736829028471\n",
      "train loss:0.000801175140176\n",
      "train loss:0.000385022234772\n",
      "train loss:6.89972214147e-05\n",
      "train loss:0.00202853102893\n",
      "train loss:0.000219833190282\n",
      "train loss:0.000256085427425\n",
      "train loss:8.55633532216e-05\n",
      "train loss:0.00514480621949\n",
      "train loss:0.000320598038723\n",
      "train loss:0.000171119234058\n",
      "train loss:0.00450051547883\n",
      "train loss:0.00512869595068\n",
      "train loss:0.000163352991071\n",
      "train loss:0.000555024611554\n",
      "train loss:0.000325353817476\n",
      "train loss:0.00740966656788\n",
      "train loss:0.00197687490872\n",
      "train loss:0.000196431145034\n",
      "train loss:0.00196115726755\n",
      "train loss:0.00162734380185\n",
      "train loss:0.00266290682713\n",
      "train loss:0.00461447795231\n",
      "train loss:0.0019435301533\n",
      "train loss:5.32288889025e-05\n",
      "train loss:0.000855615931663\n",
      "train loss:6.47389887953e-05\n",
      "train loss:0.000747932954722\n",
      "train loss:0.00313153968841\n",
      "train loss:0.00190488993925\n",
      "train loss:0.00110334501091\n",
      "train loss:0.00144842606482\n",
      "train loss:0.000779408224697\n",
      "train loss:0.00147229809371\n",
      "train loss:7.11789166174e-05\n",
      "train loss:0.00169077128543\n",
      "train loss:0.000691463278879\n",
      "train loss:0.000421468895137\n",
      "train loss:0.00222968858944\n",
      "train loss:0.000584688005236\n",
      "train loss:0.0291080430232\n",
      "train loss:0.000262780691987\n",
      "train loss:0.00113352846419\n",
      "train loss:0.000672680421477\n",
      "train loss:4.72840673131e-05\n",
      "train loss:0.00286398427754\n",
      "train loss:0.00124584317292\n",
      "train loss:0.00178513738459\n",
      "train loss:0.00335743944576\n",
      "train loss:0.00155183063028\n",
      "train loss:0.000712157083066\n",
      "train loss:9.02977007985e-05\n",
      "train loss:0.000199545856799\n",
      "train loss:0.00233888221996\n",
      "train loss:0.0068964305183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000649563564819\n",
      "train loss:0.000686328632239\n",
      "train loss:0.000476418872709\n",
      "train loss:0.00113691585795\n",
      "train loss:0.000978995048031\n",
      "train loss:0.000424052339988\n",
      "train loss:0.000453661941731\n",
      "train loss:0.000135433665132\n",
      "train loss:0.00211800903881\n",
      "train loss:0.000149663302632\n",
      "train loss:0.000794775854204\n",
      "train loss:0.0102851567575\n",
      "train loss:0.000626402228584\n",
      "train loss:0.0102540345638\n",
      "train loss:0.000748648018776\n",
      "train loss:0.00121412450415\n",
      "train loss:0.00134720297384\n",
      "train loss:0.000213584264092\n",
      "train loss:0.000925283179509\n",
      "train loss:0.000523808556648\n",
      "train loss:0.000685490783052\n",
      "train loss:0.000369240150611\n",
      "train loss:0.00636202277915\n",
      "train loss:0.00116784008911\n",
      "train loss:0.000835662676105\n",
      "train loss:7.67300454368e-05\n",
      "train loss:0.00440415234061\n",
      "train loss:0.00183062893216\n",
      "train loss:0.00025067427559\n",
      "train loss:0.00158735492265\n",
      "train loss:0.00537968471527\n",
      "train loss:0.000655889633181\n",
      "train loss:0.0238871226109\n",
      "train loss:0.000399911099912\n",
      "train loss:0.000422265435746\n",
      "train loss:0.00100658409128\n",
      "train loss:0.00163414180018\n",
      "train loss:0.000136424114751\n",
      "train loss:0.000400175183466\n",
      "train loss:0.000816710853031\n",
      "train loss:0.00108765192485\n",
      "train loss:0.000499234697305\n",
      "train loss:0.00107991988472\n",
      "train loss:0.000121377470527\n",
      "train loss:0.000256711782423\n",
      "train loss:0.0022464830599\n",
      "train loss:0.000444784388067\n",
      "train loss:0.00408880009837\n",
      "train loss:0.0022437304003\n",
      "train loss:0.00123280777367\n",
      "train loss:0.00065102175839\n",
      "train loss:0.00274059156332\n",
      "train loss:0.000418781790194\n",
      "train loss:0.000163140733044\n",
      "train loss:0.000405958593532\n",
      "train loss:3.00295930848e-05\n",
      "train loss:0.00292173845847\n",
      "train loss:3.50873347903e-05\n",
      "train loss:0.000317762310496\n",
      "train loss:0.000886501039455\n",
      "train loss:0.0011913176954\n",
      "train loss:0.000172122614607\n",
      "train loss:0.0054053667898\n",
      "train loss:0.00507770377628\n",
      "train loss:0.000948667463603\n",
      "train loss:0.000480095341084\n",
      "train loss:0.000318068287308\n",
      "train loss:0.000347375399195\n",
      "train loss:0.000876768019229\n",
      "train loss:8.05118080496e-05\n",
      "train loss:0.000962505871326\n",
      "train loss:0.000266468734404\n",
      "train loss:0.00168136252897\n",
      "train loss:0.00589785819088\n",
      "train loss:0.00189949727289\n",
      "train loss:0.00196167438702\n",
      "train loss:0.00154051088568\n",
      "train loss:0.000402307011026\n",
      "train loss:0.000203497075182\n",
      "train loss:0.00110886041123\n",
      "train loss:0.000173560413985\n",
      "train loss:0.000797100081734\n",
      "train loss:0.000287076076174\n",
      "train loss:0.00140990608648\n",
      "train loss:0.00489425967093\n",
      "train loss:0.00173062062645\n",
      "train loss:5.48982566284e-05\n",
      "train loss:0.00339613243973\n",
      "train loss:0.000121195997854\n",
      "train loss:0.00143549018578\n",
      "train loss:0.00126523771776\n",
      "train loss:0.00309908489326\n",
      "train loss:0.00627088085639\n",
      "train loss:0.000117167478637\n",
      "train loss:0.00109566350748\n",
      "train loss:0.000266460321312\n",
      "train loss:0.000898874013298\n",
      "train loss:0.000219072032383\n",
      "train loss:0.000597998036971\n",
      "train loss:0.00166211644711\n",
      "train loss:0.000209714612523\n",
      "train loss:0.00261962430918\n",
      "train loss:1.88336191617e-05\n",
      "train loss:0.000125726763135\n",
      "train loss:0.000412664688148\n",
      "train loss:0.000137641592452\n",
      "train loss:0.00251859014366\n",
      "train loss:0.000468069646925\n",
      "train loss:0.00183884038276\n",
      "train loss:0.00183972256435\n",
      "train loss:0.000122625874915\n",
      "train loss:0.000493955635367\n",
      "train loss:0.00112484051602\n",
      "train loss:0.00248949564298\n",
      "train loss:0.00247056256348\n",
      "train loss:6.74506920602e-05\n",
      "train loss:0.0078687813217\n",
      "train loss:0.000303549158699\n",
      "train loss:0.000100402378727\n",
      "train loss:0.00360185931408\n",
      "train loss:0.00339051645263\n",
      "train loss:0.00143764461574\n",
      "train loss:0.000144774444013\n",
      "train loss:0.000265432554216\n",
      "train loss:0.000407107215969\n",
      "train loss:0.0110524995124\n",
      "train loss:0.0014489894537\n",
      "train loss:6.58812860209e-05\n",
      "train loss:0.000778349446622\n",
      "train loss:0.000205128030006\n",
      "train loss:8.55117098663e-05\n",
      "train loss:0.000297102187502\n",
      "train loss:0.0003703307607\n",
      "train loss:0.00123643434068\n",
      "train loss:3.54991382633e-05\n",
      "train loss:9.27709363542e-05\n",
      "train loss:0.000677617952318\n",
      "train loss:0.000791436538307\n",
      "train loss:0.00611343821927\n",
      "train loss:0.00125490059406\n",
      "train loss:3.93380325424e-05\n",
      "train loss:0.000174374118996\n",
      "train loss:0.000927180719644\n",
      "train loss:0.00113645644645\n",
      "train loss:0.00122919855121\n",
      "train loss:0.000233044947543\n",
      "train loss:7.09075768131e-05\n",
      "train loss:0.000226976326542\n",
      "train loss:0.00109295071164\n",
      "train loss:0.00215142567697\n",
      "train loss:0.00283049150805\n",
      "train loss:0.00129684323312\n",
      "train loss:0.000205100384807\n",
      "train loss:0.00155842016408\n",
      "train loss:5.7290084358e-05\n",
      "train loss:0.000107833295216\n",
      "train loss:0.00311529056829\n",
      "train loss:0.00015783980593\n",
      "train loss:0.000151050819951\n",
      "train loss:7.36791238242e-05\n",
      "train loss:0.000112062399381\n",
      "train loss:0.00150456345584\n",
      "train loss:0.000866561769687\n",
      "train loss:0.00434220720968\n",
      "train loss:0.000329948238473\n",
      "train loss:0.000235458730234\n",
      "train loss:0.00155857755422\n",
      "train loss:0.00037477349481\n",
      "train loss:9.37181466735e-05\n",
      "train loss:0.00428885411164\n",
      "train loss:0.000837194470129\n",
      "train loss:0.000210175492233\n",
      "train loss:0.000124274928414\n",
      "train loss:0.000963093916314\n",
      "train loss:8.06775848632e-05\n",
      "train loss:0.00597952078349\n",
      "train loss:0.000241978690701\n",
      "train loss:0.000925842447255\n",
      "train loss:0.00096162069885\n",
      "train loss:0.000822015440524\n",
      "train loss:0.00159043737402\n",
      "train loss:0.00433729023491\n",
      "train loss:5.67021197396e-05\n",
      "train loss:0.000719033777338\n",
      "train loss:0.000107671501607\n",
      "train loss:0.000386927544618\n",
      "train loss:4.09465648345e-05\n",
      "train loss:0.000827251531409\n",
      "train loss:0.00423611054332\n",
      "train loss:0.000647637852776\n",
      "train loss:0.000115620599945\n",
      "train loss:0.00254174469506\n",
      "train loss:0.000225293390355\n",
      "train loss:0.000124469337608\n",
      "train loss:6.89024897701e-05\n",
      "train loss:0.00100105977135\n",
      "train loss:0.000630107311534\n",
      "train loss:0.00116568000478\n",
      "train loss:0.00118160452679\n",
      "train loss:0.00047468636884\n",
      "train loss:0.000412153165604\n",
      "train loss:0.00043603949369\n",
      "train loss:0.000320023306529\n",
      "train loss:0.00057582627065\n",
      "train loss:0.00179457165102\n",
      "train loss:3.26169496952e-05\n",
      "train loss:0.000866695252885\n",
      "train loss:0.00126648479459\n",
      "train loss:0.0363373323434\n",
      "train loss:0.00108846572613\n",
      "train loss:0.00036322337979\n",
      "train loss:0.00317805170106\n",
      "train loss:4.58012323022e-05\n",
      "train loss:0.000445900510172\n",
      "train loss:0.00423939709662\n",
      "train loss:2.10687027495e-05\n",
      "train loss:0.0258018913615\n",
      "train loss:1.44912971678e-05\n",
      "train loss:9.64150177487e-06\n",
      "train loss:0.000565436737241\n",
      "train loss:0.00128985489808\n",
      "train loss:0.00370420031999\n",
      "train loss:4.3095170305e-05\n",
      "train loss:0.0031376222675\n",
      "train loss:0.000870510001584\n",
      "train loss:0.000898060772905\n",
      "train loss:0.000419087358057\n",
      "train loss:0.000319171782497\n",
      "train loss:0.00165574342962\n",
      "train loss:0.000562077676966\n",
      "train loss:8.56993354771e-05\n",
      "train loss:0.000685105306346\n",
      "train loss:3.06780748708e-05\n",
      "train loss:0.000933209416567\n",
      "train loss:0.00294459378633\n",
      "train loss:0.000149465467137\n",
      "train loss:0.000234735295764\n",
      "train loss:0.0014609969526\n",
      "train loss:0.00151608605537\n",
      "train loss:0.00455459448158\n",
      "train loss:0.00159840373354\n",
      "train loss:0.00274946176691\n",
      "train loss:0.000207666001933\n",
      "train loss:0.00140970377546\n",
      "train loss:0.00129073810481\n",
      "train loss:0.000595954961328\n",
      "train loss:0.000835403590787\n",
      "train loss:0.000365517568843\n",
      "train loss:0.00374328278456\n",
      "train loss:0.000489449419702\n",
      "train loss:0.00159931833337\n",
      "train loss:0.000333108376376\n",
      "train loss:0.00212176654121\n",
      "train loss:0.000336495192421\n",
      "train loss:0.00591896968739\n",
      "train loss:0.000205611287275\n",
      "train loss:0.00038037926517\n",
      "train loss:0.000573200592356\n",
      "train loss:0.000215473100924\n",
      "train loss:0.000121521019286\n",
      "train loss:0.000111631013598\n",
      "train loss:0.00118348034482\n",
      "train loss:0.000535637386908\n",
      "train loss:0.000979898635067\n",
      "train loss:0.00330748046222\n",
      "train loss:0.000996442256153\n",
      "train loss:0.00256729731616\n",
      "train loss:0.00045995046024\n",
      "train loss:0.00505727454581\n",
      "train loss:0.000371556608498\n",
      "train loss:0.000964546604226\n",
      "train loss:0.000130981256857\n",
      "train loss:0.00121806195677\n",
      "train loss:0.000157175024311\n",
      "train loss:0.000345478954181\n",
      "train loss:0.00162039104867\n",
      "train loss:0.000790959538132\n",
      "train loss:0.000588471405606\n",
      "train loss:0.00058385856595\n",
      "train loss:0.000274493391427\n",
      "train loss:0.000237997667795\n",
      "train loss:0.000150869667055\n",
      "train loss:0.011081835871\n",
      "train loss:0.000694088975744\n",
      "train loss:0.000602009913969\n",
      "train loss:0.000640566992215\n",
      "train loss:0.0167553873695\n",
      "train loss:0.000395026349212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0127499737009\n",
      "train loss:0.00020916986497\n",
      "train loss:0.00653381826325\n",
      "train loss:0.00771248025517\n",
      "train loss:0.00893676871016\n",
      "train loss:0.000348804414027\n",
      "train loss:5.43836925042e-05\n",
      "train loss:0.0014116657867\n",
      "train loss:0.00347637005712\n",
      "train loss:0.000577025141867\n",
      "train loss:9.65632492955e-05\n",
      "train loss:7.54930722999e-06\n",
      "train loss:6.76511511377e-05\n",
      "train loss:9.1208752383e-05\n",
      "train loss:6.22482417254e-05\n",
      "train loss:0.00131331742471\n",
      "train loss:0.00115140218268\n",
      "train loss:0.00190885413311\n",
      "train loss:0.000581750512249\n",
      "train loss:0.00140737243671\n",
      "train loss:0.00299638232384\n",
      "train loss:0.000259677995983\n",
      "train loss:0.000408615271697\n",
      "train loss:0.000531711300539\n",
      "train loss:0.00038911846041\n",
      "train loss:0.000193443079195\n",
      "train loss:0.000526624695782\n",
      "train loss:0.000143833864416\n",
      "train loss:0.000721370117259\n",
      "train loss:0.00167389911719\n",
      "train loss:0.0010075282272\n",
      "train loss:5.68934762863e-05\n",
      "train loss:7.71273011563e-05\n",
      "train loss:2.19923446327e-05\n",
      "train loss:0.00919295093753\n",
      "train loss:3.20232489294e-05\n",
      "train loss:0.000313477456896\n",
      "train loss:0.011673429264\n",
      "train loss:0.00119323286103\n",
      "train loss:0.0145989185825\n",
      "train loss:0.00154788839415\n",
      "train loss:0.000337650131746\n",
      "train loss:0.000417433475926\n",
      "train loss:0.00129232661503\n",
      "train loss:0.000530228756814\n",
      "train loss:9.48633559475e-05\n",
      "train loss:0.000313405673107\n",
      "train loss:0.00304099309521\n",
      "train loss:0.000170939082146\n",
      "train loss:0.000378309353673\n",
      "train loss:0.00344190928059\n",
      "train loss:2.10694419108e-05\n",
      "train loss:0.000445016574345\n",
      "train loss:0.000519691531661\n",
      "train loss:0.0024908156762\n",
      "train loss:0.000124942888373\n",
      "train loss:0.0011210429527\n",
      "train loss:0.000172622515246\n",
      "train loss:0.00152728698342\n",
      "train loss:0.00273117877328\n",
      "train loss:0.00193671074995\n",
      "train loss:0.000240588060832\n",
      "train loss:0.000742115977247\n",
      "train loss:0.000288692032045\n",
      "train loss:0.0028702928701\n",
      "train loss:0.000953771876343\n",
      "train loss:1.70565836288e-05\n",
      "train loss:0.000195059312228\n",
      "train loss:0.000911912364158\n",
      "train loss:0.00101940401846\n",
      "train loss:0.000815524013703\n",
      "train loss:0.000651978426502\n",
      "train loss:0.00402187017303\n",
      "train loss:6.77742452353e-05\n",
      "train loss:0.0015241476962\n",
      "train loss:0.000699161320232\n",
      "train loss:0.000284157203611\n",
      "train loss:0.00113340099754\n",
      "train loss:0.00304341874789\n",
      "train loss:0.000140904903856\n",
      "train loss:0.000300261954477\n",
      "train loss:0.000351744005944\n",
      "train loss:0.000340528664509\n",
      "train loss:3.28522072268e-05\n",
      "train loss:0.00190787441171\n",
      "train loss:7.21764661896e-05\n",
      "train loss:0.00113143690057\n",
      "train loss:0.000577953291664\n",
      "train loss:0.00294689031691\n",
      "train loss:0.000263921126752\n",
      "train loss:0.00206596858579\n",
      "train loss:0.000820562396301\n",
      "train loss:0.000295184281945\n",
      "train loss:0.000280721098397\n",
      "train loss:0.00366184350439\n",
      "train loss:0.000618587866443\n",
      "train loss:0.000199329621715\n",
      "train loss:0.000359824588624\n",
      "train loss:0.000479207178508\n",
      "train loss:0.00109681827454\n",
      "train loss:0.000872523015662\n",
      "train loss:0.00133642217381\n",
      "train loss:0.000288985392702\n",
      "train loss:0.000975532234192\n",
      "train loss:0.000521363683624\n",
      "train loss:0.000595896280931\n",
      "train loss:0.013031747741\n",
      "train loss:0.00118713910372\n",
      "train loss:0.000314270543106\n",
      "train loss:0.0025962575745\n",
      "train loss:0.000777563259712\n",
      "train loss:9.73254243765e-05\n",
      "=== epoch:20, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.000965754081172\n",
      "train loss:0.00197601139901\n",
      "train loss:0.00298914223123\n",
      "train loss:0.0023675824838\n",
      "train loss:0.000585128859935\n",
      "train loss:0.000943628203088\n",
      "train loss:4.0293779648e-05\n",
      "train loss:0.00434976452557\n",
      "train loss:0.000849185713703\n",
      "train loss:0.0184652077217\n",
      "train loss:0.00113027579992\n",
      "train loss:0.000217233579955\n",
      "train loss:0.00359557545456\n",
      "train loss:0.00186170241203\n",
      "train loss:0.000610205710551\n",
      "train loss:0.00175225235919\n",
      "train loss:0.000196297019779\n",
      "train loss:3.6724109665e-05\n",
      "train loss:0.00068306584864\n",
      "train loss:0.000371605522481\n",
      "train loss:0.000454672499393\n",
      "train loss:0.00178924816808\n",
      "train loss:0.000964145113309\n",
      "train loss:0.000245550844055\n",
      "train loss:0.000248163619642\n",
      "train loss:0.00127906200413\n",
      "train loss:0.000311845018127\n",
      "train loss:0.00188235711452\n",
      "train loss:0.000607873716465\n",
      "train loss:0.00290570908956\n",
      "train loss:0.000154775006899\n",
      "train loss:0.000589033155131\n",
      "train loss:0.00164001090301\n",
      "train loss:0.00126329545268\n",
      "train loss:4.55112043958e-05\n",
      "train loss:0.000178628730918\n",
      "train loss:0.00067552470643\n",
      "train loss:0.000126481406419\n",
      "train loss:0.000142640111486\n",
      "train loss:6.84022854295e-05\n",
      "train loss:0.0126704286487\n",
      "train loss:0.00252670420319\n",
      "train loss:0.000822641819252\n",
      "train loss:0.00159103905369\n",
      "train loss:0.00316352366899\n",
      "train loss:0.00747687570951\n",
      "train loss:0.000101550253721\n",
      "train loss:0.0031349350474\n",
      "train loss:0.00674532219217\n",
      "train loss:0.0018011170222\n",
      "train loss:0.00464869307616\n",
      "train loss:0.00206190798782\n",
      "train loss:0.000419162622359\n",
      "train loss:0.000841856061092\n",
      "train loss:1.80794889322e-05\n",
      "train loss:0.000796923127446\n",
      "train loss:0.000187973423403\n",
      "train loss:0.000287596538483\n",
      "train loss:0.000196568250158\n",
      "train loss:0.00194660138797\n",
      "train loss:0.00317640544689\n",
      "train loss:0.000286426434744\n",
      "train loss:0.00188953640356\n",
      "train loss:0.000354003597731\n",
      "train loss:0.000248846345661\n",
      "train loss:0.00202628512173\n",
      "train loss:0.00352540246497\n",
      "train loss:0.00329706899034\n",
      "train loss:0.00112321554221\n",
      "train loss:0.0059335851419\n",
      "train loss:8.86370538196e-05\n",
      "train loss:0.00196475735355\n",
      "train loss:0.000528496488819\n",
      "train loss:3.00905216943e-05\n",
      "train loss:2.87067831579e-05\n",
      "train loss:0.00211036163367\n",
      "train loss:4.95447378499e-05\n",
      "train loss:0.0020084956265\n",
      "train loss:0.000293340242633\n",
      "train loss:0.000387117031858\n",
      "train loss:0.000379065686603\n",
      "train loss:0.00251920635885\n",
      "train loss:0.00301213334303\n",
      "train loss:0.000742795021573\n",
      "train loss:0.00221824800208\n",
      "train loss:0.00363759414152\n",
      "train loss:0.00116505481133\n",
      "train loss:0.000181989823999\n",
      "train loss:0.000276951110636\n",
      "train loss:0.000657839002276\n",
      "train loss:0.00316485364756\n",
      "train loss:3.94725498467e-05\n",
      "train loss:0.00331427618134\n",
      "train loss:0.000166153828991\n",
      "train loss:0.00114553402039\n",
      "train loss:0.000231620157783\n",
      "train loss:0.000255860960489\n",
      "train loss:0.00273586387893\n",
      "train loss:0.00120649770703\n",
      "train loss:0.0031994418816\n",
      "train loss:0.00106603295126\n",
      "train loss:0.00165702533274\n",
      "train loss:0.00035397260879\n",
      "train loss:0.000579499592146\n",
      "train loss:0.0151975900602\n",
      "train loss:0.00116486715401\n",
      "train loss:0.000554460330195\n",
      "train loss:0.00032375756861\n",
      "train loss:7.51176650789e-05\n",
      "train loss:0.000481769678264\n",
      "train loss:0.00252755787288\n",
      "train loss:0.00275026372196\n",
      "train loss:0.0034535903795\n",
      "train loss:7.34736458444e-05\n",
      "train loss:0.00129580263984\n",
      "train loss:0.000252979504151\n",
      "train loss:0.000309616401699\n",
      "train loss:0.000410630552409\n",
      "train loss:0.000911741076007\n",
      "train loss:0.0013476632812\n",
      "train loss:0.0014008452824\n",
      "train loss:0.000254665662353\n",
      "train loss:7.42968535622e-05\n",
      "train loss:9.62405391492e-05\n",
      "train loss:5.78960065471e-05\n",
      "train loss:0.000898850644588\n",
      "train loss:0.00313936514392\n",
      "train loss:0.000892545546588\n",
      "train loss:1.57008029497e-05\n",
      "train loss:0.00126848893158\n",
      "train loss:0.00153124309367\n",
      "train loss:0.00200471039438\n",
      "train loss:0.000875494427964\n",
      "train loss:0.00261441016813\n",
      "train loss:0.000140068673392\n",
      "train loss:0.00251721779645\n",
      "train loss:0.000470048742572\n",
      "train loss:0.00198121202329\n",
      "train loss:0.000248714762114\n",
      "train loss:3.83961848746e-05\n",
      "train loss:0.000149663625104\n",
      "train loss:0.000483955787058\n",
      "train loss:0.00113195535346\n",
      "train loss:0.000617413058712\n",
      "train loss:0.00104969659687\n",
      "train loss:0.00158901698068\n",
      "train loss:0.000253304091644\n",
      "train loss:0.00138909083438\n",
      "train loss:1.13612058632e-05\n",
      "train loss:0.00160811883344\n",
      "train loss:0.00154001288129\n",
      "train loss:0.00222275333883\n",
      "train loss:0.000194165939216\n",
      "train loss:0.000131932469105\n",
      "train loss:0.00147386937909\n",
      "train loss:0.00179802242721\n",
      "train loss:0.000733657716066\n",
      "train loss:0.000748336468854\n",
      "train loss:0.00324522373241\n",
      "train loss:9.85313178202e-05\n",
      "train loss:0.00219180641698\n",
      "train loss:0.0113486380142\n",
      "train loss:0.0014248471342\n",
      "train loss:0.000384384479786\n",
      "train loss:0.00268304896539\n",
      "train loss:0.000390161579188\n",
      "train loss:0.00195546877421\n",
      "train loss:0.000928754476701\n",
      "train loss:0.00173091639538\n",
      "train loss:0.000127942916977\n",
      "train loss:0.00110189223944\n",
      "train loss:0.00248359575348\n",
      "train loss:0.000182539678648\n",
      "train loss:0.00257609890424\n",
      "train loss:0.001968687342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00230573592513\n",
      "train loss:0.00154095785856\n",
      "train loss:0.000701099119305\n",
      "train loss:0.000597435956909\n",
      "train loss:0.000624234401639\n",
      "train loss:0.000261674750829\n",
      "train loss:0.00694416166455\n",
      "train loss:0.000395486031924\n",
      "train loss:0.000115522642117\n",
      "train loss:0.00254918660638\n",
      "train loss:0.000839955269376\n",
      "train loss:0.00155094467617\n",
      "train loss:0.00570744791112\n",
      "train loss:0.00143168673723\n",
      "train loss:0.00461425084815\n",
      "train loss:0.000347852820973\n",
      "train loss:6.9754074356e-05\n",
      "train loss:4.90018794498e-05\n",
      "train loss:4.49150480269e-05\n",
      "train loss:0.000410177742412\n",
      "train loss:0.000158606402376\n",
      "train loss:0.00245326082256\n",
      "train loss:0.001777215235\n",
      "train loss:0.00111162676655\n",
      "train loss:0.000403124413572\n",
      "train loss:0.00157775974547\n",
      "train loss:0.000788678136799\n",
      "train loss:0.00100533309882\n",
      "train loss:0.00337585044682\n",
      "train loss:1.51225509586e-05\n",
      "train loss:0.0014919871034\n",
      "train loss:0.00389637127844\n",
      "train loss:0.000154096217725\n",
      "train loss:5.88133095817e-05\n",
      "train loss:0.000145483884431\n",
      "train loss:0.00304232137781\n",
      "train loss:0.0017880460887\n",
      "train loss:0.000270983212981\n",
      "train loss:0.00108556014516\n",
      "train loss:0.000522549558076\n",
      "train loss:5.84166317298e-05\n",
      "train loss:0.000601007594579\n",
      "train loss:0.0015537907011\n",
      "train loss:0.00534592879464\n",
      "train loss:0.000350731415766\n",
      "train loss:2.44388194156e-05\n",
      "train loss:0.000641505899954\n",
      "train loss:0.000369733751532\n",
      "train loss:0.00191891949419\n",
      "train loss:0.0027360587571\n",
      "train loss:0.000102282244498\n",
      "train loss:0.000274725090459\n",
      "train loss:0.000171843463779\n",
      "train loss:0.00165227917633\n",
      "train loss:0.00110483096545\n",
      "train loss:0.000315664690643\n",
      "train loss:0.0171793558072\n",
      "train loss:0.000775727803538\n",
      "train loss:0.00142689660562\n",
      "train loss:0.00021952738879\n",
      "train loss:0.00303141905288\n",
      "train loss:0.000242264940228\n",
      "train loss:0.00294912138476\n",
      "train loss:0.000290333963835\n",
      "train loss:0.0033472353823\n",
      "train loss:0.00383123964681\n",
      "train loss:0.000166492154109\n",
      "train loss:0.00223743773183\n",
      "train loss:0.00042502461454\n",
      "train loss:0.00184469421899\n",
      "train loss:0.001281744928\n",
      "train loss:0.00532301790613\n",
      "train loss:0.00077357929884\n",
      "train loss:0.0017202493856\n",
      "train loss:0.000146749637332\n",
      "train loss:0.000126153762268\n",
      "train loss:0.000616149206442\n",
      "train loss:0.00154858713156\n",
      "train loss:0.00804505736569\n",
      "train loss:1.21107284028e-05\n",
      "train loss:0.000822300930074\n",
      "train loss:0.00100236914446\n",
      "train loss:0.00148483946309\n",
      "train loss:4.88089662196e-05\n",
      "train loss:0.000751244080871\n",
      "train loss:0.00315648242202\n",
      "train loss:0.00242320498042\n",
      "train loss:0.000294986778737\n",
      "train loss:0.000523815101396\n",
      "train loss:0.0376430755378\n",
      "train loss:0.00249823754596\n",
      "train loss:0.000795671587774\n",
      "train loss:0.000858327614235\n",
      "train loss:0.000960110927959\n",
      "train loss:0.000136950947304\n",
      "train loss:0.000649368914752\n",
      "train loss:0.000467927752416\n",
      "train loss:0.00162163872205\n",
      "train loss:0.000278959915575\n",
      "train loss:0.000847784502076\n",
      "train loss:0.000741062988986\n",
      "train loss:0.000144680765777\n",
      "train loss:0.00157889641259\n",
      "train loss:0.0129294466097\n",
      "train loss:0.0126098320007\n",
      "train loss:0.00866643635703\n",
      "train loss:0.00538109945711\n",
      "train loss:0.000149739408935\n",
      "train loss:0.000387697769366\n",
      "train loss:0.00584289544715\n",
      "train loss:0.00267246304667\n",
      "train loss:0.00165472432103\n",
      "train loss:0.00414742476063\n",
      "train loss:0.0538635199035\n",
      "train loss:0.0510827078293\n",
      "train loss:0.000451360151774\n",
      "train loss:0.000856912152308\n",
      "train loss:0.00174422742594\n",
      "train loss:0.000895571850799\n",
      "train loss:0.00079250395238\n",
      "train loss:0.0318382092651\n",
      "train loss:0.00854505275542\n",
      "train loss:0.000531953407686\n",
      "train loss:0.00807598199998\n",
      "train loss:0.00143247145041\n",
      "train loss:0.00998085826728\n",
      "train loss:0.00153241038038\n",
      "train loss:0.00343075866975\n",
      "train loss:0.0016590700566\n",
      "train loss:0.00221071231037\n",
      "train loss:0.00231176632177\n",
      "train loss:0.00139193167774\n",
      "train loss:0.00131466554142\n",
      "train loss:0.0156519641566\n",
      "train loss:0.000894905258933\n",
      "train loss:0.00209517949742\n",
      "train loss:0.0142843909821\n",
      "train loss:0.00202703159649\n",
      "train loss:0.00149241902527\n",
      "train loss:0.00194681366671\n",
      "train loss:0.00690252342351\n",
      "train loss:0.000456015874637\n",
      "train loss:0.00758349104053\n",
      "train loss:0.00191757820739\n",
      "train loss:0.000256874097465\n",
      "train loss:0.00170192937618\n",
      "train loss:0.00452849174044\n",
      "train loss:0.0313253624305\n",
      "train loss:0.00651408221458\n",
      "train loss:0.000752595875396\n",
      "train loss:0.00102039246193\n",
      "train loss:0.0509590350634\n",
      "train loss:0.00517433839199\n",
      "train loss:0.000165571238206\n",
      "train loss:0.00473133433809\n",
      "train loss:0.00652831839768\n",
      "train loss:8.5481600837e-05\n",
      "train loss:0.00025720064247\n",
      "train loss:0.000907844542436\n",
      "train loss:0.00415945616558\n",
      "train loss:0.00101413108377\n",
      "train loss:0.000999291058711\n",
      "train loss:0.00616249106183\n",
      "train loss:0.00281392524091\n",
      "train loss:0.00848911854324\n",
      "train loss:0.00251362806356\n",
      "train loss:0.000834922928522\n",
      "train loss:0.00586575384676\n",
      "train loss:0.00205102485635\n",
      "train loss:0.000231966344344\n",
      "train loss:0.000910021001617\n",
      "train loss:0.00134024261644\n",
      "train loss:0.00433142483924\n",
      "train loss:0.00321477085003\n",
      "train loss:0.00509750937668\n",
      "train loss:0.000629326160088\n",
      "train loss:0.000548993582571\n",
      "train loss:0.00461117722462\n",
      "train loss:0.00421954906864\n",
      "train loss:0.00169414216955\n",
      "train loss:0.00142292274353\n",
      "train loss:0.00906225444979\n",
      "train loss:0.00370075706122\n",
      "train loss:0.000608462764279\n",
      "train loss:0.0213123447641\n",
      "train loss:0.00220882655036\n",
      "train loss:0.00022397547495\n",
      "train loss:0.00158910316104\n",
      "train loss:0.000243247375343\n",
      "train loss:0.000745307501103\n",
      "train loss:0.0024465621297\n",
      "train loss:0.00220886527046\n",
      "train loss:0.00253713083043\n",
      "train loss:0.000169511258885\n",
      "train loss:0.00123641802732\n",
      "train loss:0.00124628248609\n",
      "train loss:0.00784624466338\n",
      "train loss:0.00812097935966\n",
      "train loss:0.000499996966401\n",
      "train loss:0.00305594388251\n",
      "train loss:0.00181043492275\n",
      "train loss:0.000875994395764\n",
      "train loss:0.00348498157953\n",
      "train loss:0.00594809071608\n",
      "train loss:0.0014456503874\n",
      "train loss:7.61125882299e-05\n",
      "train loss:0.0023910581988\n",
      "train loss:0.00257921320227\n",
      "train loss:0.00104126105972\n",
      "train loss:0.00211496604011\n",
      "train loss:0.00135850138489\n",
      "train loss:0.00333555438694\n",
      "train loss:0.0040664200981\n",
      "train loss:0.000491623077748\n",
      "train loss:0.0360535725274\n",
      "train loss:0.0328574863614\n",
      "train loss:0.000687275792813\n",
      "train loss:0.00249972731472\n",
      "train loss:0.0010770294043\n",
      "train loss:0.00941639596965\n",
      "train loss:0.00278195335237\n",
      "train loss:0.0232615312682\n",
      "train loss:0.00381420959215\n",
      "train loss:0.00518404954438\n",
      "train loss:9.26771702569e-05\n",
      "train loss:0.00233468257136\n",
      "train loss:0.000631019532322\n",
      "train loss:0.000536455203473\n",
      "train loss:0.00271013848679\n",
      "train loss:0.00545921924038\n",
      "train loss:0.027784044691\n",
      "train loss:0.00379488998684\n",
      "train loss:0.000249217465663\n",
      "train loss:0.061618672677\n",
      "train loss:0.00286373782827\n",
      "train loss:0.000931685066809\n",
      "train loss:0.00465791502381\n",
      "train loss:0.000827262472318\n",
      "train loss:0.00454240713241\n",
      "train loss:0.00066586570147\n",
      "train loss:0.000618712919204\n",
      "train loss:0.00143650852005\n",
      "train loss:0.00350539888933\n",
      "train loss:0.0422419890106\n",
      "train loss:0.00647402422605\n",
      "train loss:0.00202681888647\n",
      "train loss:0.00215172851475\n",
      "train loss:0.0033561857418\n",
      "train loss:0.00500580266534\n",
      "train loss:0.00243927564583\n",
      "train loss:0.000140572886014\n",
      "train loss:0.00144955561214\n",
      "train loss:0.00194415035346\n",
      "train loss:0.00209508918057\n",
      "train loss:0.0155967463854\n",
      "train loss:0.00177122928114\n",
      "train loss:0.00147090393006\n",
      "train loss:0.00465165298239\n",
      "train loss:9.23566152445e-05\n",
      "train loss:0.00202262020195\n",
      "train loss:0.00663222401933\n",
      "train loss:0.00176222108889\n",
      "train loss:0.001367143337\n",
      "train loss:0.00172640250763\n",
      "train loss:0.00975835064616\n",
      "train loss:0.0156179581362\n",
      "train loss:0.000393962134704\n",
      "train loss:0.000259621740398\n",
      "train loss:0.00233324253511\n",
      "train loss:0.00182996229889\n",
      "train loss:0.000492703494299\n",
      "train loss:0.0111170902582\n",
      "train loss:0.00279182811983\n",
      "train loss:0.00256968703439\n",
      "train loss:9.30429162593e-05\n",
      "train loss:0.00954023520937\n",
      "train loss:0.00100669722234\n",
      "train loss:0.00662349008327\n",
      "train loss:0.000352574774086\n",
      "train loss:0.00383688731531\n",
      "train loss:0.00282868577087\n",
      "train loss:0.00311507202896\n",
      "train loss:0.000988523069804\n",
      "train loss:0.000812534430394\n",
      "train loss:0.00345610999745\n",
      "train loss:0.00247084523357\n",
      "train loss:0.000823365202418\n",
      "train loss:0.00488303943958\n",
      "train loss:0.00137285225136\n",
      "train loss:0.00171897824484\n",
      "train loss:0.00224330803703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00030187296069\n",
      "train loss:0.0011027835961\n",
      "train loss:8.5312809441e-05\n",
      "train loss:0.00174724462401\n",
      "train loss:0.000145840021885\n",
      "train loss:0.00231069909783\n",
      "train loss:0.00136253109364\n",
      "train loss:0.00095891646707\n",
      "train loss:0.000186020508035\n",
      "train loss:0.00201565822619\n",
      "train loss:0.0138392883429\n",
      "train loss:0.00214665249781\n",
      "train loss:8.7589867864e-05\n",
      "train loss:0.00226740624805\n",
      "train loss:0.0169007214457\n",
      "train loss:2.31223436145e-05\n",
      "train loss:0.00447664969197\n",
      "train loss:0.000780985975181\n",
      "train loss:0.000439396391571\n",
      "train loss:1.71553085837e-05\n",
      "train loss:0.000382897764976\n",
      "train loss:0.00177615047117\n",
      "train loss:0.000105492754229\n",
      "train loss:0.00155076777728\n",
      "train loss:0.0014952000351\n",
      "train loss:0.000215870352846\n",
      "train loss:0.000488855265255\n",
      "train loss:0.00853517789971\n",
      "train loss:0.00107637455404\n",
      "train loss:0.00462814207495\n",
      "train loss:0.000256048846016\n",
      "train loss:0.00205506054802\n",
      "train loss:0.00160480248182\n",
      "train loss:0.000482400524888\n",
      "train loss:0.000427701522537\n",
      "train loss:0.00107127538344\n",
      "train loss:0.000586661392131\n",
      "train loss:0.00192773682545\n",
      "train loss:7.31349361949e-05\n",
      "train loss:0.00228208407684\n",
      "train loss:0.00346813011946\n",
      "train loss:0.00171024955867\n",
      "train loss:3.5968080645e-05\n",
      "train loss:0.000723415538494\n",
      "train loss:0.000994313971277\n",
      "train loss:0.000526396346877\n",
      "train loss:0.00197780828933\n",
      "train loss:0.00206141351726\n",
      "train loss:0.00171653444791\n",
      "train loss:0.0028171391603\n",
      "train loss:0.00588047579867\n",
      "train loss:0.00113207196764\n",
      "train loss:0.00209099181745\n",
      "train loss:0.000473641187514\n",
      "train loss:0.00453982535517\n",
      "train loss:0.000483924349882\n",
      "train loss:0.00303269056667\n",
      "train loss:0.00155164749991\n",
      "train loss:0.000159249211854\n",
      "train loss:0.0154741013611\n",
      "train loss:0.000653453580399\n",
      "train loss:0.0026731779777\n",
      "train loss:0.000140149275521\n",
      "train loss:0.00125211926464\n",
      "train loss:0.00062699853297\n",
      "train loss:0.00845692235469\n",
      "train loss:0.0032114798612\n",
      "train loss:0.000117141815396\n",
      "train loss:0.000134913512641\n",
      "train loss:0.000382612450874\n",
      "train loss:0.00622155082102\n",
      "train loss:0.000176237495323\n",
      "train loss:8.20230384715e-05\n",
      "train loss:0.00218728797781\n",
      "train loss:0.00308609840116\n",
      "train loss:0.00210128915283\n",
      "train loss:0.000157386052881\n",
      "train loss:0.000449816964647\n",
      "train loss:0.000276066286308\n",
      "train loss:0.00203916648644\n",
      "train loss:0.00068780413258\n",
      "train loss:4.9083511974e-05\n",
      "train loss:0.000210346838838\n",
      "train loss:0.000335036853526\n",
      "train loss:0.00151665378254\n",
      "train loss:0.00234591683039\n",
      "train loss:0.000302296482695\n",
      "train loss:0.00421182882265\n",
      "train loss:0.00139124285433\n",
      "train loss:0.0497727935009\n",
      "train loss:0.000452091184064\n",
      "train loss:5.71780064665e-05\n",
      "train loss:0.00020240491274\n",
      "train loss:0.000455437674241\n",
      "train loss:0.00388123546328\n",
      "train loss:0.00032247318899\n",
      "train loss:0.00288699745653\n",
      "train loss:0.00015455413166\n",
      "train loss:4.631413227e-05\n",
      "train loss:0.000698896453285\n",
      "train loss:0.000111368764605\n",
      "train loss:0.00278047260978\n",
      "train loss:0.000339783239778\n",
      "train loss:0.00652334371385\n",
      "train loss:0.000328623751539\n",
      "train loss:2.39867961608e-05\n",
      "train loss:0.000823582013506\n",
      "train loss:0.000261335997427\n",
      "train loss:0.000360826993842\n",
      "train loss:0.00100074093757\n",
      "train loss:0.000721593747297\n",
      "train loss:0.000179884549158\n",
      "train loss:0.00149009844237\n",
      "train loss:0.002452969149\n",
      "train loss:0.00769342181756\n",
      "train loss:0.000319736538491\n",
      "train loss:0.000605282787107\n",
      "train loss:0.00322126287338\n",
      "train loss:0.00277197607588\n",
      "train loss:0.00148561723105\n",
      "train loss:0.000284176708766\n",
      "train loss:9.15781309534e-05\n",
      "train loss:0.00101057962872\n",
      "train loss:0.000103416216884\n",
      "train loss:0.00347779620182\n",
      "train loss:0.00124630676026\n",
      "train loss:7.0849996666e-05\n",
      "train loss:0.00165250930869\n",
      "train loss:0.00367501384277\n",
      "train loss:0.000182966679722\n",
      "train loss:0.000834829222633\n",
      "train loss:6.97312009967e-05\n",
      "train loss:0.00256442511319\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9879\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tmp.dataset.mnist import load_mnist\n",
    "#from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============== Final Test Accuracy ===============\n",
    "\n",
    "test acc:0.9879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 CNN 시각화 \n",
    "\n",
    "## 7.6.1 가중치 시각화 \n",
    "\n",
    "<img src='CNNimg.png' width=50%>\n",
    "\n",
    "1번째 층의 합성곱 계층에서는 에지나 블롭 등의 저수준 정보가 추출된다. \n",
    "\n",
    "- 에지: 색상이 바뀐 경계선\n",
    "- 블롭: 국소적으로 덩어리진 영역\n",
    "\n",
    "## 7.6.2 층 깊이에 따른 추출 정보 변환\n",
    "\n",
    "계층이 깊어질수록 추출되는 정보는 더 추상화된다. \n",
    "\n",
    "<img src='AlexNet.png' width=50%>\n",
    "\n",
    "처음층은 단순한 에지, 텍스처 필터에 반응, 더 복잡한 사물의 일부에 반응하도록 변화함 \n",
    "\n",
    "층이 깊어지면서 뉴런이 반응하는 대상에 단순한 모양에 '고급' 정보로 변화해감 (사물의 '의미'를 이해하도록 변화)\n",
    "\n",
    "* AlexNet\n",
    "\n",
    "    차이점 \n",
    "    - 활성화 함수 ReLU 사용 \n",
    "    - Local Response Normalization LRN 구소적 정규화를 실시하는 계층이용\n",
    "    - 드롭아웁을 사용 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x83210b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEjCAYAAABD3BobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhdC70HoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa21fe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "\n",
    "RNN은 관련 정보와 그 정보를 사용하는 지점 사이 거리가 멀 경우 역전파시 그래디언트가 점차 줄어 학습능력이 크게 저하되는 것으로 알려져 있습니다. 이를 vanishing gradient problem\n",
    "\n",
    "state 값이 점점 작아지면서 연산을 거듭할수록 0에 가까워짐 0.1x0.1 -> 0.001 ...\n",
    "\n",
    "-> 보안 LSTM (Long Short-Term Memory): 이전에 계산된 x 값  \n",
    "\n",
    "이전상태를 언제까지 기억할것인가 \n",
    "\n",
    "https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
