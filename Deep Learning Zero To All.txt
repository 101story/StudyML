tensorflowkorea 텐서플로우 문서 한글 번역본
https://www.gitbook.com/book/tensorflowkorea/tensorflow-kr/details

https://hunkim.github.io/ml/

텐서플로우 실행
(C:\....\Documents\Anaconda3) C:\...>activate tensorflow
(tensorflow) C:\...>python
>> import tensorflow as tf
>> tf.__version__


텐서플로우 예제
https://github.com/hunkim/DeepLearningZeroToAll


2015년에 발표한 엔드류응 교수
머신러닝 슈퍼파워

누가 봐야 하나

목적
  머신러닝에 대한 이해
  딥러닝을 이해하기 위한 알고리즘 (Linear)
  딥러닝 (Neural..)
  텐서플로우 & 파이썬

소스
  엔드류응 교수
  노트
  비쥬얼

많은 데이터 multivarial 다루는 방법

######################
## 1장 ML Lec
######################

머신러닝이 무엇인가
  소프트웨어 프로그래밍
  explicit programming : 명확한 프로그램밍의 제한
  개발자가 일일이 정하지 않고 기계 자체가 학습해서 배우는 능력을 갖음
  Arthur Samuel 이 1959년에 개발

러닝은 무엇인가
  Supervised : 레이블들이 정해져있는 트레이닝 데이터가 있는 상태에서 학습함.
    개/고양이 구분
    이건 개야 이건 고양이야 이렇게 알려주고 시작하는 학습방법
  Unsupervised : 유사한 것끼리 그룹핑을 함.

Supervised learning
  스팸메일
  기존에 시험본 사람들의 데이터를 보고 나의 시험결과를 예측

Training data set
  특징적인 데이터 x = 레이블 y 을 통해 학습을 통한 모델이 만들어짐
  x,y 가 Training data set
  알파고

Supervised 종류
  Regression : 범위 안에 값
    시험에 대한 예측
  Binary classification : pass / non-pass 2가지의 경우로만 나눔
  Mul level classification(Letter grade) : 몇가지 경우로 나뉨

-----
## ML lab 01 텐서플로우 설치
-----

텐서플로우를 사용하는 종류
  압도적인 1등
  많은 자료들이 존재함

Data flow graph 를 이용하여 계산을 할 수 있는 라이브러리

Data Flow Graph
  노드 (오퍼레이션: +,-,*)
  엣지 (데이터, 데이터 어레이) 또는 Tensor
  이러한 작업을 할 수 있도록 flow 해 놓은 것들
  텐서 들이 막 돌아 다님
  Tensor Flow

https://brunch.co.kr/@mapthecity/15

cmd 에서 python 을 사용해서 import 한 후 버전 확인

소스 코드
https://github.com/hunkim/DeepLearningZeroToAll/

헬로우 라는 노드가 생기고 세션을 통하여 실행 시킴

ts에 타입을 변경해주면 계속 반영됨
b : byte 스트림

Computational Graph
  그래프의 텐서들
  세션을 통해서 RUN 해야지만 결과값이 나옴

1. 그래프를 빌드 함
2. 그래프 실행
3. 결과로 그래프의 값이 업데이트 되거나 리턴값을 줌

Placeholder
  실행시킬떄 값을 던져 주고 싶을 떄
  노드를 placeholder 라는 특별한 값으로 만들어줌
  세션을 실행 시킬떄 feed dict로 값을 넘겨 줌
  array 로 여러개의 값도 넘겨 줄 수 있음

Tensor
  막 돌아 다니는
  기본적으로 array 를 말함
  Rank N차원 배열 배열의 중복
    rank 1인 tensor는 벡터
    rank 2인 tensor는 행렬
  Shape 각각의 엘리먼트에 몇개씩 들어가있나 차원별
    [[1,2,3], [4,5,6], [7,8,9]] -> 2차원 [3,3]
  Type 데이터 타입
    주로 float32, int32 를 씀



----- 설치 -----
  (C:....\Anaconda3) C:\>python -m pip install --upgrade pip
  Requirement already up-to-date: pip in c:\....\anaconda3\lib\site-packages

  (C:....\Anaconda3) C:\>conda create -n tensorflow python=3.5
  Fetching package metadata ...........
  Solving package specifications: .

  Package plan for installation in environment C:\....\Anaconda3\envs\tensorflow:

  The following NEW packages will be INSTALLED:

      pip:            9.0.1-py35_1
      python:         3.5.3-0
      setuptools:     27.2.0-py35_1
      vs2015_runtime: 14.0.25123-0
      wheel:          0.29.0-py35_0

  Proceed ([y]/n)? y

  python-3.5.3-0 100% |###############################| Time: 0:00:08   3.59 MB/s
  setuptools-27. 100% |###############################| Time: 0:00:00   3.54 MB/s
  wheel-0.29.0-p 100% |###############################| Time: 0:00:00   8.09 MB/s
  pip-9.0.1-py35 100% |###############################| Time: 0:00:00   4.32 MB/s
  #
  # To activate this environment, use:
  # > activate tensorflow
  #
  # To deactivate this environment, use:
  # > deactivate tensorflow
  #
  # * for power-users using bash, you must source
  #


  (C:\....\Documents\Anaconda3) C:\...>activate tensorflow

  (tensorflow) C:\...>pip install tensorflow
  Collecting tensorflow
    Downloading tensorflow-1.1.0-cp35-cp35m-win_amd64.whl (19.4MB)
      100% |################################| 19.4MB 54kB/s
  Collecting numpy>=1.11.0 (from tensorflow)
    Downloading numpy-1.12.1-cp35-none-win_amd64.whl (7.7MB)
      100% |################################| 7.7MB 138kB/s
  Collecting werkzeug>=0.11.10 (from tensorflow)
    Downloading Werkzeug-0.12.1-py2.py3-none-any.whl (312kB)
      100% |################################| 317kB 1.5MB/s
  Collecting six>=1.10.0 (from tensorflow)
    Downloading six-1.10.0-py2.py3-none-any.whl
  Requirement already satisfied: wheel>=0.26 in c:\...\documents\anaconda3\envs\tensorflow\lib\site-packages (from tensorflow)
  Collecting protobuf>=3.2.0 (from tensorflow)
    Downloading protobuf-3.3.0.tar.gz (271kB)
      100% |################################| 276kB 1.4MB/s
  Requirement already satisfied: setuptools in c:\.....\documents\anaconda3\envs\tensorflow\lib\site-packages\setuptools-27.2.0-py3.5.egg (from protobuf>=3.2.0->tensorflow)
  Building wheels for collected packages: protobuf
    Running setup.py bdist_wheel for protobuf ... done
    Stored in directory: C:\....\AppData\Local\pip\Cache\wheels\1b\42\a0\4c7343df5b629ec9c75655468dce7652b28026896b0209ba55
  Successfully built protobuf
  Installing collected packages: numpy, werkzeug, six, protobuf, tensorflow
  Successfully installed numpy-1.12.1 protobuf-3.3.0 six-1.10.0 tensorflow-1.1.0 werkzeug-0.12.1

  (tensorflow) C:\.....>python
  Python 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)] on win32
  Type "help", "copyright", "credits" or "license" for more information.
  >>> import tensorflow as tf
  >>> hello = tf.constant('Hello, TensorFlow!')
  >>> sess = tf.Session()
  2017-05-04 17:11:07.900146: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
  >>> print(sess.run(hello))
  b'Hello, TensorFlow!'

----------------------------------------
2017-05-04 17:11:07.900146: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
해결 : SSE 명령을 수행할 수 없다는 말 곧 CPU 성능만큼 쓸수 없을 것이다. 단일명령으로 복수의 데이터 처리 SSE  http://www.kwangsiklee.com/ko/2017/04/%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%EA%B2%BD%EA%B3%A0%EB%A9%94%EC%84%B8%EC%A7%80-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-the-tensorflow-library-wasnt-compiled-to-use-sse3-instructions/

-----
window tensorflow 설치 설명
http://jaejunyoo.blogspot.com/2017/02/start-tensorflow-gpu-window-10.html

jupyter notebook import tensorflow
http://stackoverflow.com/questions/37061089/trouble-with-tensorflow-in-jupyter-notebook
(tensorflow) username$ conda install ipython
(tensorflow) username$ pip install jupyter #(use pip3 for python3)



######################
## 2장 ML Lec Linear Regression
######################

* Predicting exam score: regression
  트레이닝 데이터를 이용하여 학습한 모델을 만들고
  그 모델에게 예측값을 물어봄


* Hypothesis 가설
  리니어한 모델이 우리 데이터에 맞을것이라고 가정
  공부하는 시간이 많을 수록 성적이 잘나올 것이다.
  잘 맞는 선을 찾는것 = 학습한다.
  H(x) 가설
  가장 잘 맞는 선은 무엇일까?

* Cost Function
  실제 데이터와 가설이 얼마나 다른지 계산
  H(x) - y
    -> 차이를 제곱해서 양수로 표시해주고, 차이가 클때 더 값이 커질수 있도록 해줌

  cost function : 값들의 차이를 다 더해줘서 / n 개 해서 평균을 구하게 됨
  cost 함수에 가설H(x)을 대입하면 (W, b) 함수가 됨
  이 값을 가장 작게 만들어 주는것 이 리니어 리그레션의 학습이 된다.

* Goal
  최소의 cost 를 구하자

-----
## ML lab 02 linear regression
-----
* 가설과 cost 함수
  w 라는 웨이트(회귀 가중치)의 곱과 b bias 의 합
  예측 값과 실제값의 차이의 평균이 가장 작은것

* TensorFlow Mechanics
  1. 그래프를 빌드
  2. 세션으로 실행시킴
  3. 실행 결과를 받거나 업데이트 함

* 1. 그래프 만들기
  주어진 학습값
  variable 이라는 노드로 wight 값과 bias 값을 정의
    변수와는 다른 개념으로 텐서플로우가 사용하는 값이다.
    텐서플로우가 자체적으로 변경시키는 값이다.
    Tranable 한 변수값
  텐서플로우의 shape 이 어떻게 되는지 줌
    보통 w, b의 값을 모르니까 random 한 값으로 줌 [] 엔 shape 을 줌 1차원 array
    hyposthesis 정의
  텐서플로우에 있는 함수를 사용하여 만듬
    함수에 대해서는 다음장에 설명

* reduce_mean
  tf.square y = x * x = x^2
  값의 평균을 내줌

  Graident Descent 로 최소화를 해줌
  함수의 최소값을 찾는 알고리즘: 옵티마이져(Optimizer)
  (이부분은 나중에... )
  Cost 함수에 대해서 그래프를 그려보면 ^2 2차식의 그래프가 나오고 거기에 최소 기울기를 구함
  http://bcho.tistory.com/1139

* 2.3. 과정
  w,b 라는 변수를 사용했는데
  global_variable... 를 사용해서 초기화 해줘야 한다.
  2001 번 돌리는데
    20번에 한번씩 출력해줘라
    cost, w, b 값을 찍어줌
  train-cost-hy-(-w-b)

* placeholders
  직접 x,y 값을 주지 않고 필요할떄 값을 던져주겠다.
  sess.run() train 시킬때 x,y 값을 array feed_dict 로 넘겨줌
  return 되는 값으로 cost_val, w_val, b_val , _(필요없음) 변수 선언해줌
  train 노드

* full code with placeholders
  입력값에 따르면
  w=1 b=1.1 이 나와야됨
  학습한 모델에 예측하고 싶은 값을 넣어서 결과가 맞는지 확인해봄
  print(sess.run...x: [5]) > 6.1.....
  동시에 두개도 가능

* 최종 텐서 머신
  w, b 를 계속 업데이트 시킴



######################
## 3장 ML Lec Linear Regression cost
######################

* Gradient descent (경사하강법)
  경사가 내려가는 알고리즘
  최고값 알고리즘
  W,b 뿐만 아니라 여러개가 있는 cost function 도 최소값을 찾아 낼 수 있음

* How it work
  시작점은 상관없음
  W를 변경하여 경사도를 점점 바꿔감

* Formal definition
 알파값은 러닝넷 0.1 상수값으로 가정
 W 값을 큰값으로 또는 작은값으로 W 를 변경해가며 기울기를 구하겠다.
 미분절차
 W 가 변화되는 Decent 알고리즘이 만들어짐
 Cost 함수를 최소화 하는 W 를 구함

* Convex function
 경사를 타고 타고 내려고는 것이 최소의 W, b 를 구하는 것인데
 경사가 들쑥 날쑥 하다면 최소 값이 다를 수 있다.
 우리가 만든 Cost function 은 바닥이 오목한 값이여서 괜찮음
 이런모양을 convex 라고 함


-----
## ML lab 03 linear regression cost
-----

* full code
 range(-30, 50) : -3 ~ 5 까지의 값을 0.1 간격으로 작게 움직이겠다.
 W x 축 cose y 축으로 이루어진 plot 함수를 그림

* Gradient descent
 W 값을 조정하는 방법
 -3 부터 시작한 이유 x 값 W 가 가장 낮은곳이 1이여서 -값이 + 가 되게 해줘야됨
 알파값이 어느 간격으로 움직이게 될지 정함
 update 는 변수에 다시 어싸인 되는 것을 말함 .assign() 사용

* Full Code
 매번 미분 식을 주는 방법보다 optimizer 값을 사용할 수 있다.
 자동으로 미분해줌

* Option
 그레디언트조작하는 방법
 그레디언트를 계산한 값을 받고 다시 변경하여 다시 전달 할 수 있다.
 get gradients



######################
## 4장 ML Lec Multi-Linear Regression
######################

* Predicting exam score
  3개의 변수로 예측하기
  w1x1+w2x2+w3x3+b=H(x1,x2,x3)

* Hypothesis using matrix
  행렬로 하면 x,w 의 위치가 바뀐다.
  1행으로 이뤄진 x 를 앞에 1열로 이뤄진 w 를 뒤에 쓴다.
  H(X) = XW

* Many x instances
  각 실제 데이터를 인스턴스 라고 부름

* Hypothesis using matrix
  여러개의 x 열(인스턴스)이 생기더라도
  X 행 의 여러 열을 한번에 계산 할 수 있다.
  [5,3] * [3,1] = [5,1]
  3개의 x 값 (입력을 원하는 3개의 피처) 열으로 이뤄진 5개의 행(데이터 샘플) 인스턴스와
  3개의 w 값 행으로 이뤄진 1개의 열을 곱하면
  1개의 xw 값 행으로 이뤄진 5개의 열이 나옴

* Hypothesis using matrix
  W 에 대한 크기를 결정해야되는데
  입력되는 x 값과 출력값을 알면 크기를 구할 수 있다.
  n 개의 인스턴스
  [n,3] * [3,1] = [n,1]

회귀분석
선형성, 독립성, 정규성, 등분산성, 다중공선성

결정계수 : 실제 데이터를 얼마나 설명하는지
수정결정계수 : 변수가 계속 늘어나면 결정계수가 계속 올라감 이걸 수정

P : 0.05 값보다 작은 값
T : 1.96 -1.96
점진선택 영향력이 많이 있는것부터
후진선택 영향력이 적은 것부터
단계선택


-----
## ML lab 04 Multi-Linear Regression
-----

* Matrix
  함수로 계산하면 복잡해지기 때문에
  행렬을 이용하여 계산한다.

* 파일의 데이터 로드 하기ㅎ
  numpy 의 loadtxt

* Queue Runner
  Decode (데이터 분리: , 기준으로 분리.. 등)
  1. 파일리스트 정의
  2. 파일을 읽어올 reader 를 정의 어떤 타입으로 읽을지
  3. value 값을 어떻게 이해할 것인가
    decode_csv(데이터 타입과 값이 없으면 0으로 맞춰주기도함)
  4. batch
    읽어온 데이터를 x 데이터, y데이터 나눠서 batch 해라
    한번에 몇개씩 가져올지
  5. queue 관리
  6. for loop sess.

  Coordinator 클래스는 멀티 쓰레드들이 함께 정지되도록 돕고 예외처리들을 그들이 정지되기 위해 대기하는 프로그램에 알린다.
  QueueRunner 클래스는 같은 큐 안의 tensors 를 추가하기 위해 협력하는 많은 쓰레드들을 생성한다.


* Classifying diabetes
  당료병 예측 (0/1)

  파일로 읽어 오기
  8 개의 x 데이터
  8 개가 들어와서 1개가 리턴됨

* Excercise
  tf.decode_csv
  www.kaggle.com


######################
## lec 5-1 Logistic(regresion)
######################

* Regression
  가정 : 행렬을 이용
  Cost : 얼마나 가설이 실제값에 가까운지
  Gradient decent : W = W - 기울기
  알파 : 한번에 얼마나 움직일까 (learning weight)

* classification
  Binary (두개중에 한개)
  0, 1로 인코딩함

* Linear Regression
  이상값이 존재하면 binary 기준이 달라질수 있어 문제가 될 수 있다.
  0 or 1 보다 훨씬 큰 값이 나올 수 있다.
  x=100 w=0.5 y=50

* Logistic Hypothesis
  G(x) 모든 값은 0~1 까지의 값으로 바꿔주는 함수를 찾아보자
  sigmoid 함수 = logistic
  로 모든 x 값을 0~1 의 값으로 바꿈


######################
## lec 5-2 Logistic Regression의 cost 함수 설명
######################

* Cost Function
  sigmoid 함수를 적용하여 H(x) 를 만들면 울퉁불퉁한 U 값이 나온다
  들어가는 값 자체가 제곱이 되면서 구불구불해짐
  Gradient decent 를 하면 다른 값이 나올 수 있다.
  Global Minimum 을 찾아야 함 (전체를 통틀어서 제일 작은값)
  > 때문에 Cost 함수를 변경해야 한다.

* New cost function for logistic
  Cost 함수 y=1 인 경우 와 y=0 인 경우로 나누어 계산함
  log 함수를 사용하
  y=1 -log(H(x))
  y=0 -log(1-H(x))
  예측한 값이 옳으면 0 에 가깝게 되고 틀리면 무한으로 감

  if 조건을 계속 사용하는 것이 좋지 않기때문에 없애줌
  0 또는 1을 넣어서 식이 없어 질 수 있도록 함

* Minimize cost
  w = w - 미분값
  Gradient decent 함수를 이용하여 w 값을 구함


----
lab 5 TensorFlow로 Logistic Classification의 구현하기(new)
----


* Logistic Regression
  H(x) 는 시그모이드 함수를 이용

* Training Data
  Shape 설명
  https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/resources/dims_types.html

  x_data = [[1,2], ...] Shape[None, 2]
    Shape[None, 2] 값이 두개 전체 개수는 정하지 않고 N 개
  y_data = [[0], ....]  Shape[None, 1]
    Shape[None, 1] 값이 두개 전체 개수는 정하지 않고 N 개

  tf.random_normal(shape)
    정규분포를 갖는 랜덤값
    tf.random_normal([2, 1]) -> [[w1,w2]] shape 이 2,1 인 2차원 변수 (행렬)
    http://pythonkim.tistory.com/69

  행렬 곱셈
  x 가 2개의 객체가 들어오고 1개로 나간다
  w = [2,1]
  b 는 나가는 값과 같게 씀 y 가 하나기 때문에 하나
  b = [1]

  predicted = 시험에 통과 했는지 안했는지 (binary classification)
  hypothesis 가 0.5 보다 큰지 작은지 pass=1 fail=0
  hypothesis 는 float 로 만들면 1, 0 이 됨

  accuracy 예측 값과 실제값이 같은지 확인 10번을 예측했는데 5번 맞았다 50%

* Train the model

  sess.run(a) return a 에 대한 train 된 값
  sess.run(a,b,c) return 각 a, b, c 에 대한 train 된 값이 각각 나옴


######################
## lec 6-1. Multinomial
######################

* Logistic regression
  binomial classification 에는 적합하지 않았다.
  시그모이드( =logistic)를 함수를 이용

  실제 데이터 와 예측 데이터 y^(햇)

  데이터를 구분하는 선을 도출

* Multinomial classification
  학점을 부여 하자 (a,b,c)
  binomial 로 만들어보면
    a or not
    b or not
    c or not

  물음표??)
    공부한시간, 수업참여시간 2개였는데
    왜 x, w 가 3개 일까 a,b,c 3개여서??
    !!=답변> x1, x2는 입력 feature의 갯수라 x3, x4등 계속해서 많아 질수 있습니다. 입력 feature들의 한가지 예를 보여 드린 것이고요. 대부분의 경우 이 feature가 100~1,000 개 이상이 될수도 있습니다.


######################
## lec 6-2. Cost 함수 소개
######################

* Sigmoid
  큰 값이 아닌 0~1 사이의 작은 값으로 구분하고싶다.
  a 인지 아닌지, b 인지 아닌지

* softmax 함수
  1. 이것이 0~1사이의 값
  2. 전체의 sum 이 1
  3. 그중의 하나만 명확하게 하고 싶다. (one-hot encoding) arg max

* Cross Entropy
  cost 함수로 cross entropy 가 적합하다.
  S(y) 예측값 L 정답 실제값
  예측값과 실제값의 차이를 cross entropy 를 이용해서 구함

  -log 함수는 soft max 함수를 거쳤기 때문에 0~1 사이의 값으로 0 에 가까울수록 무한으로 큰 값 1로 갈수록 0 으로 수렴

  cost function 은 예측이 맞으면 값을 아주 크게 주고 예측이 틀리면 값을 적게 주는 역할을 하도록 함

* Logistic cost VS cross entropy

* Gradient descent
  cost 함수는 주어졌고
  다음은 최소값 찾기
  경사면을 타고 따라 내려 가면 최소 값을 찾을 수 있다.
  lost 함수 (미분값은 알아서 공부하는걸로...)


----
LAB 06-1: TENSORFLOW로 SOFTMAX CLASSIFICATION의 구현하기
----

0. reduce_sum(a, reduction_indices=1)
첫 번째 매개변수에 대한 합계 계산. 두 번째가 없으면 전체 합계, 0을 입력하면 열 기준, 1을 입력하면 행 기준 합계 적용. Y*tf.log(hypothesis)의 결과가 어떤 매트릭스인지 파악되면, reduce_sum 함수도 쉽게 이해할 수 있음

출처: http://pythonkim.tistory.com/category/머신러닝_김성훈교수님?page=3 [파이쿵]


* softmax function
  여러개의 클래스를 예측할때 유용
  N 개의 예측할 일이 있을 때 사용
  XW=y
  Softmax 에 통과시키면 확률로 나오게 된다.
  확률을 모두 더하면 1이 된다.

* tensor 코드로 표현
  tf.nn.softmax() 함수 사용
  scores = logit 의 값을 넣어 줌
  -> probabilities (확률) 로 결과가 나옴

* Cost fuction: cross entropy
  loss function y*log(y예측값)
  axis = 1 (?) 이건뭐지????

* full code
  여러개의 분류중 어디에 해당하는지
  one hot encoding 방식을 사용
  3개의 분류중 하나 인경우
  0,1,2 3자리중 한자리만 핫하게 해준다
  핫하다 : 한자리만 1로 만들어준다 .
  행렬곱 W [4,3] 인 이유
        aaa
  (xxxx)aaa = (xa+xa+xa+xa xa+xa+xa+xa xa+xa+xa+xa)
        aaa
        aaa

* Test&one-hot encoding
  예측하고 싶은 x 값을 hypothesis 로 만들어
  가장 큰 값을 출력함
  arg_max(a,1) 1인 이유?????
  몇번쨰가 높은가요 축?


----
LAB 06-2: TENSORFLOW로 FANCY SOFTMAX CLASSIFICATION의 구현하기
----
* full code
  softmax 확률로 변환해줌
  logits -> softmax (2.0 -> 0.7) 확률값으로 변경

-- 예쁘게
cross_entropy, one_hot, reshape

* softmax_cross_entropy_with_logits
  one-hot 방식을 사용하여 y 값을 줌
  - 도 나오고.. 복잡함
  cross-entropy는 통계학 용어로, 두 확률 분포 p와 q 사이에 존재하는 정보량을 계산하는 방법을 말한다
  hypothesis 부분에 logits 을 넣음
  softmax 함수에 들어가기 전의 값

* Animal classification
  동물의 특징을 가지고 종 분류하기

* tf.one_hot and reshape
  0~6 숫자로 되어 있는 y 값을 one_hot 방식으로 바꿔줘야 한다.
  tf.one_hot(1,2) 사용 1: 0 부터 시작하는 값, 클래스 갯수 (0~6 7개)
  one_hot 을 하면 차원을 하나더 더함
  shape(None, 1) -> shape(None, 1, 7)
      [[0],[3]]  -> [[[1000000]],[[0001000]]]
        rank2    -> rank3
  reshape() 사용해서 (-1, 7) shape 을 만듬 (-1 : 나머지 everything)
    --> [[1000000],[0001000]]
  shape(가장큰거 -> 작은거) -> [[1,1],[1,1],[1,2]] = (3,2)

* full code
  매번 생각하기 힘드니까
  W = [입력 x 값, 출력 7 개]
  b = [출력 7개]

  argmax(Y_one_hot, 1) Y_one_hot one_hot 으로 만들어준값, 1 Y 그값자체 원핫을 만들기 전의값
  맞게 예측한 것들을 모아서 평균을 내서 정확도를 구함

  flatten [[1],[0]] 를 풀어줌 [1,0]
  각각의 list 를 zip 으로 묶어서 p, y 로 넘겨줌





######################
## Lec 7-1 학습 rate, Overfitting, 그리고 일반화 (Regularization)
######################
> Tip
  - learning rate 조절
  - 데이터 선처리
  - overfitting 방지방법

* Gradient decent
  알파값 임의값 learning rate
  learning rate 를 잘 정하는 것이 중요
  step 이 너무 크면
    최소의 w 값을 지나쳐 버릴 수 있다.
    학습이 이뤄지지도 않고 숫자가 아닌값이 찍힐 수 있다.
    ==> Overshooting
  step 이 너무 작으면
    최소의 w 값까지 갈 수가 없다.

* Data(x) preprocessing
  for Gradient Decent
  w 가 두개라고 생각하면 항아리를 위에서 바라본 형태가 나옴
  두개의 x 값이 큰 차이가 있는 겨우
    예) 1x=1 2x=10e-12
    한쪽으로 외곡된 타원의 등고선이 나옴
    -> 임의 알파 값이 튀어 나갈 수 있다.
  해결>
    zero-centered data
      중심값을 0.0 으로 맞춰줌
    normalized data
      공간을 작게 줘서 그 안에 데이터가 다 들어 올수 있게 함

* Standardization
  normalized data
    x 값을 평균/분산 계산해주면 됨

* Overfitting
  머신러닝이 학습을 통해서 모델을 만드는데
  학습데이터에 너무 딱 맞는 모델이 나올 수 있다.
  실제 테스트 데이터에는 안맞는 경우가 생길 수 있다.

* Solution for overfitting
  트레이닝 데이터를 많이 함
  features 개수를 줄임
  Regularization : 일반화

* Regularization
  w 값을 너무 큰 값으로 주지 말자

?????>  구부리지 말고 펴자 -> w 이 작은 값을 가지도록 하자

  cost 함수를 최소화 하는것이 목표였는데
    cost 함수에 term 을 추가해줌
    w 의 값에 제곱한 값이 작아 질수 있도록 최소화 시킴
    하나의 상수 regurarization strength 로 값을 조절해줌
  l2reg = 0.001 * tf.reduce_sum(tf.square(w))
    0.001 > regurarization strength


######################
## Lec 7-2 regurarization strength
######################
> 모델 검정방법 확인

* Training and test sets
  트레이닝 셋과 테스트 셋을 분류하여 확인
  (교과서 와 실전문제 로 나눔)

* Training, validation and test sets
  validation (람다값) : regularization 을 할떄 얼마나 강하게 할지에 대한 값
  Training set 을 2개로 나눠서 validation set 을 따로 줌
    validation 으로 training data set 으로 학습시킨 모델을 다시 튜닝함
    (공부를 한 후 모의고사 를 한번 봄)

* Online learning
  데이터가 너무 많을때
  100만개이 데이터가 있을때 한번에 넣을 수 없으니
  10만개씩 잘라서 학습시킴
  이전 학습 결과를 남기고 추가해서 학습시킴

* MINIST Dataset
  손으로 작성한 다양한 모양의 숫자를 컴퓨터가 알아 볼 수 있도록 함
  (작성한 우편번호 확인)

* Accuracy
  모델이 얼마나 정확한지 특정
  데이터의 y 값과 모델의 예측 y 값 비교



----
lab 07-1: training/test dataset, learning rate, normalization
----

Training and Test datasets
  is_correct 맞는지 아닌지 확인

Learning rate
  learning rate 을 잘 줘야 한다.
  너무 커고 너무 작아도 안됨
  선안에 작은 굴곡에 갇혀 버릴수 있다.

Non-normalized inputs
  NaN
  값이 너무 커져버리면 밖으로 툭 나가버린다.
  input data 가 normalized 되지 않아서 그런다
  MinMaxScaler 함수
  값을 0~1 사이의 값으로 normalized 한다.
  데이터값이 너무 크거나 값이 들쑥 날쑥 할떄 사용



----
lab 07-2: Meet MNIST Dataset
----

28x28xI image
  x 784개의 x 피처들
  y 10개의 숫자값

MNIST Dataset
  샘플 데이터
  100개씩 올려서 확인
  y 값을 one_hot 으로 읽어 들일때 설정함

  W 의 값 784개가 들어오고 10개가 나가는값
  b 는 y 값

Softmax
  이전에 softmax 사용한식 확인...

Training epoch/batch
  epoch : 전체 데이터 셋을 한번 학습시키는 것 1epoch(애폭?)
    1epoch = batch size 100(한번에 100개씩)
  이중 for 문을 사용해서 전체 데이터 셋을 15번 반복해서 학습
  전체 데이터를 100개씩 나눠서 학습
  놈? 학습 방법

  테스트 데이터를 이용해서 모델 평가
  session.run() 을 사용해서 돌릴수도 있고
  eval() 이라는 함수를 사용해서 돌릴수도 있음



######################
## lec 8 딥러닝의 기본 개념: 시작과 XOR 문제
######################

Ultimate dream
  인풋의 길이에 따라 신호가 달라짐
  input * weight 들을 다 sum 하고 + bias 로 전달됨
  나온 결과 값이 특정값 이상이 되면 전달되고 안되면 전달되지 않는다

Activation Function
  신호가 들어옴 x
  신호와 weight 을 곱하고
  + bias
  activation function 에서 특정 값보다 크면 값을 넘기고
  작으면 0 으로 넘김

Logistic regression units
  동시에 연산을 계산해서 결과를 낼 수 있는 기계

AND/OR problem
  AND OR 문제도 선으로 그어서 설명할수 있다.
  XOR 은 하나의 선으로 풀수가 없다

Perceptrons
  아무도 풀수 없다.
  민스키? 교수

Backpropagation
  paul 박사
  wb 를 이용해서 만들어진 출력에서
  에러를 구해서 뒤로 트레이닝을 시키면 어떨까
  hinton 박사
  재발견으로 주목받기 시작함

Convolutional Neural Network
  고양이한테 그림을 보여주고 뉴런의 활성화 모습을 확인
  부분부분을 담당하는 신경망들이 따로 잇고 이것들이 조합되는게 아닐까
  이미지를 부분부분 잘라서 나중에 합치는 방법

A BIG problem
  소수의 레이어에서는 잘 동작하는데
  10여개 이상의 레이어에서는 backpropagation 에서는
  에러가 전달되지 않고 학습되지 않고 성능이 떨어진다.
  많은 알고리즘이 나오고 neural 보다 좋은것들이 많더라


----
딥러닝의 기본 개념2: Back-propagation 과 2006/2007 ‘딥’의 출현
----

CIFAR
  연구실
  돈안되는 일...ㅠㅠ..

Breakthrough
  초기값만 잘 주면 학습할수 있다.
  깊게 신경망을 구축하면 복잡한것도 풀수 있다.

  neural 에는 관심이 없으니 deep 으로 바꾸자

ImageNet Classification
  Hiton 교수의 알렉스 박사
  알렉스넷

  그림을 설명하기 시작

Deep API Learning
  자연어로 컴퓨터에게 말만하면 자동으로 API 를 사용해야 하는지
  알려줌
  20% 60% 까지 정확도가 높아짐

Geoffrey Hinton's summary of findings up to today
  our labeled datasets were thousands of times to small.
  our computers were millions of times too slow
  we initialized the weights in a supid way
  we used the wrong type of non-linearity



----
 Lab 8 : Tensor Manipulation
----

rank shape axis
  rank : end [ 이 몇개 있는지
  shape : [] 안에 들어 이는 개수 가장 안쪽에 엘리먼트 개수로 오른쪽부터 채움 (1,2) 가장 안쪽에 2개 엘리먼트
  Axis : 가장 안쪽에 [] 이 가장 큰 값
  가장 바깥이 0 axis

Broadcasting
  shape 이 다르더라도 연산을 할수 있게 해줌
  [[1,2]] + 3 할때 임의 3을 하나 더 줘서 더할 수 있게 해줌

Reduce mean
  줄여서 구하는 평균
  여러개의 값을 가지고 줄여서 주해준다.

  rank 와 axis
  [[1,2]    -> axis=1 가장 안쪽의 1,2 값으로 평균을 내라 1.5
    [3,4]]
    ↓ axis=0 1,3 가장 바깥 쪽의 값으로 평균을 내라 1,3 의 평균 2
  axis=-1 뒤에 축 파이썬의 -1과 같은 의미 가장 안쪽의 값들 []

Reduce sum
Argmax
Reshape
  shape=[-1, 3] : 가장 안쪽을 3개로 하고 나머지는 알아서

Reshape(squeeze, expand)
  squeeze : 여러 차원 1개로 펴줌
  expand dim : 차원을 추가

One hot
  자리를 보고 한자리 하나만 핫하게 해줌
  0000100

Casting
  True -> 1 값으로
  값을 변경 해줌

Stack
  axis = 1
  축으로 쌓는 방법을 바꾼다

Ones and Zeros like
  같은 shape 으로 같은 모양의 0 또는 1로 채워진 값의 행렬을 만들어줌

Zip
  복수개의 탠서 한방에 처리(?)


######################
## lec 09 : XOR 문제 딥러닝으로 풀기
######################

Neural net
  하나의 네트웍에 하나의 값을 구함
  W, b 가 주어졌다고 생각하고 (다음강의)
  실제로 여러 유닛을 지나며 값이 변경되는 것을 봄

  Multinomial classification 했던 것을
  한개의 노드로 표현

  수식으로 표현
  k(x) = sigmoid(xw+b)
  hypothesis = tf.sifmoid((k(x)*w2)+b2)

----
 미분
----
Basic derivative (기본 미분)
  순간 변화률
  0f/0x -> f() 식을 x 로 미분해라

chain rule
  f(g(x))
  알고 싶은 것은 x 가 f 에 미치는 영향
  f/x = f/g*g/x
  나누어서 하자
  g 로 f 를 미분하는것 * g 를 x 로 미분 하는 것을 곱하면됨


----
 lec 9-2 딥넷트웍 학습 시키기
----
  f=wx+b, g=wx, f=g+b
  w * x ->  g
          + b   -> f

  최종입력들이 있고
  제일 먼저 가장 최종의 값을 계산
  f=a+b -> a 가 f 에 미치는 영향, b가 f 에 미치는 영향

  끝을 보면
  g 가 f 에 미치는 여향을 아니까
  x 가 g 에 미치는 영향을 알 수 있고 (local)
  이것으로 x 가 f 에 미치는 영향을 알 수가 있음

  tensorflow 는 우리의 표현을 각각의 graph 로 가지고 있음
  back propagation 을 하기위해서 미분을 하려고 graph 를 가지고 있음


----
Lab 9-1: XOR을 위한 텐스플로우 딥넷트웍
----

    casting 함
        T:1 / 0
    모델 잘 안됨!!!

    * Neural Net
    레이어 하나를 더 추가함
    w1 = tf.Variable(tf.random_normal([2,2]), name='weight1')
    in 2개(x1,x2) out 2개? 왜????
    2가 맘에 들어서 2라니 -_-;
    [[5,-7],[5,-7]]
    w = 5 for [0,0] [0.1]
    w = -7 for [1,0] [1.1]
    두개의 w 을 한번에 그리고 여러개
    - y=5x+(-8), y=-7x+3 두개의 계산식을 한번에 표현


    * Wide NN for XOR
    10 개르르 입력받아서 계산해보자

    * Deep NN for XOR
    깊게 들어가게 하기
    layer 를 여러개 만듬

    * Excercise
    MNIST

----
Lab 9-2: Tensor Board로 딥네트웍 들여다보기
----
    * TensorBoard
    5개의 스탭
    1. From TF graph log 를 만듬 무엇을 기록할 것인지
    2. Merge 한번에 쓰기 위함 Summary 해줌
    3. 세션을 어느 위치에 기록할지 정하고 writer 에 그래프를 넣음
    4. summary 실행하기
    5. TensorBoard 실행하기

    * log 할 값 정하기
    Scalar 한개의 값
    Histogram 여러개의 값
        처음 값은 모여있다가 점점 값들이 나눠지는 것을 볼 수 있음

    * name_scope
    그룹을 만들어서 하나로 그룹핑 해서 정리해줌

    * global_setp
    진행 되는 순서를 기록해서 summary 에 같이 넣어 줌

    * Tensorboard 실행

    * Remote server
    포트포워딩을 이용
    SSH remote server 의 이름과 id 를 가지고 local 에 있는 주소와 연결해줌

    * Multiple runs
    같은 모델인데 옵션을 다르게 하거나 값을 비교해보고 싶다.
    learning rate 을 다르게 줘서 비교하고 싶다.
    학습을 할때 옵션을 주고
    writer 에게 다른 디렉토리를 알려줌
    logs/ 상위 디렉토리 안에 여러개의 하위 디렉토리를 만들고
    상위 디렉토리 logs 를 실행함

    * Exercise
    MNiST Tensorboard 보기



######################
## lec 10-1 XSigmoid 보다 ReLU가 더 좋아
######################

    * NN for XOR
    activation function : 시그모이드 함수 같이 active, unactive 를 결정하는 함수

    * Let's go deep & wide
    베타 값을 정하기가 힘듬
    Weight 입력은 두개  OUT 5 개는 다음의 IN 5 개로 맞춰줌
    bias  값은 두번쨰 값에 맞게 5 지정

    Input - Hidden - Output Layer

    * 9 hidden layers!
    random_uniform([], -1.0, 1.0) -1.0, 1.0 이게 뭐였지 -_-?
    텐서 보드로 확인하기

    * Backpropagation
    86년도 개발!
    2단 3단 정도의 그래프는 학습이 잘 되는데
    그 이상이 되면 학습이 잘 되지 않는다.

    * lec 9-2 chain rule
    f/x = f/g*g/x
        g/x 값은 y
        y = 0.0001 추측
        f/g*0.0001 chain rule 을 적용하면 0.0001 을 계속 곱하면 값은 계속 작아짐 최종적으로 미분 값은 아주 작은 값이 됨
    f/y = f/g*g/y
        y 값은 0 ~ 1 사이의 작은 값

    * Vanishing gradient
    점점 경사 기울기가 사라지는 문제
    output layer 근처에 있는 기울기는 진하나
    점점 input layer 로 갈수록 흐려진다.
    --> 문제로 NN 이 주목 받지 못함

    * Sigmoid
    함수를 잘못썼다.
    <1 값이여서 그렇다
    대체 -> ReLU
        ReLU : 0 보다 작으면 0
            0 보다 크면 갈때까지 보내버림

    * Rectified Linear Unit
    시그모이드 대신 적용 (activation function)

    * ReLu
    마지막 단은 0~1 사이어야 하기때문에 마지막만 sigmoid 적용

    * Activation Function
    - Leaky ReLU : 0 을 너무 끄면 그러니까 조금 살려주자 0.1 곱하기
    - ELU : 0.1 로 fix 하지 말고 원하는 값으로 바꿀수 있게 해줌
    - Maxout : ...
    - tanh : sigmoid 함수를 좀 살려서 0 을 중심으로 값을 내림 -1~1 사이의 값
    ReLU, LeakyReUL, tanh 를 주로 사용함

    * Activation functions on CIFAR-10
    maxout -> ReLU -> VLReLU 순으로 괜찮았다.


----
lec 10-2 Weight 초기화 잘해보자
----

    * Vanishing gradient 문제 해결
    초기 값을 잘 줘야 한다.

    * set all initial weights to 0
    초기값을 0 으로 줘보자
    weight 이 전부 0 으로 바껴서 계산이 되지 않음

    * Need to set the initial weight
    초기값이 모두 0 이면 안된다
    DBN (Deep Belief Nets) 을 어떻게 잘 학습시킬까 문제
        RBM : Restricted Boatman Machine (찾아보기!!!????)
        을 사용함

    * RBM Structure
    2단의 layer
    restriction : 노드들끼리는 연결되지 않고 앞뒤로만 연결됨

    * Recreate input
    두가지 operation 을 가짐
    입력을 재생산해냄
    x1, x2, x3 입력 set 이 값을 만들어냄
    출력된 값을 다시 w 를 곱해서 x1` 값으로 내보냄
    입력 x1 와 재생산한 x1` 를 빼서 차가 최저가 되도록 w 를 조절함
    Encode/Decode 라고도 함

    * How can we use RBM to initialize Weigths
    레이어가 많아도 두개씩만 값을 서로 주고 받으면서 차가 최저가 되는 w 을 구함
    구하고 나면 다음 레이어로가서 다시 구함
    (Deep Belief Network)

    * Pre training
    x 데이터 값만 있으면 됨
    우선 두개의 레이어만 가지고 RBM 을 돌림
    그다음 두번쨰 레이어와 다음 한개의 레이어와 RBM 을 돌림
    그렇게 초기화된 w 값을 만들어줌

    * Fine Tuning
    x 데이터와 레이블로 학습시킴 (이미 잘 되어 있다.)
    초기화 값만 잘주면 학습도 쉽고 잘 된다.

    * Good news
    RBM 을 안쓰고 간단한 초기값 구하는 방식이 나옴

    * Xavier/He initialization
    입력 (fan_in) 과 출력(fan_out) 값으로 구할수 있다.
    w -> fan_in ~ fan_out 사이의 값인데 sqrt(fan_in) 으로 나눈 값을 줌
    2015년
    sqrt(fan_in/2) 를 하면 더 좋은 성능이 나온다.

    * prettytensor implementation
    이미 구연된것 가져오기

    * activation functions and initialization on CIFAR-10
    여러 초기화 방법과 activation function 을 사용한 성능 비교
    LSUV
    OrthNorm
    OrthoNorm-MSRA
    Xavier
    MSRA

----
lec 10-3 Dropout 과 앙상블
----
    * Overfitting
    training data 의 에러률은 계속 떨어지는데
    test data 의 에러률은 올라갈떄 Overfitting 되었다 함

    * Solution for overfitting
        많은 데이터 이용
        Regularization 사용

    * Regularization
        l2reg = Regularization strength

    * Dropout: A simple way to prevent neural networks from overfitting
        그만둬버리는 것
        선을 끊어 버리는 것

    * Waaaait a second...
        일부러 몇개의 노드를 뺴고 계산하도록 하는 것
        고양이의 특징으로 5가지가 있는데 2가지는 뺴고도 잘 판단하는지 봄

    * TensorFlow implementation
    한단을 추가해서 랜덤으로 특징값을 빼줌
    (학습하는 동안에만 dropout 시킴)
    dropout_rate=1 이면 모든 특징 이용

    * What is Ensemble?
    여러전문가에게 물어보고 여러 대답을 듣고 병합해서 모델을 만듬




----
lec 10-4 레고처럼 네트웍 모듈을 맘껏 쌓아보자
----
    * Fast forward
    여러개의 레이어중에 중간에 몇단계씩 skip 하고 계산함
    : 시그널을 잡아서 앞으로

    * split & merge
    여러개의 입력을 모아서 하나로 하거나
    하나의 입력을 여러개로 나눠서 계산

    * Recurrent network
    확장시켜서 옆으로 더 확장 시킴
    RNN


----
Lab 10: 딥러닝으로 MNIST 98%이상 해보기
----
    * softmax classifier for MNIST
    epoch, batch 를 이용

    * NN for MNIST
    좀 더 깊게 만들어 보기
    3단정도 추가하여서
    784개를 몇단을 구정할지 나가는값으로 고려해서 정함 [784, 256]
    relu 를 사용


    * xavier (샤비에)
    초기화를 잘해야된다.
    초기화 함수를 random 에서 -> initializer 를 추가해줌
    처음부터 cost 값이 낮아 진다.

    * Deep NN
    좀더 깊고 넓게 레이어를 늘려서
    넓게 512
    깊게 레이러를 많이
    -> 결과는 오히려 떨어졌다.
        아마도 overfitting 이 된거 아닐까
        네트웍이 길어지면서 학습데이터를 기억해버린다.
        새로운 테스트 데이터를 가져오면 오히려 낮아진다.

    * Dropout (overfitting 해결)
    한 droupout layer 를 추가해줌
    몇프로를 끊을지 유질할지 keep_prob
        traning 을 할때는 0.5~0.7
        testing 을 할때는 1
    학습과 테스트의 경우를 다르게 하기위해 placeholder 사용

    * optimizers
    이전에는 GradientDescentOptimizer 사용
    tf.train... 많은 Optimizer 가 있음
    SGA, momentum, nag, adadelta, adam...
    www.denizyuret.com/ 에 가보면 어떤 최적화 방법이 좋을지 보여줌
    학습횟수 / COST 그래프

    * Adam Optimizer
    tf.train.AdamOptimizer

    * Summary
    Softmax(한단) vs Neural Nets(여러단)
    초기화 Xavier
    Dropout
    Adam Optimizer 사용
    Batch Normalization (입력값을 정규화 시켜주는 방식)
        -> github.com 10-6-mnist batchnorm 보기


######################
## lec 11-1 ConvNet의 Conv 레이어 만들기
######################

    * only limit is your imagination
        fully connected 네트워크 (forward)
        x -> [] ->[] ->[] -> y

        x 의 입력을 여러개 해서 하나로 합침
        ConvNet Convolutional Neural Networks

    * 고양이 실험
    : 이미지를 보고 특정 부분의 뉴런들만 반응함

    * 자동차 이미지 CONV RELU POOL
        하나의 이미지를 잘라서 각각의 이미지를 넘김
        Convolution layer : 각각의 이미지
        ReLU layer : 각각의 이미지를 ReLU 단계를 거침
        POOL layer : ...?
        최종적으로 fully connected neural netwarks FC 구성
        레이블링을 함

    * Start with an image (width * hight * depth)
        큰 이미지 벡터
        이미지 일부분(filter)을 처리함
        filter 의 사이즈는 임의로 정의 5*5*3 (*3 은 칼라?)

    * Get one number using the filter
        filter 의 값이 하나의 값으로 나옴
        어떻게?!
        y = Wx+b = ReLU(Wx+b)
        x1, x2, x3, x4, x5 (5*5 36개)
        W에 따라서 w1x1+w2x2 .. = y 하나의 숫자로 만들어짐
        (늘 했던것)

    * Let's look at other area with the same filter(W)
        W 의 값이 똑같은 하나의 필커로 전체의 이미지를 훑음
        총 몇개의 값이 나올까?
        --> 값들을 알아야 Weight 개수도 정하고 어떻게 넘길지 설계 할 수 있음 (산수)

    * 7 * 7 이미지 계산
    상단에서 3*3 필터가 한칸씩(중복) 총 5번 이동함
    한칸씩 이동 (stride : 1)
    두칸씩 이동 (stride : 2) 3*3 의 output 이 나옴

    ((N - F)/stride)+1
    stride 3 은 불가능 함 2.33 ...
    stride 를 크게 할수록 output 값은 작아지고 정보를 잃어 버린다.

    * In practice : Common to zero pad the border
    Padding 을 함
    둘래에 가상으로 0을 입력해줌
        - 그림이 급격하게 작아짐을 방지
        - 모서리를 알려줌
    pad with 1 pixel
        7*7 -> 9*9
    9*9 로 계산을 해보면 output 이 7*7 이 됨
    원래의 입력 이미지 7*7 이 나옴
    이미지의 손실이 없다.
    filter 사이즈에 따라 5 이면 pad 값을 2로 맞춰줌

    * Swiping the entire image
    다른 set (다른 W)으로 다른 filter 를 만듬
    필더 6 개를 적용시켜서 6개의 깊이 있는 output 값이 나옴
    (패딩을 사용하지 않았다고 가정)
    (5*5*3) 6개 filter 의 activation maps 은 (28, 28, 6)
    (32-5)/1 + 1 => 28

    * Convolution layers
    Conv, ReLU 를 여러번 함
    activation map 에 또 Conv 을 함
        5*5*x -> x 값은 깊이와 같아야 함

    처음에는 랜덤 초기화

    http://cs231n.stanford.edu/

----
lec 11-2 ConvNet Max pooling 과 Full Network
----
    * pooling layer(sampling)
    샘플링하는 것
    깊이는 몇개의 필터를 사용하냐에 따라 달라짐

    하나의 레이어만 뽑아네서
        -> resize 해서 작게 하는 것 pooling
        -> pooling 을 해서 다시 값들을 쌓음

    * MAX POOLING
    하나의 레이어씩 선택해서
    4*4 이미지
    2*2 필터로 2칸씩 이동하겠다.
        -> 총 4개의 출력이 생김

    4개의 값을 어떻게 연산할수 있을까
        -> MAX POOLING 가장 큰 값을 고르자!
    전체의 값들 중에 한개만 뽑자

    그 다음의 이미지 사이즈는 필어와 STRIGT 개수에 따라 달라짐

    * Fully Connected Layer (FC layer)
    어떤 순서로 쌓을지 쌓는 방법은 알아서
    마지막에 pooling 을 주로 함
    끝으로 Fully Connected Layer 를 거쳐서 이미지가 어디에 속하는지 구해줌

    http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html




######################
## lec 12 NN의 꽃 RNN 이야기
######################
    * Sequence data
    이전에 한말들 단어들로 맥락을 유추할 수 있다.
    series 데이터들 처리
    이전의 결과를 다음연산에 영향을 미친다.

    * Recurrent Neural Network
    ht = fw(ht-1, xt)
    new state = function with W (old state, input vector)

    * Vanila RNN
    tanh 함수를 사용해서 계산
    tanh(old state 의 W 와 현재 input vector 의 W 를 더함)
    y = W * tanh(old state 의 W 와 현재 input vector 의 W 를 더함)
        계산된 값에 가중치를 다시 곱해서 출력 값을 예측함
    전체 썔이 모두 같은 weight 를 갖는다.

    * character-level language model example
    입력으로 Hell을 주면 출력이 ello 가 나와야 함
    4개의 char 를 one hot 으로 바꿔주고 넣음
    hidden layer 3개의 weight 가 정해짐 (hidden.. 3..??)
    output 으로 one hot 의 가장 큰 값을 고름

    * RNN applications
    language model
    speech recognition
    machine translation
    conversation modeling/Question Answering
    image/video captioning
    image/music/dance generation

    * Recurrent Networks offer a lot of flexibility
    one to one (vanila RNN)
    one to many (Image Captioning)
    many to one (Sentiment Classification)
    many to many (Machine Translation)
    many to many (Video classification on frame level)


----
lab 12-1 RNN – Basic
----






----
lab 12-2 RNN – Hi Hello Training
----
    One-hot encoding
    unique chars 를 vocabulary 단위로 만듬
    각 문자열의 모음 dictinary

    Teach RNN 'hihello'
    seq: 6개 (한번에 몇개씩 넣을껀지)
    hidden : 5개 (문자열 5개중 하나로만 나와야 하니까 출력의 dimession)
    batch : 몇번 돌릴껀지 (지금은 1번)

    Creating rnn cell
    LSTMCell, GRU 를 쓸수도 있음
    cell 의 사이즈 rnn_size 는 출력값 5

    Execute RNN
    input : one-hot size
    hidden_size : one-hot output
    batch_size : 6개의 seq 를 몇번 넣을지
    seqence_length : 6 hihello

    Data creation
    x <-> y (one-hot data)

    * Feed to RNN
    hidden_size 가 아니고 input_dim
    x = None : 여기서는 1 이지만 많아도 괜찮게
    y = None : batch 사이즈
    cell : hidden_size 5
    initial_state=zero 로 batch_size 만큼 줌 초기화 해줌
    이게 뭐지..--?

    * Cost: seqence_loss
    sequence_loss 알아보기 예제
    sequence_loss : logits(예측한값), target(실제값), weight(일단 1로줌),
    0.9 강하게 예측함 loss 가 더 작게 나온다

    logit : rnn 에서 나온 값을 원래는 바로 넣지 않는다.

    * Training
    train 을 실행시켜줌
    loss 를 출력
    prediction : argmax 를 사용해서 최종 예측 값을 구함
    0, 1, 2... 숫자를 문자로 출력해줌 idx2char[c]

----
lab 12-3 Long Sequence RNN
----
    * Better data creation
    여러 데이터 가지고 예측해 보기
    enumerate 로 key value 로 숫자 문자열 만듬
    sample_idx = 샘플 데이터 인텍스 char
    x_data 입력데이터
    y_data 입력데이터 이후에 나오게 될 데이터
    "if you want you"
    i 가 나오면 다음 값으로 f 가 나옴
    tf.one_hot(one-hot 으로 바꿀변수, one-hot개수) : shape 을 주의해야됨

    * Hyper parameter
    dic_size 가 hidden, num_class(output) 와 같음

    * Training
    데이터가 커서 학습횟수를 많이 해야 함

    * Really long sentence?
    긴 문장을 학습시킬때 한번에 다 넣지 않고 batch size 를 늘려줘서 데이터를 짤라서 넣어 줌

    * Making dataset
    loop 를 돌면서 seq 만큼 짤라 여러 batch 를 만들어냄

    * RNN parameter
    seq length 자른만큼 줌
    batch 총 batch 개수

    * LSTM and loss
    x,y 의 none 값엔 batch 사이즈 만큼 들어감

    * 왜 잘안되는지 생각해보기
    힌트 : logit, rnn 이 깊지가 않음

----
lab 12-4 Stacked RNN + Softmax Layer
----
    RNN seq 의 완성

    * Wide & Deep

    * Stacked RNN
    여러 층으로 쌓음
    하나의 cell 을 만들어서
    MultiRNNCell 함수를 사용
        cell 에서는 hidden_size 만 신경써서 주고
        cell * n 해주면 알아서 deep 하게 만들어줌

    * Softmax(FC) in Deep CNN
    CNN 에서 에서 했던것 처럼 FC 를 여러개 붙여주듯이 하자

    * softmax
    softmax 를 붙여주자
    각각의 입력을 붙여서 붙일수도 있으나 메모리를 많이 씀
    어짜피 다 똑같은 데이터기 떄문에 한줄로 쌓아서 softmax 해서 나눠줌
    softmax 에 맞는 wight 는 주면됨
    x_for_softmax 에 RNN 으로 나옴 최종 data 를 넣고 hidden_size에 맞게 해주고 나머지는 알아서
    output softmax 에서 나온값을 다시 펼침
    batch_size 만큼 펼쳐줌
    wight 과 bias 를 정해줘야 함
    입력은 hidden size
    num_class output

    * Loss
    softmax 해서 나온 값으로 (rnn 의 output 값과 같은 shape 을 가지고 있음)
    sequence_loss 에 넣어서 loss 를 구함

    * char-rnn
    세익스피어 학습시키기
    소스코딩 학습시키기
        마치 사람이 쓴것처럼 주석도 달아서 코드를 만들어줌

    * 사이트
    github.com/sherjilozair/char-rnn-tensorflow
    github.com/hunkim/word-rnn-tensorflow


----
lab 12-5 Dynamic RNN
----
    * Different seq length
    늘 입력값의 길이가 정해져 있지 않을 수 있다.
    <pad> :없는 값을 임의로 채워줌
        weight 에 영향을 줘서 좋지 않을 수 있음
    각 batch 에 열의 개수를 알려줌

    * Dynamic RNN
    dynamic_rnn 함수를 이용
    sequence_length 에 길이들을 줌
    빈 곳은 loss 값을 0 으로 만듬


----
Lab12-6: RNN with Time Series Data
----
    * Time series data
    시간이 지나면서 값이 변하는 데이터
    주식시장

    * Many to one
    1 일 데이터 가지고 7일 후 데이터 알아네기
    입력의 dim 은 몇이고 seq 는 몇인지 알아내기
    input = 5 (open, high, low, volume, close)
    seq = 7 일

    * Reading data
    x[::-1] -> 시간순으로 하기 위해서 값을 거꾸로 뒤집음
    minmax 로 값의 들쑥날쑥을 normalize 함
    for 문이해가 안됨..?????

    * Training and Test data
    70% 만 training 으로 씀
