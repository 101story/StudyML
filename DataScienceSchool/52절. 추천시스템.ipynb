{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추천 시스템의 기초\n",
    "\n",
    "사용자(user)가 상품(item)에 대해 어떻게 평가하는지를 예측하는 예측 시스템\n",
    "\n",
    "## Surprise 패키지\n",
    "\n",
    "* https://github.com/NicolasHug/Surprise\n",
    "* http://surprise.readthedocs.io/en/latest/index.html\n",
    "\n",
    "\n",
    "* Koren2010: \"Factor in the Neighbors: Scalable and Accurate Collaborative Filtering\", YEHUDA KOREN. 2010\n",
    "    - http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf\n",
    "* Koren2011: \"Collaborative Filtering on Ordinal User Feedback\", Yehuda Koren and Joseph Sill, 2011\n",
    "    - http://www.ijcai.org/Proceedings/13/Papers/449.pdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!pip install --timeout 1000 surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 평점 데이터  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovieLense 데이터 중 10만개의 샘플 데이터세트\n",
    "\n",
    "data = surprise.Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item  rate\n",
       "0  196  242   3.0\n",
       "1  186  302   3.0\n",
       "2   22  377   1.0\n",
       "3  244   51   2.0\n",
       "4  166  346   1.0\n",
       "5  298  474   4.0\n",
       "6  115  265   2.0\n",
       "7  253  465   5.0\n",
       "8  305  451   3.0\n",
       "9    6   86   3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data.raw_ratings, columns=['user', 'item', 'rate', 'id'])\n",
    "del df['id']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">추천 시스템은 사용자 아이디와 상품 아이디라는 두 개의 카테고리 입력과 평점 출력을 가지는 예측 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"9\" halign=\"left\">rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rate                                \n",
       "item  211 212 213 214 215 216 217 218 219\n",
       "user                                     \n",
       "290     3                   4       2    \n",
       "291         4       4   4           4   4\n",
       "292                 3                    \n",
       "293     4       3       4   4   3   2    \n",
       "294                                      \n",
       "295             5       5   5   4   5    \n",
       "296     4                                \n",
       "297     4       3       2   4       3    \n",
       "298     5       3       5                \n",
       "299     4   4   5           5            "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x 상품, y 사용자 아이디 -> 평점 행렬 R (특정 사용자y 의 특정 상품x 의 평점)\n",
    "df_table=df.set_index(['user', 'item']).unstack()\n",
    "df_table.fillna('').iloc[212:222, 808:817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x227d26d6358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x227cfaf8b70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x227d0b5e240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x227d0bef940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD5CAYAAAA9SqL2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEGw8v8BpH/ZFW8gSxUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227cfb19550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 빈칸을 힌색, 점수에 색을줌 \n",
    "plt.imshow(df_table)\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"item\")\n",
    "plt.ylabel(\"user\")\n",
    "plt.title(\"Rate Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추천 시스템 알고리즘\n",
    "\n",
    "1. 베이스라인 모형\n",
    "2. Collaborative Filtering\n",
    "    * 2-1. Neighborhood Models\n",
    "        - User-based CF\n",
    "        - Item-based CF\n",
    "    * 2-2. Latent Factor Models\n",
    "        - Matrix Factorization\n",
    "        - SVD\n",
    "3. Content-Based Recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베이스라인 모형\n",
    "\n",
    "사용자 아이디  u , 상품 아이디  i, 두 개의 카테고리 값 입력에서 평점  $r_{ui}$ 의 예측치  $\\hat{r}_{ui}$  을 예측하는 가장 단순한 모형\n",
    "\n",
    "사용자와 상품 특성에 의한 평균 평점의 합을 이용<br>\n",
    "오차 함수를 최소화 하도록 구해짐 <br>\n",
    "과최적화를 피하기 위해 정규화 항을 추가 할 수 있다. \n",
    "\n",
    "### 최적화 알고리즘 \n",
    "\n",
    "오차 함수를 최소화하기위한 알고리즘 ( 알고리즘의 선택은 method 인수를 사용)\n",
    "\n",
    "* ALS (Alternating Least Squares)의 인수\n",
    "    reg_i: 상품에 대한 정규화 가중치. 디폴트는 10.\n",
    "    reg_u: 사용자에 대한 정규화 가중치. 디폴트는 15.\n",
    "    n_epochs: 최적화 반복 횟수. 디폴트는 10.\n",
    "* SGD (Stochastic Gradient Descent)의 인수\n",
    "    reg: 정규화 가중치. 디폴트는 0.02.\n",
    "    learning_rate: 최적화 스텝 사이즈. 디폴트는 0.005.\n",
    "    n_epochs: 최적화 반복 횟수. 디폴트는 20\n",
    "\n",
    "### 모형 사용법\n",
    "1. 데이터세트의 split, folds 메소드를 사용하여 K-Fold 트레이닝 데이터셋과 테스트 데이터셋을 만든다.\n",
    "2. 모형 알고리즘 객체를 생성한다.\n",
    "3. 모형 알고리즘 객체의 train 메서드와 트레이닝 데이터셋으로 모수를 추정한 후, test 메서드로 테스트 데이터셋에 대한 예측을 실시한다.\n",
    "4. accuracy 서브패키지의 성능평가 함수를 사용하여 예측 성능을 계산한다.\n",
    "\n",
    "evaluate 명령으로 단축할 수도 있다.\n",
    "\n",
    "베이스라인 모형을 위한 BaselineOnly 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "FCP:  0.7047\n",
      "Estimating biases using als...\n",
      "FCP:  0.6995\n",
      "Estimating biases using als...\n",
      "FCP:  0.7031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70241740660712315"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split(n_folds=3) # 3개의 fold 로 나눔 \n",
    "bsl_options = {'method': 'als',\n",
    "              'n_epochs':5,\n",
    "              'reg_u': 12, \n",
    "              'reg_i':5}\n",
    "algo = surprise.BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "np.random.seed(0)\n",
    "acc = np.zeros(3)\n",
    "for i, (trainset, testset) in enumerate(data.folds()):\n",
    "#     if i==0 : \n",
    "#         print(trainset.all_items)\n",
    "#         print('-----',trainset)\n",
    "#         print('-----',testset)\n",
    "        \n",
    "    algo.train(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    acc[i] = surprise.accuracy.fcp(predictions, verbose=True)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " FCP(Fraction of Concordant Pairs)로 계산한 평가 점수는 약 0.70점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추천성능 평가기준\n",
    "\n",
    "accuracy 서브패키지 이용 \n",
    "    - RMSE(Root Mean Squared Error)\n",
    "        $\\text{RMSE} = \\sqrt{\\frac{1}{|\\hat{R}|} \\sum_{\\hat{r}_{ui} \\in \\hat{R}}(r_{ui} - \\hat{r}_{ui})^2}$\n",
    "        \n",
    "* FCP (Fraction of Concordant Pairs) :  Karen2011 에서 제안된 것으로 평점 자체가 아닌 평점에 의한 순위를 기준으로 하는 방법\n",
    "\n",
    "evaluate 명령을 사용하면 위 코드를 다음과 같이 짧게 만들면서 여러가지 평가기준을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm BaselineOnly.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9402\n",
      "MAE:  0.7441\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9501\n",
      "MAE:  0.7533\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "RMSE: 0.9439\n",
      "MAE:  0.7482\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9447\n",
      "Mean MAE : 0.7485\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.74408670479351391,\n",
       "                             0.75330700924027127,\n",
       "                             0.74822722434354882],\n",
       "                            'rmse': [0.94022930496712953,\n",
       "                             0.95007389942101372,\n",
       "                             0.94389227907434359]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter\n",
    "모든 사용자의 데이터를 균일하게 사용하는 것이 아니라 평점 행렬이 가진 특정한 패턴을 찾아서 이를 평점 예측에 사용하는 방법\n",
    "\n",
    "* CF 방법 \n",
    "    -  Neighborhood 모형: 사용자나 상품 기준으로 평점의 유사성을 확인\n",
    "    -  Latent Factor 모형: 행렬의 수치적 특징을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood 모형 (Memory-based CF)\n",
    "\n",
    "해당 사용자와 유사한(similar) 사용자에 대해 가중치를 준다. \n",
    "\n",
    "* 사용자 기반 (User-based) CF:  해당 사용자와 유사한 사용자를 찾는 방법 즉, 평점 행렬에서 유사한 사용자 행 벡터를 찾아서 이를 기반으로 빈 데이터를 계산하는 방법을 라고 한다.\n",
    "\n",
    "\n",
    "* 상품 기반 (Item-based) CF: 특정한 상품에 대해 사용자가 준 점수 즉, 평점 행렬의 상품 열 벡터의 유사성을 찾고 특정 상품과 유사한 평점 정보를 가지는 상품들로 해당 상품의 빈 데이터를 예측하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유사도 계산\n",
    "사용자 특성 벡터(평점 행렬의 행 벡터)이나 상품 특성 벡터(평점 행렬의 열 벡터)의 유사도(similarity)을 비교하기 위한 기준도 여러가지가 있을 수 있다.\n",
    "\n",
    "- 평균제곱차이 유사도 (Mean Squared Difference Similarity)\n",
    "- 코사인 유사도 (Cosine Similarity)\n",
    "- 피어슨 유사도 (Pearson Similarity)\n",
    "- 피어슨-베이스라인 유사도 (Pearson-Baseline Similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평균제곱차이 유사도 (Mean Squared Difference Similarity)\n",
    "\n",
    "msd는 유클리드 공간에서의 거리 제곱에 비례하는 값이다.\n",
    "\n",
    "* 사용자 u 와 사용자 v 간의 msd\n",
    "\n",
    "    $\\text{msd}(u, v) = \\frac{1}{|I_{uv}|} \\cdot \\sum\\limits_{i \\in I_{uv}} (r_{ui} - r_{vi})^2$\n",
    "    \n",
    "    I 는 i사용자와 j사용자 모두에 의해 평가된 상품의 집합, |I| i사용자와 j사용자 모두에 의해 평가된 상품수 \n",
    "    \n",
    "    \n",
    "* 상품 i 와 상품 j 간의 msd\n",
    "\n",
    "    $\\text{msd}(i, j) = \\frac{1}{|U_{ij}|} \\cdot \\sum\\limits_{u \\in U_{ij}} (r_{ui} - r_{uj})^2$\n",
    "    \n",
    "    U 는 i상품, j상품 모두를 평가한 사용자의 집합이고 |U| 상품i 와 상품j 모두를 평가한 사용자 수 \n",
    "    \n",
    "\n",
    "거리가 멀수록 유사도는 떨어진다. msd값이 0이 되는 경우를 대비하여 1을 더해준다. \n",
    "\n",
    "$\\begin{split}\\text{msd_sim}(u, v) &= \\frac{1}{\\text{msd}(u, v) + 1}\\\\\n",
    "\\text{msd_sim}(i, j) &= \\frac{1}{\\text{msd}(i, j) + 1}\\end{split}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9886\n",
      "MAE:  0.7800\n",
      "------------\n",
      "Fold 2\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9902\n",
      "MAE:  0.7836\n",
      "------------\n",
      "Fold 3\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9869\n",
      "MAE:  0.7806\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9885\n",
      "Mean MAE : 0.7814\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.78003965346735049,\n",
       "                             0.78363621800346173,\n",
       "                             0.78056677108086081],\n",
       "                            'rmse': [0.98858741197997724,\n",
       "                             0.99017322051835588,\n",
       "                             0.98686584325074944]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name':'msd'}\n",
    "algo = surprise.KNNBasic(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코사인 유사도 (Cosine Similarity)\n",
    "\n",
    "두 특성 벡터의 각도에 대한 코사인 값 \n",
    "\n",
    "벡터 x 와 벡터 y 사이의 각도 θ  는 두 벡터의 내적 x⋅y 와 다음과 같은 관계가 있다. \n",
    "\n",
    "각도 θ 가 0도이면 코사인 유사도는 1이다. 반대로 각도 θ 가 90도이면 코사인 유사도는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0223\n",
      "MAE:  0.8075\n",
      "------------\n",
      "Fold 2\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0247\n",
      "MAE:  0.8118\n",
      "------------\n",
      "Fold 3\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0190\n",
      "MAE:  0.8076\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0220\n",
      "Mean MAE : 0.8089\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.80750332552680459,\n",
       "                             0.81177206213621389,\n",
       "                             0.80756159060634702],\n",
       "                            'rmse': [1.0222944428841125,\n",
       "                             1.0246658327983542,\n",
       "                             1.0189738441664089]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'cosine'}\n",
    "algo = surprise.KNNBasic(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피어슨 유사도 (Pearson Similarity)\n",
    "\n",
    "두 벡터의 상관계수(Pearson correlation coefficient)\n",
    "\n",
    "- 사용자 u 와 사용자 v 간의 msd\n",
    "- 상품 i 와 상품 j 간의 msd\n",
    "\n",
    "상관계수는 가장 높은 경우의 값이 1이고 무상관인 경우에는 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0203\n",
      "MAE:  0.8083\n",
      "------------\n",
      "Fold 2\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0219\n",
      "MAE:  0.8117\n",
      "------------\n",
      "Fold 3\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0196\n",
      "MAE:  0.8091\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0206\n",
      "Mean MAE : 0.8097\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.80832858833726573,\n",
       "                             0.81172876105088099,\n",
       "                             0.80907484745025715],\n",
       "                            'rmse': [1.0203032617754169,\n",
       "                             1.0218681954683047,\n",
       "                             1.0195611604258723]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson'}\n",
    "algo = surprise.KNNBasic(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피어슨-베이스라인 유사도 (Pearson-Baseline Similarity)\n",
    "\n",
    "상관계수를 구하지만 각 벡터의 기댓값을 단순 평균이 아니라 베이스라인 모형에서 예측한 값을 사용한다.\n",
    "\n",
    "는 벡터의 차원 즉, 두 사용자나 상품에 공통적으로 있는 평점 원소의 갯수를 이용하여 정규화를 하는 shrinkage를 추가하여 사용\n",
    "\n",
    "* 사용자와 사용자 msd  $ \\hat{\\rho}_{uv}$ 를 사용\n",
    "$\\begin{split}\\text{pearson_baseline_shrunk_sim}(u, v) &= \\frac{|I_{uv}| - 1}\n",
    "{|I_{uv}| - 1 + \\text{shrinkage}} \\cdot \\hat{\\rho}_{uv}\\end{split}$\n",
    "\n",
    "* 상품과 상품 msd  $ \\hat{\\rho}_{ij}$ 를 사용\n",
    "$\\begin{split}\\text{pearson_baseline_shrunk_sim}(i, j) &= \\frac{|U_{ij}| - 1}\n",
    "{|U_{ij}| - 1 + \\text{shrinkage}} \\cdot \\hat{\\rho}_{ij}\\end{split}$\n",
    "\n",
    "\n",
    "* surprise 패키지의 유사도 설정 옵션\n",
    "    - name: 사용할 유사도의 종류를 나타내는 문자열. 디폴트는 'MSD'.\n",
    "    - user_based: True면 사용자 기반, False면 상품 기반.\n",
    "    - min_support: 두 사용자나, 상품에서 공통적으로 있는 평점 원소의 수의 최솟값. 공통 평점 원소의 수가 이 값보다 적으면 해당 벡터는 사용하지 않는다. 디폴트는\n",
    "    - shrinkage: Shrinkage 가중치. 디폴트는 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBasic.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0104\n",
      "MAE:  0.7982\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0112\n",
      "MAE:  0.8006\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0113\n",
      "MAE:  0.8010\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0110\n",
      "Mean MAE : 0.8000\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.7982307138145035,\n",
       "                             0.80060439054999366,\n",
       "                             0.80104432969047168],\n",
       "                            'rmse': [1.0103975523064834,\n",
       "                             1.0111963400864099,\n",
       "                             1.0113342753032724]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline'}\n",
    "algo = surprise.KNNBasic(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN 가중치 예측 방법\n",
    "\n",
    "* KNN(K Nearest Neighbors) 기반 예측 방법: 일단 유사도가 구해지면 평점을 예측하고자 하는 사용자(또는 상품)와 유사도가 큰 k 개의 사용자(또는 상품) 벡터를 사용하여 가중 평균을 구해서 가중치를 예측하는 방법 \n",
    "\n",
    "\n",
    "* surprise 패키지의 3가지 kNN 기반 가중치 예측 알고리즘 클래스 \n",
    "    -  KNNBasic : 평점들을 단순히 가중 평균한다. Nk 는 k 개의 가장 유사도가 큰 벡터의 집합이다.\n",
    "    - KNNWithMeans : 평점들을 평균값 기준으로 가중 평균한다.\n",
    "    - KNNBaseline : 평점들을 베이스라인 모형의 값 기준으로 가중 평균한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNWithMeans.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9454\n",
      "MAE:  0.7362\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9548\n",
      "MAE:  0.7436\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9459\n",
      "MAE:  0.7389\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9487\n",
      "Mean MAE : 0.7395\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.73615574599618594,\n",
       "                             0.74359161656742523,\n",
       "                             0.73888041744545319],\n",
       "                            'rmse': [0.94544127849978465,\n",
       "                             0.95483697175919002,\n",
       "                             0.94592206643814936]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline'}\n",
    "algo = surprise.KNNWithMeans(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm KNNBaseline.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9288\n",
      "MAE:  0.7267\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9377\n",
      "MAE:  0.7351\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9310\n",
      "MAE:  0.7300\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9325\n",
      "Mean MAE : 0.7306\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.72668665897975215,\n",
       "                             0.73509977830678708,\n",
       "                             0.73000684126778348],\n",
       "                            'rmse': [0.9288461182053559,\n",
       "                             0.93774902478999866,\n",
       "                             0.9310173410593936]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline'}\n",
    "algo = surprise.KNNBaseline(sim_options=sim_options)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor 모형\n",
    "\n",
    "긴 사용자 특성이나 상품 특성을 몇 개의 요인 벡터로 간략화(approximate)할 수 있다는 가정에서 출발한 모형이다. PCA(Principle Component Analysis)를 사용하면 긴 특성 벡터를 소수의 차원으로 차원 축소할 수 있듯이 사용자의 특성도 차원 축소 할 수 있다.\n",
    "\n",
    "예를 들어 액션을 싫어하고(-1) 코미디(2)나 드라마(3)를 좋아하는 사용자의 요인 벡터는 다음과 같다.\n",
    "\n",
    "pTu=(−1,2,3)\n",
    " \n",
    "어떤 영화가 액션 요소가 2이고 코미디 요소가 1이고, 드라마 요소가 1이라면\n",
    "\n",
    "qTi=(2,1,1)\n",
    " \n",
    "평점은 다음과 같을 것이다.\n",
    "$r_{ui} = q_i^Tp_u = -1 \\cdot 2 + 2 \\cdot 1 + 3 \\cdot 1 = 3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "Matrix Factorization 방법은 모든 사용자와 상품에 대해 다음 오차 함수를 최소화하는 요인 벡터를 찾아낸다. \n",
    "\n",
    "   $R \\approx PQ^T$\n",
    "\n",
    "- $R \\in \\mathbf{R}^{m \\times n}$ : m 사용자와 n 상품의 평점 행렬  \n",
    "- $P \\in \\mathbf{R}^{m \\times k}$ : m 사용자와 k 요인의 관계 행렬 \n",
    "- $Q \\in \\mathbf{R}^{n \\times k}$ : n 상품과 k 요인의 관계 행렬 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD (Singular Value Decomposition)\n",
    "\n",
    "SVD (Singular Value Decomposition) 특이값분해 는 Matrix Factorization 문제를 푸는 방법 중 하나이다.\n",
    "\n",
    "m×n 크기의 행렬 R 은 다음과 같이 세 행렬의 곱으로 나타낼 수 있다. \n",
    "\n",
    "$R =  U \\Sigma V^T$\n",
    "- $U$ : m×m 크기의 행렬로 역행렬이 대칭 행렬\n",
    "- $\\Sigma$ : m×n 크기의 행렬로 비대각 성분이 0\n",
    "- $V$ : n×n 크기의 행렬로 역행렬이 대칭 행렬\n",
    "\n",
    "$\\Sigma$ 의 대각성분 = 특이치 \n",
    "\n",
    "전체 특이치 중에서 가장 큰 값 k 개의 특이치만 사용 (Truncated SVD) 하여 다음행렬을 만듬 \n",
    "- $\\hat{U}$ : U 에서 가장 큰 값 k 개의 특이치에 대응하는 k 개의 성분만 남긴 m x k 크기의 행렬 \n",
    "- $\\hat{\\Sigma}$ : 가장 큰 값 k 개의 특이치에 대응하는 k 개의 성분만 남긴 k x k 크기의 대각행렬 \n",
    "- $\\hat{V}$ : v 에서 가장 큰 값 k 개의 특이치에 대응하는 k 개의 성분만 남긴 k x n 크기의 행렬 \n",
    "\n",
    "이 행렬들을 조합해 원래의 행렬과 같은 크기의 유사한 행렬을 만듬 \n",
    "\n",
    "하지만 실제로 평점 행렬은 빈 원소가 많은 sparse 행렬로서 SVD를 바로 적용하기 힘들기 때문에 행렬  P, Q 는 다음과 같은 모형에 대해 오차 함수를 최소화하여 구한다.\n",
    "\n",
    "surprise 패키지에서는 matrix_factorization 서브패키지에서 SVD 와 SVDpp라는 클래스를 제공한다.\n",
    "\n",
    "http://surprise.readthedocs.io/en/latest/matrix_factorization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9532\n",
      "MAE:  0.7508\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9602\n",
      "MAE:  0.7570\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9534\n",
      "MAE:  0.7519\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9556\n",
      "Mean MAE : 0.7532\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.75081270552967738,\n",
       "                             0.75701018410304088,\n",
       "                             0.75186228416016865],\n",
       "                            'rmse': [0.95315143945678538,\n",
       "                             0.96021523509860573,\n",
       "                             0.95340125771148521]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.SVD(n_factors=200, n_epochs=30)\n",
    "surprise.evaluate(algo, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
