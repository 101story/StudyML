{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" #'last' 기본값"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting datasets one feature at a time: decision trees\n",
    "\n",
    "\n",
    "* 의사 결정 트리 (스무고개)\n",
    "\n",
    "\n",
    "* Decision Tree Flowchart\n",
    "    - Decision Block (의사결정 블록, 사각형)\n",
    "    - Terminal Block (단말 블록, 타원형)\n",
    "    - Branch (가지)\n",
    "    \n",
    "    \n",
    "* 장점\n",
    "    - 적은 계산 비용\n",
    "    - 이해하기 쉬운 학습 결과\n",
    "    - 누락값 처리\n",
    "    - 분류와 무관한 특징 처리 가능\n",
    "\n",
    "\n",
    "* 단점\n",
    "    - 과적합되기 쉬움 (너무 복잡한 형태)\n",
    "    \n",
    "    \n",
    "* 적용\n",
    "    - 수치형값, 명목형값\n",
    "\n",
    "---- 이진트리도 있으나 주로 정렬할때 사용 (여기서는 사용하지 않는다.)<br>\n",
    "kNN 알고리즘은 데이터에대한 추가적으로 생각할 정보를 주지 않는다. \n",
    "\n",
    "_알쓸신잡) <br>\n",
    "Btreeindex, bitmapindex.. 오라클의 저장단위는 물리적인단위, 논리적인 단위로 나뉘어 져있다. 논리적인 단위가 있는 이유 다른 file system 이여도 저장 가능하도록 하기위해서. NTFS 는 제한없음, FAT32 4G 가 최대 <br>\n",
    "오라클 데이터 주소값 : 6자리3자리6자리3자리 > 오파블로 (objectId(segmentID), 파일번호(몇번째파일), 데이터블럭ID, RowID)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tree construction\n",
    "\n",
    "** ID3 알고리즘**\n",
    "\n",
    "* ID3 를 이용한 트리 생성 순서 \n",
    "\n",
    "    1. 데이터를 가장 잘 나눌 수 있는 틍징을 먼저 찾아서 데이터 집합을 하위 집합으로 분할\n",
    "        - 정보 이득 (Informaion Gain) 이 가장 큰 특징 (현상태와 그다음상태의 정보 차이) \n",
    "        - 엔트로피 (Entropy 정보량) 가 가장 크게 낮아지는 특징\n",
    "        - 정보량이 많다. = 선택사항이 많다. = 불확실 하다. = 복잡성, 불확정성\n",
    "    2. 해당 특징을 포함하는 노드 생성\n",
    "    3. 하위 집합의 모든 데이터가 같은 클래스에 속하면 해당 하위 집합에 대한 분류 종료\n",
    "    4. 2의 경우가 아니라면 이 하위 집합에 대해 1을 적용\n",
    "    5. 모든 데이터가 분류될 때까지 (=모든 하위 집합에 대해) 1~4 반복\n",
    "        - 재귀적방법으로 해결\n",
    "        - factorial(n) : n x (n-1) x (n-2).... =>  fact(n) = n x fact(n-1)\n",
    "    \n",
    "    \n",
    "노드에 비에 feature 정보가 적을 땐 남아있는 타갯들을 보고 다수결로 해결 \n",
    "\n",
    "\n",
    "### $ 트리 구조 생성 의사코드 \n",
    "\n",
    "    데이터 집합에 있는 모든 아이템이 같은 부류항복에 속하는지 확인 :\n",
    "        if 그렇다면, 분류 항목 표시를 반환\n",
    "        else 아니면\n",
    "            데이터를 분할하는 가장 좋은 속성을 찾음\n",
    "            데이터 집합 분할\n",
    "            가지 노드 생성\n",
    "                for 각노드마다 분할 반복\n",
    "                    create branch 를 호출하고 가지노드에 결과 추가 \n",
    "            가지 노드를 반환함 \n",
    "\n",
    "\n",
    "General approach to decision trees\n",
    "\n",
    "    1. Collect: 모든 방법\n",
    "    2. Prepare: 명목형값, 연속형값(수지형)은 양자화를 통해 이산형 값으로 변환 \n",
    "        - 양자화 (Quantizaton) : 끊어지는 값으로 만듬, 이산\n",
    "    3. Analyze: 모든방법, 트리를 만든 후 시각적 트리 검토\n",
    "    4. Train: 트리형태로 구조 구성\n",
    "    5. Test: 학습된 트리로 오류율(error rate) 계산\n",
    "    6. Use: 모든 지도학습에서 사용 (데이터를 이해하기 위해 사용되기도 함)\n",
    "\n",
    "    >> Knowledge Representation : 생성된 tree 구조 \n",
    "\n",
    "\n",
    "* 의사결정트리 알고리즘 종류\n",
    "    - ID3 (Iterative Dichotomiser 3)\n",
    "    - C4.5 (successor of ID3)\n",
    "    - C5.0 (successor of ID4)\n",
    "    - CART (Classification And Regression Tree)\n",
    "    - CHAID (CHi-squared Automatic Interaction Detector) : 이 알고리즘은 분류 트리를 계산할 때 다단계 분할을 수행한다.\n",
    "    - MARS (Multivariate adaptive regression splines) : 더 많은 수치 데이터를 처리하기 위해 결정 트리를 사용한다.\n",
    "    - 조건부 추론 트리 (Conditional Inference Trees) : 과적합을 피하기 위해 여러 테스트에 대해 보정 분할 기준으로 비 - 파라미터 테스트를 사용하는 통계 기반의 방법이다. 이 방법은 편견 예측 선택 결과와 가지 치기가 필요하지 않다.\n",
    "    \n",
    "    https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95\n",
    "    \n",
    "    \n",
    "* 가장 적합한 분할 기준 선택 방법\n",
    " - 정보 이득\n",
    " - 지니 불순도 \n",
    " - 분산 감소 \n",
    " \n",
    " \n",
    "* target 정보의 yes 로 판단할지 no 로 판단할지는 양적인 조건으로 판단 quantitative 예) 물고기다. 아니다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Information gain\n",
    "\n",
    "* 교제 용어 \n",
    "    - class : feature  예) 2개의 class (컬럼이 2개)\n",
    "    - class label : feature 의 실제 value 값 예) yes, no\n",
    "    - label : feature 의 실제 String 값 예) 2번째 컬럼 값 지느러미여부\n",
    "    - target : 결과 예) 물고기다. 아니다. \n",
    "\n",
    "\n",
    "* 데이터를 분할하기 이전 이후의 정보량(엔트로피) 변화\n",
    "* 정보 이득이 가장 큰 특징에 대한 분할 수행\n",
    "* 정보 이득으로 정보의 불확실성(엔트로피) 감소\n",
    "\n",
    "### 개별 정보량과 엔트로피 \n",
    "\n",
    "$log_2p(x_i)$\n",
    "\n",
    "* 개별 정보량 \n",
    "    * 확률이 낮을 수록 개별 정보량은 커짐 : 엔트로피가 커지는데 기어\n",
    "        * 로그의 결과에 -1 을 곱한 이유 (0~1 확률은 1/n 분수니까, log(1) 이하의 값은 음수가 나옴) <br>\n",
    "        확률이 낮을수록 개별 정보량은 커짐 > 엔트로피가 커짐 \n",
    "    * 정보를 전달(표현) 하는데 몇 자리 2진수(몇비트) 면 충분한가\n",
    "        * 밑이 2 인 log (컴퓨터로 정보를 전달 하려고 하기 때문에)         \n",
    "  \n",
    "  \n",
    "* 엔트로피 \n",
    "    * 개별 정보량에 대한 기댓값 <br>\n",
    "        $H=-\\sum_{i=1}^{n}p(x_i)\\log_2 P(x_i)$\n",
    "    * 불확실한 정도, 무질서 정도\n",
    "    * 확률이 낮은 사건이 많을수록 정보의 엔트로피(불확실성)이 커진다.\n",
    "        - 로그함수 0 에 가까울수록 -y 값이 커짐\n",
    "    * 정보의 불확실성이 높다.\n",
    "        = 어떤 값이 나올지 알기 힘들다.\n",
    "    * 엔트로피가 높은 원인\n",
    "        - 모든 사건의 확률이 균등 \n",
    "            개별정보가 기대값이 가장 많을때, 동전 앞,뒤면 나오는 확률이 같을때<br>\n",
    "            앞면이 나올 확률이 높은 경우 (예, 8/10) 정보의 불확실 성은 줄어든다. (앞면이 많이 나올테니까) 정보량이 적다. (외부에 남아있는 정보가 적다. 뒷면이 나올 확률 2/10)             \n",
    "        - 확률이 낮은 사건이 많음 (정보가 다양) \n",
    "      \n",
    "\n",
    "\n",
    "<img src='03.entropy.png' width=500>\n",
    "--- 엔트로피의 성질 : 집합에 범주가 고르게 분포할 수록 엔트로피 값은 높다. (불확실성 상태가 크다.)\n",
    "의사결정 나무에서는 엔트로피가 높을 수록 Target 구분을 잘 못해주는 속성 필드가 되며, 낮을 수록 구분을 잘 해주는 유의한 속성 필드가 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [code] 3.1 calcShannonEnt : 데이터 집합의 새넌 엔트로피 계산 \n",
    "\n",
    "입력 데이터 집합을 순회하면서 타겟 라벨의 빈도수를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']],\n",
       " ['no surfacing', 'flippers'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marinedata, labels = trees.createDataSet()\n",
    "marinedata, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 'yes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'yes': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'yes': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가능한 모든 분류에 대한 딕셔너리 만들기 \n",
    "numentries = len(marinedata); numentries\n",
    "labelcounts = {}\n",
    "\n",
    "# for 문 \n",
    "i=0\n",
    "featvec = marinedata[i]; featvec\n",
    "current_targetlabel = featvec[-1]; current_targetlabel\n",
    "# 새로운 키 인 경우 사전에 저장 \n",
    "if current_targetlabel not in labelcounts.keys():\n",
    "    labelcounts[current_targetlabel] = 0\n",
    "    labelcounts\n",
    "labelcounts[current_targetlabel] += 1\n",
    "labelcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 사전의 get 함수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 키 인 경우 사전에 저장 (다른방법) \n",
    "# if current_targetlabel not in labelcounts.keys():labelcounts[current_targetlabel] = 0\n",
    "# labelcounts[current_targetlabel] += 1\n",
    "\n",
    "labelcounts[current_targetlabel] = labelcounts.get(current_targetlabel, 0) + 1\n",
    "labelcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5287712379549449"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "# 새넌 엔트로피 구하기 \n",
    "shannonEnt = 0.0\n",
    "i = 0\n",
    "# for 문 \n",
    "key = labelcounts.keys()[i]; key\n",
    "labelcounts[key]\n",
    "prob = float(labelcounts[key])/numentries\n",
    "shannonEnt -= prob * math.log(prob,2) #log base 2\n",
    "shannonEnt # yes 일때의 확률이 나옴 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [code] trees calcShannonEnt 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trees' from 'trees.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(trees)\n",
    "marinedata, labels = trees.createDataSet()\n",
    "shannonEnt = trees.calcShannonEnt(marinedata); shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shannonEnt 는 target 종류가 늘어날 수록 값이 커진다. <br>\n",
    "    \n",
    "    yes 2/5, no 3/5 = shannonEnt 0.9 \n",
    "        -> yes 1/5, no 3/5, maybe(추가) 1/5 = shannonEnt 1.3 \n",
    "\n",
    "    정보량이 증가, 복잡도가 높아짐 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Splitting the dataset\n",
    "\n",
    "데이터를 첫 번째 feature 값 (라벨) 로 분할하되 그 값이 '1' 인 생물의 데이터 집합 얻기 <br>\n",
    "집합을 분할하기 위해서 feature 를 선택해야 한다.     \n",
    "\n",
    "데이터를 2차원으로 분류 > feature 가 2개 \n",
    "\n",
    "어떤 feature 를 선택할 것인가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [code] splitDataSet(dataSet, axis, value) feature 의 value 값에 따라 data 모으기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retdataset = []\n",
    "marinedata, labels = trees.createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 'yes']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 'yes']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [1, 'yes']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 feature(axis=0) 가 1인 것만 뽑기 \n",
    "axis=1; value=1\n",
    "\n",
    "i=0\n",
    "# for 문 \n",
    "featvec = marinedata[i]; featvec\n",
    "# value 가 1 이면 저장하기 해당 feature 값 나머지 데이터 저장 \n",
    "if featvec[axis] == value:\n",
    "    # [1,1,'yes'] 에서 [ 만 선택 \n",
    "    reducedfeatvet = featvec[:axis]; reducedfeatvet\n",
    "    # [1,1,'yes'] 에서 나머지 1,'yes'] 만 선택 \n",
    "    # append 면 [, [1,'yes']] 중첩으로 들어감 풀어져 나옴 \n",
    "    # extend [1, 'yes']\n",
    "    reducedfeatvet.extend(featvec[axis+1:]); reducedfeatvet\n",
    "    # append 로 중접으로 쌓음  [[1, 'yes'], [1, 'yes']]\n",
    "    retdataset.append(reducedfeatvet); retdataset\n",
    "\n",
    "# axis=1 인 경우 [1, 0, yes] 중에서 1 고르고 yes 를 골라서 붙임 [1, yes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 다른 방법 \n",
    "# if featvec[axis] == value:\n",
    "#     reducedfeatvet = featvec[:axis]\n",
    "#     reducedfeatvet.extend(featvec[axis+1:])\n",
    "#     retdataset.append(reducedfeatvet)\n",
    "if featvec[axis] == value:\n",
    "    del featvec[1]\n",
    "    retdataset.append(featvec); retdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [code] trees splitDataSet 사용 (모든 feature value 에 대해서 엔트로피 구하기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'trees' from 'trees.pyc'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(trees)\n",
    "# 첫번째 피처 값 (라벨)이 1인 데이터 집합의 엔트로피 구하기 \n",
    "feat01 = trees.splitDataSet(marinedata, 0, 1); feat01\n",
    "trees.calcShannonEnt(feat01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번쨰 피처 값이 0인 데이터 집합의 엔트로피 \n",
    "feat00 = trees.splitDataSet(marinedata, 0, 0); feat00\n",
    "trees.calcShannonEnt(feat00) # 전부 같은 데이터만 있음 분류할 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat10 = trees.splitDataSet(marinedata, 1, 0); feat10\n",
    "trees.calcShannonEnt(feat10)\n",
    "feat11 = trees.splitDataSet(marinedata, 1, 1); feat11\n",
    "trees.calcShannonEnt(feat11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
